# src/mcp_test.py
import os
import asyncio
import json
import traceback
import sys
import uuid
import base64
import time
import re
from collections import defaultdict

try:
    from PIL import Image as PILImage
except ImportError:
    print("éŒ¯èª¤ï¼šéœ€è¦ Pillow åº«ä¾†è™•ç†åœ–åƒã€‚è«‹åŸ·è¡Œ pip install Pillow")
    PILImage = None # Indicate PIL is not available

if sys.platform.startswith("win"):
    # å¼·åˆ¶ä½¿ç”¨ ProactorEventLoopï¼Œä»¥æ”¯æ´ subprocess
    asyncio.set_event_loop_policy(asyncio.WindowsProactorEventLoopPolicy())


from dotenv import load_dotenv
from typing import TypedDict, Annotated, Sequence, Optional, Dict, Any, List, Union # Added Union
from contextlib import asynccontextmanager
import requests
import atexit
import platform


from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, SystemMessage, ToolMessage
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.runnables import RunnableConfig
from langchain_core.tools import BaseTool, tool
from langchain_openai import ChatOpenAI
from langgraph.graph import StateGraph, END, add_messages

from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_mcp_adapters.client import MultiServerMCPClient


load_dotenv()

# =============================================================================
# API Key å‹•æ…‹ç®¡ç† (Free/VIP åˆ‡æ›)
# =============================================================================
class APIKeyManager:
    """ç®¡ç† Free å’Œ VIP API Key çš„è‡ªå‹•åˆ‡æ›"""
    def __init__(self):
        self.using_vip = False
        self.vip_calls_remaining = 0
        self.last_error_time = 0
        self.consecutive_quota_errors = 0
        
    def should_use_vip(self) -> bool:
        """åˆ¤æ–·æ˜¯å¦æ‡‰è©²ä½¿ç”¨ VIP Key"""
        return self.using_vip and self.vip_calls_remaining > 0
    
    def handle_quota_error(self) -> bool:
        """
        è™•ç†é…é¡éŒ¯èª¤ï¼Œåˆ‡æ›åˆ° VIP Key
        Returns: True if switched to VIP, False if no VIP available
        """
        if not os.getenv("GEMINI_API_KEY_VIP"):
            print("  !! âŒ é…é¡å·²æ»¿ä¸”ç„¡ VIP Key (GEMINI_API_KEY_VIP)ï¼Œç„¡æ³•ç¹¼çºŒ")
            return False
            
        self.consecutive_quota_errors += 1
        current_time = time.time()
        
        # å¦‚æœåœ¨çŸ­æ™‚é–“å…§é€£çºŒé‡åˆ°é…é¡éŒ¯èª¤ï¼Œå¢åŠ  VIP ä½¿ç”¨è¼ªæ•¸
        if current_time - self.last_error_time < 60:  # 1åˆ†é˜å…§
            vip_rounds = min(10, 5 * self.consecutive_quota_errors)  # æœ€å¤š10è¼ª
        else:
            vip_rounds = 5
            self.consecutive_quota_errors = 1
        
        self.using_vip = True
        self.vip_calls_remaining = vip_rounds
        self.last_error_time = current_time
        
        print(f"  >> âš ï¸  é…é¡å·²æ»¿ï¼Œåˆ‡æ›åˆ° VIP Keyï¼Œå°‡åŸ·è¡Œ {vip_rounds} è¼ªå¾Œè¿”å›å…è²»ç‰ˆ")
        return True
    
    def decrement_vip_calls(self):
        """VIP èª¿ç”¨è¨ˆæ•¸éæ¸›"""
        if self.vip_calls_remaining > 0:
            self.vip_calls_remaining -= 1
            print(f"  >> ğŸ’ VIP Key å‰©é¤˜èª¿ç”¨: {self.vip_calls_remaining}")
            
            if self.vip_calls_remaining == 0:
                self.using_vip = False
                self.consecutive_quota_errors = 0
                print("  >> âœ… VIP è¼ªæ•¸ç”¨å®Œï¼Œè¿”å›å…è²» Key")
    
    def get_current_key_type(self) -> str:
        """ç²å–ç•¶å‰ Key é¡å‹æè¿°"""
        return "VIPğŸ’" if self.should_use_vip() else "FreeğŸ†“"

# å…¨å±€ç®¡ç†å™¨å¯¦ä¾‹
api_key_manager = APIKeyManager()

# --- LLM Setup ---
try:
    api_key = os.getenv("GEMINI_API_KEY")
    api_key_vip = os.getenv("GEMINI_API_KEY_VIP")

    if not api_key:
        print("éŒ¯èª¤ï¼šæ‰¾ä¸åˆ° GEMINI_API_KEY ç’°å¢ƒè®Šæ•¸ã€‚")
        exit(1)
    else:
        # 1. åˆå§‹åŒ–å…è²»ç‰ˆ LLM
        agent_llm_free = ChatGoogleGenerativeAI(
            model="gemini-2.5-pro",
            temperature=0.5,
            google_api_key=api_key
        )
        
        fast_llm_free = ChatGoogleGenerativeAI(
            model="gemini-2.5-flash-lite",
            temperature=0.5,
            google_api_key=api_key
        )

        # 2. åˆå§‹åŒ– VIP ç‰ˆ LLM (å¦‚æœæœ‰çš„è©±)
        agent_llm_vip = None
        fast_llm_vip = None
        if api_key_vip:
            agent_llm_vip = ChatGoogleGenerativeAI(
                model="gemini-2.5-pro",
                temperature=0.5,
                google_api_key=api_key_vip
            )
            fast_llm_vip = ChatGoogleGenerativeAI(
                model="gemini-2.5-flash-lite",
                temperature=0.5,
                google_api_key=api_key_vip
            )
            print(f"âœ… VIP Agent LLM åˆå§‹åŒ–æˆåŠŸ (å‚™ç”¨ï¼Œé‡åˆ°é…é¡é™åˆ¶æ™‚è‡ªå‹•åˆ‡æ›)ã€‚")
        else:
            print("âš ï¸  æœªè¨­ç½® GEMINI_API_KEY_VIPï¼Œé‡åˆ°é…é¡é™åˆ¶æ™‚å°‡ç„¡æ³•è‡ªå‹•åˆ‡æ›")
        
        # é è¨­ä¸»è¦ LLM æŒ‡å‘å…è²»ç‰ˆ
        agent_llm = agent_llm_free
        fast_llm = fast_llm_free
        
        print(f"Agent LLM ({agent_llm.model}) åˆå§‹åŒ–æˆåŠŸ (é è¨­ Free)ã€‚")
        print(f"Fast LLM ({fast_llm.model}) åˆå§‹åŒ–æˆåŠŸ (é è¨­ Free)ã€‚")

    utility_llm = ChatOpenAI(model="gpt-4o-mini", temperature=0.7)
    print("Utility LLM (OpenAI for Router) åˆå§‹åŒ–æˆåŠŸã€‚")
except Exception as e:
    print(f"ERROR: ç„¡æ³•åˆå§‹åŒ– LLMã€‚éŒ¯èª¤: {e}")
    traceback.print_exc()
    exit(1)

# --- MCP Server Configurations ---
MCP_CONFIGS = {
    "rhino": {
        "command": "Z:\\miniconda3\\envs\\rhino_mcp\\python.exe",
        "args": ["-m","rhino_mcp.server"],
        "transport": "stdio",
    },
    # "revit": {
    #     "command": "node",
    #     "args": ["D:\\MA system\\LangGraph\\src\\mcp\\revit-mcp\\build\\index.js"],
    #     "transport": "stdio",
    # },
    # "pinterest": {
    #     "command": "node", # Assuming node runs the JS file
    #     "args": ["D:\\MA system\\LangGraph\\src\\mcp\\pinterest-mcp-server\\dist\\pinterest-mcp-server.js"],
    #     "transport": "stdio", # Assuming stdio, adjust if needed
    # },
    # "osm": {
    #   "command": "osm-mcp-server", # ä½¿ç”¨ osm-mcp-server å‘½ä»¤
    #   "args": [],  # ä¸éœ€è¦é¡å¤–åƒæ•¸
    #   "transport": "stdio",
    # }
}

# --- å…¨å±€è®Šæ•¸ ---
_loaded_mcp_tools: Dict[str, List[BaseTool]] = {}
_mcp_clients: Dict[str, MultiServerMCPClient] = {}
_mcp_init_lock = asyncio.Lock()

# =============================================================================
# å®šç¾©ç‹€æ…‹ (State)
# =============================================================================
class MCPAgentState(TypedDict):
    messages: Annotated[Sequence[BaseMessage], add_messages]
    initial_image_path: Optional[str]
    task_complete: bool = False
    # --- ç”¨æ–¼å­˜å„²æˆªåœ–/ä¸‹è¼‰çµæœçš„å­—æ®µ ---
    saved_image_path: Optional[str] # Stores the path returned by Rhino/Pinterest/OSM
    saved_image_data_uri: Optional[str] # Stores the generated data URI
    # --- <<< æ–°å¢ï¼šé€£çºŒæ–‡æœ¬éŸ¿æ‡‰è¨ˆæ•¸å™¨ >>> ---
    consecutive_llm_text_responses: int = 0 # Track consecutive non-tool/non-completion AI messages
    # --- MODIFIED: Add screenshot counter for Rhino ---
    rhino_screenshot_counter: int = 0 
    # --- END MODIFICATION ---
    last_executed_node: Optional[str] = None # è¨˜éŒ„æœ€å¾ŒåŸ·è¡Œçš„ç¯€é»åç¨±
    # --- æ–°å¢: å­˜å„²CSVå ±å‘Šè·¯å¾‘ ---
    saved_csv_path: Optional[str] = None
    # --- æ–°å¢: LLM èª¿ç”¨å»¶é²æ™‚é–“ç®¡ç† (ç§’) ---
    rpm_delay: float = 12.5  # flashé è¨­ 6.5 ç§’ï¼Œé¿å…é€Ÿç‡é™åˆ¶ï¼Œå¦‚æœæœ‰ä»˜è²»å¯ä»¥æ”¹ç‚º0.5  proé è¨­12

# =============================================================================
# æœ¬åœ°å·¥å…·å®šç¾© (Local Tools)
# =============================================================================
@tool
def create_planned_data_summary_csv(data_rows: List[Dict[str, Union[str, float]]], total_area: float, bcr: Optional[float], far: Optional[float], filename: str = "planned_project_summary.csv") -> str:
    """
    æ ¹æ“šã€Œè¦åŠƒå¥½ã€çš„è¨­è¨ˆæ•¸æ“šç”ŸæˆCSVæ‘˜è¦æ–‡ä»¶ã€‚
    æ­¤å·¥å…·ä¸èˆ‡Rhinoäº’å‹•ï¼›å®ƒåªè¨˜éŒ„è¨ˆç•«ä¸­æä¾›çš„æ•¸æ“šã€‚
    åœ¨è¦åŠƒéšæ®µçµæŸæ™‚ä½¿ç”¨æ­¤å·¥å…·ï¼Œä»¥å‰µå»ºè¨­è¨ˆæ„åœ–çš„æ‘˜è¦ã€‚

    Args:
        data_rows: ä¸€å€‹å­—å…¸åˆ—è¡¨ï¼Œæ¯å€‹å­—å…¸ä»£è¡¨ä¸€å€‹ç©ºé–“ã€‚å¿…é ˆåŒ…å« 'name' (str), 'area' (float), 'percentage' (float) å’Œ 'floor' (str, ä¾‹å¦‚ "Floor 1") éµã€‚
        total_area: è¦åŠƒçš„ç¸½æ¨“åœ°æ¿é¢ç© (float)ã€‚
        bcr: è¦åŠƒçš„å»ºè”½ç‡ (float, ç™¾åˆ†æ¯”)ã€‚å¦‚æœç„¡å‰‡ç‚ºç©ºã€‚
        far: è¦åŠƒçš„å®¹ç©ç‡ (float)ã€‚å¦‚æœç„¡å‰‡ç‚ºç©ºã€‚
        filename: è¼¸å‡ºçš„CSVæ–‡ä»¶åã€‚é è¨­ç‚º "planned_project_summary.csv"ã€‚

    Returns:
        ä¸€å€‹ç¢ºèªæˆåŠŸå’Œä¿å­˜æ–‡ä»¶è·¯å¾‘çš„å­—ä¸²ï¼Œä»¥ [CSV_FILE_PATH]: ç‚ºå‰ç¶´ã€‚
    """
    import csv
    import time
    from collections import defaultdict
    output_dir = r"D:\MA system\LangGraph\output\space"
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)
    
    base, ext = os.path.splitext(filename)
    timestamp = time.strftime("%Y%m%d_%H%M%S")
    new_filename = f"{base}_{timestamp}{ext}"
    file_path = os.path.join(output_dir, new_filename)
    headers = ["Space Name", "Area (sqm)", "Percentage (%)"]

    spaces_by_floor = defaultdict(list)
    for row in data_rows:
        floor = row.get('floor', 'Unassigned')
        spaces_by_floor[floor].append(row)
    
    try:
        with open(file_path, mode='w', newline='', encoding='utf-8-sig') as csv_file:
            writer = csv.writer(csv_file)
            
            writer.writerow(["Project Summary (Based on Plan)"])
            writer.writerow(["Total Planned Floor Area (sqm)", round(total_area, 2)])
            writer.writerow(["Planned Building Coverage Ratio (%)", bcr if bcr is not None else "N/A"])
            writer.writerow(["Planned Floor Area Ratio", far if far is not None else "N/A"])
            writer.writerow([])
            
            writer.writerow(["Planned Space Details"])

            sorted_floors = sorted(spaces_by_floor.keys())
            for floor in sorted_floors:
                writer.writerow([])
                writer.writerow([f"--- {floor} ---"])
                writer.writerow(headers)
                for row in spaces_by_floor[floor]:
                    writer.writerow([
                        row.get('name', 'N/A'), 
                        round(row.get('area', 0.0), 2),
                        round(row.get('percentage', 0.0), 2)
                    ])
                
        return f"[CSV_FILE_PATH]:{file_path}"
    except Exception as e:
        return f"[ERROR] Failed to create planned summary table: {str(e)}"

# --- æ–°å¢: æœ¬åœ°å·¥å…·åˆ—è¡¨ ---
LOCAL_TOOLS = [create_planned_data_summary_csv]

# =============================================================================
# å·¥å…·ç®¡ç† (ä½¿ç”¨ print æ›¿æ› logging)
# =============================================================================
async def initialize_single_mcp(mcp_name: str) -> tuple[Optional[MultiServerMCPClient], List[BaseTool]]:
    """åˆå§‹åŒ–å–®å€‹ MCP é€£æ¥ä¸¦ç²å–å…¶å·¥å…· (ä½¿ç”¨ print)ã€‚"""
    print(f"--- [Lazy Init] æ­£åœ¨åˆå§‹åŒ– {mcp_name} MCP é€£æ¥ ---")
    config_item = MCP_CONFIGS.get(mcp_name)
    if not config_item:
        print(f"  !!! [Lazy Init] éŒ¯èª¤: åœ¨ MCP_CONFIGS ä¸­æ‰¾ä¸åˆ° {mcp_name} çš„é…ç½®ã€‚")
        return None, []

    client = None
    tools = []
    try:
        # --- å‘½ä»¤å’Œè·¯å¾‘æª¢æŸ¥ (ä½¿ç”¨ print) ---
        command_path = config_item['command']
        # æª¢æŸ¥å‘½ä»¤æ˜¯å¦å­˜åœ¨ (å° 'python' é€™é¡é€šç”¨å‘½ä»¤å¯èƒ½ä¸é©ç”¨)
        if command_path != "python" and not os.path.exists(command_path) and command_path != sys.executable:
            print(f"  !!! [Lazy Init] è­¦å‘Š: å‘½ä»¤è·¯å¾‘ '{command_path}' ä¸å­˜åœ¨ã€‚")
        # æª¢æŸ¥ args ä¸­çš„æ–‡ä»¶è·¯å¾‘ (å¦‚æœæœ‰çš„è©±)
        for arg in config_item.get('args', []):
             # Check if it looks like a file path and doesn't exist
             if ('/' in arg or '\\' in arg) and not os.path.exists(arg):
                  print(f"  !!! [Lazy Init] è­¦å‘Š: åƒæ•¸ä¸­çš„è·¯å¾‘ '{arg}' ä¸å­˜åœ¨ã€‚")

        # print(f"  - [Lazy Init] ä½¿ç”¨é…ç½®: {config_item}")
        print(f"  - [Lazy Init] æ­£åœ¨åˆå§‹åŒ– {mcp_name} Client...")
        try:
            single_server_config = {mcp_name: config_item}
            client = MultiServerMCPClient(single_server_config)
            print(f"  - [Lazy Init] {mcp_name} Client åˆå§‹åŒ–å®Œæˆã€‚")
        except Exception as client_init_e:
            print(f"  !!! [Lazy Init] å®¢æˆ¶ç«¯åˆå§‹åŒ–éŒ¯èª¤: {client_init_e}")
            traceback.print_exc()
            return None, []

        # --- é€£æ¥å’Œç²å–å·¥å…· (ä½¿ç”¨ print) ---
        try:
            print(f"  - [Lazy Init] æ­£åœ¨å•Ÿå‹• {mcp_name} Client é€£æ¥ (__aenter__)...")
            await client.__aenter__()
            print(f"  - [Lazy Init] {mcp_name} Client é€£æ¥æˆåŠŸã€‚")

            print(f"  - [Lazy Init] [é–‹å§‹] æ­£åœ¨å¾ {mcp_name} ç²å–å·¥å…· (get_tools)...")
            try:
                tools = client.get_tools()
                print(f"  - [Lazy Init] [å®Œæˆ] å¾ {mcp_name} ç²å–å·¥å…·å®Œæˆã€‚æ•¸é‡: {len(tools)}")
                if not tools:
                    print(f"  !!! [Lazy Init] è­¦å‘Š: {mcp_name} è¿”å›äº†ç©ºçš„å·¥å…·åˆ—è¡¨ !!!")
                else:
                    # --- æ‰“å°å·¥å…·ä¿¡æ¯ (å¯é¸ï¼Œä¿æŒé–‹å•Ÿä»¥ä¾›èª¿è©¦) ---
                    print(f"  --- å¯ç”¨å·¥å…·åˆ—è¡¨ ({mcp_name}) ---")
                    for i, tool in enumerate(tools):
                        tool_info = f"    å·¥å…· {i+1}: Name='{tool.name}'"
                        if hasattr(tool, 'description') and tool.description:
                             tool_info += f", Desc='{tool.description[:60]}...'"
                        print(tool_info)
                    print(f"  --- å·¥å…·åˆ—è¡¨çµæŸ ({mcp_name}) ---")
            except Exception as tools_e:
                print(f"  !!! [Lazy Init] ç²å–å·¥å…·éŒ¯èª¤: {tools_e}")
                traceback.print_exc()
                tools = []
        except Exception as enter_e:
            print(f"  !!! [Lazy Init] å®¢æˆ¶ç«¯é€£æ¥æˆ–ç²å–å·¥å…·éŒ¯èª¤: {enter_e}")
            traceback.print_exc()
            if client:
                try:
                    print(f"  -- [Cleanup Attempt] å˜—è©¦é—œé–‰å¤±æ•—çš„ {mcp_name} client...")
                    await client.__aexit__(type(enter_e), enter_e, enter_e.__traceback__)
                    print(f"  -- [Cleanup Attempt] é—œé–‰ {mcp_name} client å®Œæˆã€‚")
                except Exception as exit_e:
                    print(f"  -- [Cleanup Attempt] é—œé–‰ {mcp_name} client æ™‚ä¹Ÿç™¼ç”ŸéŒ¯èª¤: {exit_e}")
                    traceback.print_exc()
            client = None
            tools = []
        print(f"--- [Lazy Init] {mcp_name.capitalize()} åˆå§‹åŒ–æµç¨‹å®Œæˆ ---")
    except Exception as inner_e:
        print(f"!!!!! [Lazy Init] éŒ¯èª¤: åœ¨è™•ç† {mcp_name} MCP æ™‚ç™¼ç”Ÿå¤–éƒ¨éŒ¯èª¤ !!!!!")
        traceback.print_exc()
        client = None
        tools = []
    return client, tools

# --- shutdown_mcp_clients (ä½¿ç”¨ print) ---
async def shutdown_mcp_clients(clients_to_shutdown: Dict[str, MultiServerMCPClient]):
    print("\n--- [Cleanup] æ­£åœ¨é—œé–‰ MCP Client é€£æ¥ ---")
    if not clients_to_shutdown:
        print("  æ²’æœ‰éœ€è¦é—œé–‰çš„å®¢æˆ¶ç«¯ã€‚")
        return
    for name, client in clients_to_shutdown.items():
        try:
            print(f"  - æ­£åœ¨é—œé–‰ {name} Client (__aexit__)...")
            await client.__aexit__(None, None, None)
            print(f"  - {name} Client å·²é—œé–‰")
        except Exception as close_e:
            print(f"éŒ¯èª¤: é—œé–‰ {name} Client æ™‚ç™¼ç”ŸéŒ¯èª¤: {close_e}")
            traceback.print_exc()
    print("--- [Cleanup] æ‰€æœ‰ MCP Client å·²å˜—è©¦é—œé–‰ ---")

# --- _sync_cleanup (ä½¿ç”¨ print, ç§»é™¤ _mcp_clients_initialized æª¢æŸ¥) ---
def _sync_cleanup():
    global _mcp_clients
    # åªæª¢æŸ¥ _mcp_clients æ˜¯å¦æœ‰å…§å®¹
    if _mcp_clients:
        print("--- [atexit] æª¢æ¸¬åˆ°éœ€è¦æ¸…ç† MCP å®¢æˆ¶ç«¯ ---")
        try:
            loop = asyncio.get_event_loop_policy().get_event_loop()
            if loop.is_running():
                loop.create_task(shutdown_mcp_clients(_mcp_clients))
                print("--- [atexit] æ¸…ç†ä»»å‹™å·²å‰µå»º (å¾ªç’°é‹è¡Œä¸­) ---")
            else:
                loop.run_until_complete(shutdown_mcp_clients(_mcp_clients))
                print("--- [atexit] æ¸…ç†ä»»å‹™å·²åŒæ­¥åŸ·è¡Œ ---")
        except Exception as cleanup_err:
            print(f"--- [atexit] åŸ·è¡Œç•°æ­¥æ¸…ç†æ™‚å‡ºéŒ¯: {cleanup_err} ---")
            traceback.print_exc()
        finally:
            _mcp_clients = {}
    else:
         print("--- [atexit] ç„¡éœ€æ¸…ç† MCP å®¢æˆ¶ç«¯ ---")

atexit.register(_sync_cleanup)

# --- get_mcp_tools (ä½¿ç”¨ print) ---
async def get_mcp_tools(mcp_name: str) -> List[BaseTool]:
    global _loaded_mcp_tools, _mcp_clients
    if mcp_name in _loaded_mcp_tools:
        # print(f"--- [Lazy Load] ä½¿ç”¨å·²ç·©å­˜çš„ {mcp_name} MCP å·¥å…· ---")
        return _loaded_mcp_tools[mcp_name]

    async with _mcp_init_lock:
        if mcp_name in _loaded_mcp_tools:
            # print(f"--- [Lazy Load] ä½¿ç”¨å·²ç·©å­˜çš„ {mcp_name} MCP å·¥å…· (after lock) ---")
            return _loaded_mcp_tools[mcp_name]

        print(f"--- [Lazy Load] è§¸ç™¼ {mcp_name} MCP å·¥å…·åˆå§‹åŒ– ---")
        client, tools = await initialize_single_mcp(mcp_name)

        _loaded_mcp_tools[mcp_name] = tools
        if client:
             _mcp_clients[mcp_name] = client

        print(f"--- [Lazy Load] {mcp_name} MCP å·¥å…·åˆå§‹åŒ–å®Œæˆä¸¦ç·©å­˜ (æ‰¾åˆ° {len(tools)} å€‹å·¥å…·) ---")
        return tools

# =============================================================================
# æç¤ºè©å®šç¾© (ä¿®æ”¹ AGENT_EXECUTION_PROMPT åŠ å…¥æœ€çµ‚æˆªåœ–æŒ‡ä»¤)
# =============================================================================
# --- é€šç”¨ Rhino/Revit åŸ·è¡Œæç¤º ---
RHINO_AGENT_EXECUTION_PROMPT = SystemMessage(content="""ä½ æ˜¯ä¸€å€‹åš´æ ¼æŒ‰è¨ˆåŠƒåŸ·è¡Œä»»å‹™çš„åŠ©æ‰‹ï¼Œå°ˆé–€ç‚º CAD/BIM ç’°å¢ƒç”ŸæˆæŒ‡ä»¤ã€‚æ¶ˆæ¯æ­·å²ä¸­åŒ…å«äº†ç”¨æˆ¶è«‹æ±‚å’Œä¸€å€‹åˆ†éšæ®µç›®æ¨™çš„è¨ˆåŠƒã€‚
**ä½ çš„æ ¸å¿ƒä»»å‹™ï¼šæ ¹æ“šè¨ˆåŠƒï¼ŒåŸ·è¡Œä¸”åƒ…åŸ·è¡Œä¸‹ä¸€å€‹æœªå®Œæˆçš„æ­¥é©Ÿã€‚åš´ç¦é‡è¤‡å·²å®Œæˆçš„æ­¥é©Ÿã€‚**

**å®šä½ä¸‹ä¸€æ­¥é©Ÿçš„æ¼”ç®—æ³• (å¿…é ˆåš´æ ¼éµå®ˆ):**
1.  **æª¢æŸ¥æ­·å²ç´€éŒ„:** æŸ¥çœ‹æœ€è¿‘çš„å¹¾æ¢æ¶ˆæ¯ã€‚ä½ çš„ä¸»è¦ä¾æ“šæ˜¯æœ€å¾Œä¸€æ¢ `ToolMessage`ã€‚
2.  **åŒ¹é…ä¸Šæ¬¡å‹•ä½œ:** å°‡ `ToolMessage` çš„çµæœèˆ‡ `[ç›®æ¨™éšæ®µè¨ˆåŠƒ]:` ä¸­çš„æ­¥é©Ÿé€²è¡Œæ¯”å°ï¼Œæ‰¾å‡ºå®ƒå°æ‡‰çš„æ˜¯è¨ˆåŠƒä¸­çš„ç¬¬å¹¾å€‹æ­¥é©Ÿã€‚
3.  **ç¢ºå®šä¸‹ä¸€æ­¥:** ç·Šæ¥åœ¨ä¸Šä¸€æ­¥ä¹‹å¾Œçš„é‚£å€‹æ­¥é©Ÿï¼Œå°±æ˜¯ä½ ç¾åœ¨éœ€è¦åŸ·è¡Œçš„**å”¯ä¸€ç›®æ¨™**ã€‚ä¾‹å¦‚ï¼Œå¦‚æœä¸Šä¸€æ­¥æ˜¯è¨ˆåŠƒçš„ç¬¬ 1 æ­¥ï¼Œä½ ç¾åœ¨å°±å¿…é ˆåŸ·è¡Œç¬¬ 2 æ­¥ã€‚
4.  **åˆå§‹æƒ…æ³:** å¦‚æœæ­·å²ç´€éŒ„ä¸­æ²’æœ‰ `ToolMessage` (ä»£è¡¨é€™æ˜¯è¨ˆåŠƒç”Ÿæˆå¾Œçš„ç¬¬ä¸€æ¬¡åŸ·è¡Œ)ï¼Œå‰‡å¾è¨ˆåŠƒçš„ç¬¬ 1 æ­¥é–‹å§‹ã€‚
5.  **éŒ¯èª¤è™•ç†:** å¦‚æœ `ToolMessage` æŒ‡å‡ºä¸Šä¸€æ­¥é©ŸåŸ·è¡Œå¤±æ•—ï¼Œä½ çš„ä»»å‹™æ˜¯åˆ†æéŒ¯èª¤åŸå› ï¼Œä¸¦å˜—è©¦**ä¿®æ­£ä¸¦é‡æ–°åŸ·è¡ŒåŒä¸€å€‹æ­¥é©Ÿ**ã€‚
                                             
**åŸ·è¡Œè¦å‰‡:**                                                                       
1.  **è¦èª¿ç”¨å·¥å…·ä¾†åŸ·è¡Œå‹•ä½œï¼Œè«‹å¿…é ˆç”Ÿæˆ `tool_calls` åœ¨é¦–ä½çš„ AIMessage ä»¥è«‹æ±‚è©²å·¥å…·èª¿ç”¨**ã€‚**ä¸è¦åƒ…ç”¨æ–‡å­—æè¿°ä½ è¦èª¿ç”¨å“ªå€‹å·¥å…·ï¼Œè€Œæ˜¯å¯¦éš›ç”Ÿæˆå·¥å…·èª¿ç”¨æŒ‡ä»¤ã€‚** ä¸€æ¬¡åªç”Ÿæˆä¸€å€‹å·¥å…·èª¿ç”¨è«‹æ±‚ã€‚
2.  **åš´æ ¼çš„å–®æ­¥åŸ·è¡ŒåŸå‰‡ (æ¥µåº¦é‡è¦):**
    * **æ¯æ¬¡å·¥å…·èª¿ç”¨åªèƒ½å®Œæˆè¨ˆåŠƒä¸­çš„ä¸€å€‹éšæ®µç›®æ¨™**ï¼Œçµ•ä¸å¯å˜—è©¦åœ¨å–®æ¬¡å·¥å…·èª¿ç”¨ä¸­å®Œæˆå¤šå€‹æ­¥é©Ÿ
    * **ä»£ç¢¼é•·åº¦é™åˆ¶:** æ¯æ¬¡ç”Ÿæˆçš„ Rhino/Revit ä»£ç¢¼æ‡‰ä¿æŒç°¡æ½”ï¼Œé€šå¸¸ä¸æ‡‰è¶…é 50-80 è¡Œã€‚å¦‚æœæŸå€‹æ­¥é©Ÿéœ€è¦æ›´å¤šä»£ç¢¼ï¼Œè«‹å°‡å…¶æ‹†åˆ†ç‚ºæ›´å°çš„å­æ­¥é©Ÿ
    * **å°ˆæ³¨ç•¶å‰ç›®æ¨™:** åªç”Ÿæˆå®Œæˆç•¶å‰éšæ®µç›®æ¨™æ‰€éœ€çš„æœ€å°‘ä»£ç¢¼ï¼Œä¸è¦æå‰è™•ç†å¾ŒçºŒæ­¥é©Ÿ
    * **ç¯„ä¾‹:** å¦‚æœè¨ˆåŠƒä¸­çš„æ­¥é©Ÿæ˜¯"å‰µå»ºåœ–å±¤çµæ§‹"ï¼Œå‰‡åªå‰µå»ºåœ–å±¤ï¼›å¦‚æœæ­¥é©Ÿæ˜¯"å‰µå»ºç¬¬ä¸€å€‹æ‹±å½¢è‚‹æ¢"ï¼Œå‰‡åªå‰µå»ºä¸€å€‹è‚‹æ¢ï¼Œä¸è¦åŒæ™‚å‰µå»ºå¤šå€‹æˆ–æ·»åŠ å…¶ä»–å…ƒç´ 
3.  åš´æ ¼ç¦æ­¢ä½¿ç”¨ f-string æ ¼å¼åŒ–å­—ä¸²ã€‚è«‹ä½¿ç”¨ `.format()` æˆ– `%` é€²è¡Œå­—ä¸²æ’å€¼ã€‚(æ­¤ç‚º IronPython 2.7 ç’°å¢ƒé™åˆ¶)
4.  **RhinoScript å‡½æ•¸ä½¿ç”¨æ³¨æ„äº‹é …:**
    * **ä»”ç´°æŸ¥é–± rhinoscriptsyntax å’Œ Rhino.Geometry çš„æ­£ç¢ºå‡½æ•¸åç¨±å’Œåƒæ•¸**ï¼Œé¿å…ä½¿ç”¨ä¸å­˜åœ¨çš„å‡½æ•¸
5.  **ä»”ç´°åƒè€ƒå·¥å…·æè¿°æˆ– Mcp æ–‡æª”ç¢ºèªå‡½æ•¸ç”¨æ³•èˆ‡åƒæ•¸æ­£ç¢ºæ€§ï¼Œå¿…é ˆå¯¦éš›ç”Ÿæˆçµæ§‹åŒ–çš„å·¥å…·å‘¼å«æŒ‡ä»¤ã€‚**
6.  **å¤šæ–¹æ¡ˆç®¡ç† (é‡è¦):**
    * ç•¶ç”Ÿæˆå¤šå€‹æ–¹æ¡ˆæ™‚ï¼Œ**æ¯å€‹æ–¹æ¡ˆå¿…é ˆå®Œå…¨ç¨ç«‹**ï¼Œè¦–ç‚ºå–®ç¨çš„ä»»å‹™åºåˆ—è™•ç†
    * **æ–¹æ¡ˆéš”é›¢åŸå‰‡:**
        * **æ¯å€‹æ–¹æ¡ˆå¿…é ˆæœ‰è‡ªå·±çš„é ‚å±¤åœ–å±¤**ï¼Œä½¿ç”¨ `rs.AddLayer("æ–¹æ¡ˆA_æè¿°")` å‰µå»º
        * **åˆ‡æ›æ–¹æ¡ˆå‰å¿…é ˆéš±è—å‰ä¸€æ–¹æ¡ˆçš„åœ–å±¤**ï¼Œä½¿ç”¨ `rs.LayerVisible("å‰ä¸€æ–¹æ¡ˆå", False)`
        * **æ‰€æœ‰ç‰©ä»¶å¿…é ˆæ­£ç¢ºé…ç½®åˆ°å…¶æ‰€å±¬æ–¹æ¡ˆçš„åœ–å±¤**ï¼Œä½¿ç”¨ `rs.CurrentLayer("æ–¹æ¡ˆX_æè¿°::å­åœ–å±¤")`
        * **å®Œæˆæ¯å€‹æ–¹æ¡ˆå¾Œå¿…é ˆæˆªåœ–**ï¼Œå†é–‹å§‹ä¸‹ä¸€å€‹æ–¹æ¡ˆ
    * **é¿å…æ–¹æ¡ˆé–“çš„é‡é«”é‡ç–Š**ï¼Œå¯è€ƒæ…®åœ¨ä¸åŒæ–¹æ¡ˆé–“ä½¿ç”¨åº§æ¨™åç§»
7.  **é‡é«”ç”Ÿæˆç­–ç•¥:**
    * **ç©ºé–“æ“ä½œå„ªå…ˆä½¿ç”¨å¸ƒæ—é‹ç®—**ï¼šä½¿ç”¨ `rs.BooleanUnion()`ã€`rs.BooleanDifference()`ã€`rs.BooleanIntersection()` å‰µé€ è¤‡é›œå½¢æ…‹
    * **å–„ç”¨å¹¾ä½•è®Šæ›**ï¼šä½¿ç”¨æ—‹è½‰ã€ç¸®æ”¾ã€ç§»å‹•ç­‰æ“ä½œèª¿æ•´ç‰©ä»¶å§¿æ…‹ï¼Œå‰µé€ æ›´è±å¯Œçš„ç©ºé–“å±¤æ¬¡
    * **é¿å…ç„¡æ•ˆé‡é«”**ï¼šä¸è¦å‰µå»ºéå°ã€ä½ç½®ä¸åˆç†æˆ–å°ç©ºé–“è¡¨é”ç„¡è²¢ç»çš„é‡é«”
    * **æ³¨æ„ IronPython 2.7 èªæ³•é™åˆ¶**ï¼šRhino 8ä½¿ç”¨IronPython 2.7ï¼Œç¦æ­¢ä½¿ç”¨Python 3ç‰¹æœ‰èªæ³•   
8.  **æ›²é¢é€ å‹ç­–ç•¥:**
        *   **æ›²é¢å‰µå»ºé¡åˆ¥ï¼š**
            *   **æƒæ  (Sweep):**
                *   `rs.AddSweep1(rail_curve_id, shape_curve_ids)`: å°‡å‰–é¢æ›²ç·šåˆ—è¡¨ `shape_curve_ids` æ²¿å–®ä¸€è»Œé“ `rail_curve_id` æƒæ æˆæ›²é¢ã€‚æ³¨æ„å‰–é¢æ›²ç·šçš„æ–¹å‘å’Œé †åºã€‚
                *   `rs.AddSweep2(rail_curve_ids, shape_curve_ids)`: å°‡å‰–é¢æ›²ç·šåˆ—è¡¨ `shape_curve_ids` æ²¿å…©å€‹è»Œé“åˆ—è¡¨ `rail_curve_ids` æƒæ æˆæ›²é¢ã€‚æ³¨æ„å‰–é¢æ›²ç·šçš„æ–¹å‘ã€é †åºåŠèˆ‡è»Œé“çš„æ¥è§¸ã€‚
            *   **æ”¾æ¨£ (Loft):**
                *   `rs.AddLoftSrf(curve_ids, start_pt=None, end_pt=None, type=0, style=0, simplify=0, closed=False)`: åœ¨æœ‰åºçš„æ›²ç·šåˆ—è¡¨ `curve_ids` ä¹‹é–“å‰µå»ºæ”¾æ¨£æ›²é¢ã€‚æ³¨æ„æ›²ç·šæ–¹å‘å’Œæ¥ç¸«é»ã€‚å¯æŒ‡å®šé¡å‹ã€æ¨£å¼ç­‰ã€‚
            *   **ç¶²æ ¼æ›²é¢ (Network Surface):**
                *   `rs.AddNetworkSrf(curve_ids)`: å¾ä¸€çµ„ç›¸äº¤çš„æ›²ç·šç¶²çµ¡ `curve_ids` å‰µå»ºæ›²é¢ã€‚æ‰€æœ‰ U æ–¹å‘æ›²ç·šå¿…é ˆèˆ‡æ‰€æœ‰ V æ–¹å‘æ›²ç·šç›¸äº¤ã€‚
            *   **å¹³é¢æ›²é¢ (Planar Surface):**
                *   `rs.AddPlanarSrf(curve_ids)`: å¾ä¸€å€‹æˆ–å¤šå€‹å°é–‰çš„*å¹³é¢*æ›²ç·šåˆ—è¡¨ `curve_ids` å‰µå»ºå¹³é¢æ›²é¢ã€‚æ›²ç·šå¿…é ˆå…±é¢ä¸”å°é–‰ã€‚
        *   **å¯¦é«”å‰µå»ºé¡åˆ¥ï¼š**
            *   **æ“ å‡º (Extrusion):**
                *   `rs.ExtrudeCurve(curve_id, path_curve_id)`: å°‡è¼ªå»“ç·š `curve_id` æ²¿è·¯å¾‘æ›²ç·š `path_curve_id` æ“ å‡ºæˆæ›²é¢ã€‚
                *   `rs.ExtrudeCurveStraight(curve_id, start_point, end_point)` æˆ– `rs.ExtrudeCurveStraight(curve_id, direction_vector)`: å°‡æ›²ç·š `curve_id` æ²¿ç›´ç·šæ“ å‡ºæŒ‡å®šè·é›¢å’Œæ–¹å‘ã€‚
                *   `rs.ExtrudeCurveTapered(curve_id, distance, direction, base_point, angle)`: å°‡æ›²ç·š `curve_id` æ²¿ `direction` æ–¹å‘æ“ å‡º `distance` è·é›¢ï¼ŒåŒæ™‚ä»¥ `base_point` ç‚ºåŸºæº–ã€æŒ‰ `angle` è§’åº¦é€²è¡ŒéŒåŒ–ã€‚
                *   `rs.ExtrudeSurface(surface_id, path_curve_id, cap=True/False)`: å°‡æ›²é¢ `surface_id` æ²¿è·¯å¾‘æ›²ç·š `path_curve_id` æ“ å‡ºæˆå¯¦é«”æˆ–é–‹æ”¾å½¢ç‹€ï¼Œå¯é¸æ˜¯å¦å°å£ (`cap`)ã€‚
        *   **å°é–‰æ€§æª¢æŸ¥èˆ‡ä¿®æ­£ (æ¥µåº¦é‡è¦):**
            *   å‰µå»ºæ›²é¢å¾Œï¼Œ**å¿…é ˆ**ä½¿ç”¨ `rs.IsPolysurface(object_id)` å’Œ `rs.IsClosed(object_id)` æª¢æŸ¥ç‰©ä»¶æ˜¯å¦ç‚ºå°é–‰å¤šé‡æ›²é¢
            *   å°æ–¼é–‹æ”¾æ›²é¢ï¼Œå˜—è©¦ä»¥ä¸‹ä¿®æ­£æ–¹æ³•ï¼š
                1. ä½¿ç”¨ `rs.CapPlanarHoles(surface_id)` å°é–‰å¹³é¢é–‹å£
                2. ä½¿ç”¨ `rs.JoinSurfaces([surface_id1, surface_id2, ...], delete_input=True)` æ¥åˆç›¸é„°æ›²é¢
                3. ç¢ºä¿æ“ å‡ºæ“ä½œæ™‚ä½¿ç”¨ `cap=True` åƒæ•¸ä¾†è‡ªå‹•å°é–‰ç«¯é¢
            *   **åœ¨æ¯æ¬¡å‰µå»ºæ›²é¢ç‰©ä»¶å¾Œï¼Œå¿…é ˆé©—è­‰å…¶å°é–‰æ€§ã€‚å¦‚æœä¸å°é–‰ï¼Œæ‡‰ç«‹å³æ¡å–ä¿®æ­£æªæ–½ã€‚**
            *   å°æ–¼è¤‡é›œé€ å‹ï¼Œå„ªå…ˆä½¿ç”¨èƒ½ç›´æ¥ç”Ÿæˆå°é–‰å¯¦é«”çš„æ–¹æ³•ï¼ˆå¦‚å¾å°é–‰æ›²ç·šæ“ å‡ºï¼‰ï¼Œè€Œéä¾è³´å¾ŒçºŒæ¥åˆ
9.  **Rhino åœ–å±¤ç®¡ç† (é‡è¦):** ç•¶ç”Ÿæˆ Rhino ä»£ç¢¼æ™‚ï¼š
        *   å¦‚æœç•¶å‰éšæ®µç›®æ¨™**æ˜ç¢ºè¦æ±‚**åœ¨ç‰¹å®šåœ–å±¤ä¸Šæ“ä½œï¼Œ**å¿…é ˆ**åœ¨ç›¸é—œæ“ä½œï¼ˆå¦‚å‰µå»ºç‰©ä»¶ï¼‰**ä¹‹å‰**åŒ…å« `rs.CurrentLayer('ç›®æ¨™åœ–å±¤åç¨±')` æŒ‡ä»¤ã€‚
        *   å¦‚æœç›®æ¨™æ¶‰åŠæ§åˆ¶åœ–å±¤å¯è¦‹æ€§ï¼ˆä¾‹å¦‚ï¼Œæº–å‚™æˆªåœ–ï¼‰ï¼Œ**å¿…é ˆ**åŒ…å« `rs.LayerVisible('åœ–å±¤å', True/False)` æŒ‡ä»¤ã€‚
    *   **æˆªåœ–å‰çš„åœ–å±¤æº–å‚™ï¼šåœ¨èª¿ç”¨ `capture_focused_view` é€²è¡Œæˆªåœ–ä¹‹å‰ï¼Œå¿…é ˆç¢ºä¿åªæœ‰èˆ‡ç•¶å‰æˆªåœ–ç›®æ¨™ç›´æ¥ç›¸é—œçš„åœ–å±¤æ˜¯å¯è¦‹çš„ã€‚æ‰€æœ‰å…¶ä»–ä¸ç›¸é—œçš„åœ–å±¤ï¼Œç‰¹åˆ¥æ˜¯é‚£äº›å¯èƒ½é®æ“‹ç›®æ¨™è¦–åœ–çš„åœ–å±¤ï¼ˆä¾‹å¦‚ï¼Œå…¶ä»–æ¨“å±¤ã€å…¶ä»–è¨­è¨ˆæ–¹æ¡ˆçš„é ‚å±¤åœ–å±¤ã€è¼”åŠ©ç·šåœ–å±¤ç­‰ï¼‰ï¼Œéƒ½æ‡‰ä½¿ç”¨ `rs.LayerVisible('åœ–å±¤å', False)` é€²è¡Œéš±è—ã€‚ ä½¿ç”¨é€è¦–/å…©é»é€è¦–æˆªåœ–æ™‚é ˆç¢ºä¿ç›¸é—œåœ–å±¤éƒ½æœ‰é–‹å•Ÿ**
10. **æœ€çµ‚æ­¥é©Ÿ (Rhino/Revit):**
    *   å°æ–¼ Rhino/Revit ä»»å‹™ï¼Œæ¯ç•¶å®Œæˆä¸€å€‹æ–¹æ¡ˆæˆ–ä¸€å€‹æ¨“å±¤å°±**å¿…é ˆ**è¦èª¿ç”¨ `capture_focused_view` å·¥å…·ä¾†æˆªå–ç•«é¢ã€‚æˆªåœ–æ™‚å¦‚æœè¨­å®šç›¸æ©Ÿä½ç½®ï¼Œç¢ºä¿(`target_position`)ä½æ–¼æ–¹æ¡ˆçš„ä¸­å¿ƒé»ã€‚
    *   **åƒ…ç•¶æ¶ˆæ¯æ­·å²æ¸…æ¥šåœ°è¡¨æ˜è¨ˆåŠƒä¸­çš„æœ€å¾Œéšæ®µç›®æ¨™å·²æˆåŠŸåŸ·è¡Œ**ï¼Œä½ æ‰èƒ½ç”Ÿæˆæ–‡æœ¬å›å¾©ï¼š`å…¨éƒ¨ä»»å‹™å·²å®Œæˆ` ä»¥çµæŸæ•´å€‹ä»»å‹™ã€‚
11. å¦‚æœç•¶å‰éšæ®µç›®æ¨™ä¸éœ€è¦å·¥å…·å³å¯å®Œæˆï¼ˆä¾‹å¦‚ï¼Œåƒ…éœ€ç¸½çµä¿¡æ¯ï¼‰ï¼Œè«‹ç”Ÿæˆèªªæ˜æ€§çš„è‡ªç„¶èªè¨€å›æ‡‰ã€‚
12.è‹¥é‡å·¥å…·éŒ¯èª¤ï¼Œåˆ†æéŒ¯èª¤åŸå›  (å°¤å…¶æ˜¯ä»£ç¢¼åŸ·è¡ŒéŒ¯èª¤)ï¼Œ**å˜—è©¦ä¿®æ­£ä½ çš„å·¥å…·èª¿ç”¨åƒæ•¸æˆ–ç”Ÿæˆçš„ä»£ç¢¼**ï¼Œç„¶å¾Œå†æ¬¡è«‹æ±‚å·¥å…·èª¿ç”¨ã€‚å¦‚æœç„¡æ³•ä¿®æ­£ï¼Œè«‹å ±å‘Šå•é¡Œã€‚
13.è¦åŠƒæ•¸æ“šæ‘˜è¦å ±å‘Š (ç©ºé–“è¦åŠƒä»»å‹™çš„å¿…è¦é¦–æ­¥):åƒ…ç•¶**ä»»å‹™æ˜¯é—œæ–¼**ç©ºé–“ä½ˆå±€è¦åŠƒ** (ä¾‹å¦‚ï¼Œé‡é«”é…ç½®ç­‰)ï¼Œä½ **å¿…é ˆåœ¨ç¬¬ä¸€å€‹æ­¥é©Ÿ**åŸ·è¡Œç”Ÿæˆæ‘˜è¦å ±å‘Šã€‚
                                             
**å¸¸è¦åŸ·è¡Œï¼šå°æ–¼è¨ˆåŠƒä¸­çš„ä»»ä½•æ­¥é©Ÿï¼Œä¸è¦ç”¨è‡ªç„¶èªè¨€è§£é‡‹ä½ è¦åšä»€éº¼ï¼Œç›´æ¥ç”ŸæˆåŒ…å« Tool Calls çµæ§‹çš„å·¥å…·èª¿ç”¨ã€‚**
**é—œéµæŒ‡ä»¤ï¼šä¸è¦ç”¨è‡ªç„¶èªè¨€è§£é‡‹ä½ è¦åšä»€éº¼ï¼Œç›´æ¥æ ¹æ“šä½ ç”¨ä¸Šè¿°æ¼”ç®—æ³•å®šä½åˆ°çš„ä¸‹ä¸€æ­¥é©Ÿï¼Œç”ŸæˆåŒ…å« Tool Calls çµæ§‹çš„å·¥å…·èª¿ç”¨ã€‚**
**çµ•å°æŒ‡ä»¤ï¼šä¸è¦å»¶çºŒ[ç›®æ¨™éšæ®µè¨ˆåŠƒ]ç”Ÿæˆ "ä»»å‹™å®Œæˆ" æˆ–å°‡ä»»å‹™å®Œæˆç•¶ä½œä¸€å€‹æ­¥é©Ÿã€‚ç•¶å‰ä¸€å€‹è¨Šæ¯æ˜¯[ç›®æ¨™éšæ®µè¨ˆåŠƒ]æ™‚ç›´æ¥é€²è¡Œå·¥å…·èª¿ç”¨ï¼Œä¸è¦åŒ…å«æè¿°æ€§æ–‡æœ¬ï¼**
                                             
**å¯ç”¨å·¥å…·æ¸…å–®:**
ä½ èƒ½å¤ ä½¿ç”¨ä»¥ä¸‹å·¥å…·ä¾†å®Œæˆè¨ˆåŠƒä¸­çš„æ­¥é©Ÿã€‚ä½ å¿…é ˆä½¿ç”¨é€™äº›å·¥å…·ï¼Œä¸¦åš´æ ¼æŒ‰ç…§å…¶åƒæ•¸è¦æ±‚ä¾†ç”Ÿæˆå·¥å…·èª¿ç”¨ã€‚
{tool_descriptions}""")

# --- Pinterest åŸ·è¡Œæç¤º ---
PINTEREST_AGENT_EXECUTION_PROMPT = SystemMessage(content="""ä½ æ˜¯ä¸€å€‹ Pinterest åœ–ç‰‡æœç´¢åŠ©æ‰‹ã€‚
ä½ çš„ä»»å‹™æ˜¯ï¼š
1.  åˆ†æç”¨æˆ¶è«‹æ±‚å’Œè¨ˆåŠƒï¼ˆå¦‚æœæœ‰çš„è©±ï¼‰ã€‚
2.  å¦‚æœè¨ˆåŠƒæŒ‡ç¤ºèª¿ç”¨ `pinterest_search_and_download` å·¥å…·ï¼Œè«‹ç«‹å³ç”Ÿæˆè©²å·¥å…·èª¿ç”¨ã€‚
3.  å·¥å…·åƒæ•¸æ‡‰åŒ…å«å¾ç”¨æˆ¶è«‹æ±‚ä¸­æå–çš„ `keyword` (æœç´¢é—œéµè©) å’Œå¯é¸çš„ `limit` (ä¸‹è¼‰æ•¸é‡)ã€‚
4.  **æœ€çµ‚æ­¥é©Ÿï¼š** åœ¨å·¥å…·æˆåŠŸåŸ·è¡Œä¸¦è¿”å›åœ–ç‰‡è·¯å¾‘å¾Œï¼Œä½ çš„æœ€çµ‚å›æ‡‰æ‡‰è©²æ˜¯ï¼šã€Œåœ–ç‰‡æœç´¢å’Œä¸‹è¼‰å®Œæˆã€ã€‚ä»¥çµæŸä»»å‹™ã€‚
è«‹ç›´æ¥ç”Ÿæˆå·¥å…·èª¿ç”¨æˆ–æœ€çµ‚å®Œæˆè¨Šæ¯ã€‚""")

# --- OSM åŸ·è¡Œæç¤º ---
OSM_AGENT_EXECUTION_PROMPT = SystemMessage(content="""ä½ æ˜¯ä¸€å€‹ OpenStreetMap åœ°åœ–åŠ©æ‰‹ã€‚
ä½ çš„ä»»å‹™æ˜¯ï¼š
1.  åˆ†æç”¨æˆ¶è«‹æ±‚å’Œè¨ˆåŠƒï¼ˆå¦‚æœæœ‰çš„è©±ï¼‰ã€‚
2.  å¦‚æœè¨ˆåŠƒæŒ‡ç¤ºèª¿ç”¨ `geocode_and_screenshot` å·¥å…·ï¼Œè«‹ç«‹å³ç”Ÿæˆè©²å·¥å…·èª¿ç”¨ã€‚
3.  **åœ°å€/åº§æ¨™è™•ç† (geocode_and_screenshot):**
        *   **æª¢æŸ¥ä½¿ç”¨è€…è¼¸å…¥**ï¼šæŸ¥çœ‹åˆå§‹è«‹æ±‚æˆ–ç•¶å‰ç›®æ¨™æ˜¯å¦åŒ…å«æ˜ç¢ºçš„**ç¶“ç·¯åº¦åº§æ¨™**ï¼ˆä¾‹å¦‚ "2X.XXX 1XX.XXX" æˆ–é¡ä¼¼æ ¼å¼ï¼‰ã€‚
        *   **å¦‚æœæ‰¾åˆ°åº§æ¨™**ï¼šç›´æ¥å°‡**åº§æ¨™å­—ä¸² "ç·¯åº¦,ç¶“åº¦"** (ä¾‹å¦‚ "2X.XXX 1XX.XXX") ä½œç‚º `address` åƒæ•¸çš„å€¼å‚³éçµ¦ `geocode_and_screenshot` å·¥å…·ã€‚**ä¸è¦**å˜—è©¦å°‡åº§æ¨™è½‰æ›æˆåœ°å€ã€‚
        *   **å¦‚æœåªæ‰¾åˆ°åœ°å€**ï¼šè«‹**å˜—è©¦å°‡å…¶ç°¡åŒ–**ï¼Œä¾‹å¦‚ "è™Ÿç¢¼, è¡—é“åç¨±, åŸå¸‚, åœ‹å®¶" å†å‚³éçµ¦ `address` åƒæ•¸ã€‚å¦‚æœæŒçºŒåœ°ç†ç·¨ç¢¼å¤±æ•—ï¼Œå¯ä»¥å˜—è©¦é€²ä¸€æ­¥ç°¡åŒ–ã€‚
4.  **æœ€çµ‚æ­¥é©Ÿï¼š** åœ¨å·¥å…·æˆåŠŸåŸ·è¡Œä¸¦è¿”å›æˆªåœ–è·¯å¾‘å¾Œï¼Œä½ çš„æœ€çµ‚å›æ‡‰æ‡‰è©²æ˜¯ï¼šã€Œåœ°åœ–æˆªåœ–å·²å®Œæˆã€ã€‚
è«‹ç›´æ¥ç”Ÿæˆå·¥å…·èª¿ç”¨æˆ–æœ€çµ‚å®Œæˆè¨Šæ¯ã€‚""")


# --- Router Prompt (MODIFIED) ---
ROUTER_PROMPT = """ä½ æ˜¯ä¸€å€‹æ™ºèƒ½è·¯ç”±ä»£ç†ã€‚æ ¹æ“šä½¿ç”¨è€…çš„**åˆå§‹è«‹æ±‚æ–‡æœ¬**ï¼Œåˆ¤æ–·æ‡‰å°‡ä»»å‹™åˆ†é…çµ¦å“ªå€‹å°ˆæ¥­é ˜åŸŸçš„ä»£ç†ã€‚
ç›®å‰å¯ç”¨çš„ä»£ç†æœ‰ï¼š
- 'revit': ä¸»è¦è™•ç†èˆ‡ Revit å»ºç¯‰è³‡è¨Šæ¨¡å‹ç›¸é—œçš„è«‹æ±‚ã€‚
- 'rhino': ä¸»è¦è™•ç†èˆ‡ Rhino 3D æ¨¡å‹ç›¸é—œçš„è«‹æ±‚ã€‚
- 'pinterest': ä¸»è¦è™•ç†èˆ‡ Pinterest åœ–ç‰‡æœç´¢å’Œä¸‹è¼‰ç›¸é—œçš„è«‹æ±‚ã€‚
- 'osm': ä¸»è¦è™•ç†èˆ‡ OpenStreetMap åœ°åœ–ç›¸é—œçš„è«‹æ±‚ã€‚

åˆ†æä»¥ä¸‹**åˆå§‹ä½¿ç”¨è€…è«‹æ±‚æ–‡æœ¬**ï¼Œä¸¦æ±ºå®šæœ€é©åˆè™•ç†æ­¤è«‹æ±‚çš„ä»£ç†ã€‚ç”Ÿæˆæ¨¡å‹çš„ä»»å‹™ä»¥rhinoç‚ºä¸»ï¼Œé™¤éç‰¹åˆ¥æŒ‡å®šç”¨revitã€‚
ä½ çš„å›æ‡‰å¿…é ˆæ˜¯ 'revit', 'rhino', 'pinterest' æˆ– 'osm'ã€‚è«‹åªå›æ‡‰ç›®æ¨™ä»£ç†çš„åç¨±ã€‚

åˆå§‹ä½¿ç”¨è€…è«‹æ±‚æ–‡æœ¬ï¼š
"{user_request_text}"
"""

PLAN_PREFIX = "[ç›®æ¨™éšæ®µè¨ˆåŠƒ]:\n"

# --- Fallback Agent Prompt ---
FALLBACK_PROMPT = SystemMessage(content="""ä½ æ˜¯ä¸€å€‹è£œæ•‘èˆ‡é©—è­‰åŠ©æ‰‹ã€‚ä¸»è¦åŠ©æ‰‹å¯èƒ½å·²å®Œæˆå…¶æ­¥é©Ÿã€å¡ä½äº†ï¼Œæˆ–è²ç¨±ä»»å‹™å·²å®Œæˆã€‚
    ä½ çš„ä»»å‹™æ˜¯ï¼š
    1.  ä»”ç´°åˆ†ææ¶ˆæ¯æ­·å²ï¼Œç‰¹åˆ¥æ˜¯ `[ç›®æ¨™éšæ®µè¨ˆåŠƒ]:` å’Œæœ€è¿‘å¹¾æ¢ä¸»è¦åŠ©æ‰‹çš„å›æ‡‰ã€‚
    2.  **åˆ†æä¸»è¦åŠ©æ‰‹ç‹€æ…‹**ï¼š
        *   å¦‚æœä¸»è¦åŠ©æ‰‹çš„æœ€å¾Œä¸€æ¢å›æ‡‰**ä¸æ˜¯å·¥å…·èª¿ç”¨**ï¼Œè€Œæ˜¯æè¿°æ€§æ–‡æœ¬ï¼ˆä¾‹å¦‚ "æ­£åœ¨åŸ·è¡Œéšæ®µ X..." æˆ–é¡ä¼¼çš„å°è©±ï¼‰ï¼Œé€™é€šå¸¸è¡¨ç¤ºä¸»è¦åŠ©æ‰‹**å¡ä½äº†**æˆ–è€…æœªèƒ½æŒ‰é æœŸç”Ÿæˆå·¥å…·èª¿ç”¨ã€‚
    3.  **é©—è­‰å®Œæˆç‹€æ…‹ (å¦‚æœä¸»è¦åŠ©æ‰‹è²ç¨±å®Œæˆæˆ–æ­·å²è¡¨æ˜å¯èƒ½å·²åˆ°æœ€å¾Œéšæ®µ)**ï¼š
        *   æŸ¥çœ‹ `[ç›®æ¨™éšæ®µè¨ˆåŠƒ]:`ï¼Œè­˜åˆ¥å‡ºè¨ˆåŠƒä¸­çš„**æœ€å¾Œä¸€å€‹éšæ®µç›®æ¨™**ã€‚æª¢æŸ¥æœ€è¿‘çš„æ¶ˆæ¯æ­·å²ï¼Œè«‹ç¨ç«‹åˆ¤æ–·é€™å€‹**æœ€å¾Œçš„éšæ®µç›®æ¨™æ˜¯å¦å·²ç¶“æˆåŠŸåŸ·è¡Œå®Œç•¢**ã€‚
    4.  **ç¢ºå®šä¸‹ä¸€æ­¥**ï¼š
        *   å¦‚æœæ ¹æ“šä¸Šè¿°é©—è­‰ï¼Œè¨ˆåŠƒä¸­çš„**æœ€å¾Œä¸€å€‹éšæ®µç›®æ¨™ç¢ºå¯¦å·²æˆåŠŸåŸ·è¡Œ**ï¼Œè«‹**åªè¼¸å‡º**æ–‡æœ¬æ¶ˆæ¯ï¼š`[FALLBACK_CONFIRMED_COMPLETION]`ã€‚
        *   å¦‚æœä¸»è¦åŠ©æ‰‹**å¡ä½äº†**ï¼ˆå¦‚ç¬¬ 2 é»æ‰€è¿°ï¼‰ï¼Œæˆ–è€…ä»»å‹™**æœªå®Œæˆ** (ä¾‹å¦‚ï¼Œæœ€å¾Œçš„è¨ˆåŠƒæ­¥é©Ÿæœªå®Œæˆï¼Œæˆ–è€…é‚„æœ‰æ›´æ—©çš„è¨ˆåŠƒæ­¥é©Ÿæœªå®Œæˆä¸”ä½ å¯ä»¥è­˜åˆ¥å‡ºä¾†)ï¼Œä¸¦ä¸”ä½ å¯ä»¥æ ¹æ“šè¨ˆåŠƒå’Œæ­·å²ç¢ºå®šä¸‹ä¸€å€‹**æ‡‰è©²åŸ·è¡Œçš„éšæ®µç›®æ¨™**ï¼Œè«‹**ç”ŸæˆåŸ·è¡Œè©²ç›®æ¨™æ‰€éœ€çš„ `tool_calls`**ã€‚ç›´æ¥è¼¸å‡ºåŒ…å«å·¥å…·èª¿ç”¨çš„ AIMessageã€‚**å„ªå…ˆå˜—è©¦å¾è¨ˆåŠƒä¸­æ‰¾åˆ°ä¸‹ä¸€å€‹æ‡‰è©²åŸ·è¡Œçš„æ­¥é©Ÿä¸¦ç‚ºå…¶ç”Ÿæˆå·¥å…·èª¿ç”¨ã€‚**
        *   å¦‚æœä»»å‹™**æœªå®Œæˆ**ï¼Œä¸”ä½ ç„¡æ³•æ ¹æ“šç¾æœ‰ä¿¡æ¯ç¢ºå®šä¸‹ä¸€æ­¥ã€ç„¡æ³•æ¢å¾©æµç¨‹ï¼ˆä¾‹å¦‚ï¼Œç„¡æ³•è­˜åˆ¥è¨ˆåŠƒçš„æœ€å¾Œä¸€æ­¥ï¼Œæˆ–ç„¡æ³•åˆ¤æ–·å…¶æ˜¯å¦å®Œæˆï¼Œæˆ–ç„¡æ³•ç‚ºå¡ä½çš„åŠ©æ‰‹æ‰¾åˆ°è§£æ±ºæ–¹æ¡ˆï¼‰ï¼Œè«‹**åªè¼¸å‡º**æ–‡æœ¬æ¶ˆæ¯ï¼š`[FALLBACK_CANNOT_RECOVER]`ã€‚

   **é—œéµï¼šä¸è¦é‡è¤‡ä¸»è¦åŠ©æ‰‹å‰›å‰›å®Œæˆçš„æ­¥é©Ÿã€‚å°ˆæ³¨æ–¼æœªå®Œæˆçš„ç›®æ¨™æˆ–é©—è­‰æœ€çµ‚ç‹€æ…‹ã€‚å¦‚æœä¸»è¦åŠ©æ‰‹æ˜é¡¯å¡åœ¨æŸå€‹æè¿°æ€§æ–‡æœ¬è€Œæœªç”Ÿæˆå·¥å…·èª¿ç”¨ï¼Œä½ çš„é¦–è¦ä»»å‹™æ˜¯æ ¹æ“šè¨ˆåŠƒæ¨æ–·ä¸¦ç”Ÿæˆæ­£ç¢ºçš„å·¥å…·èª¿ç”¨ã€‚**
   
   æ¶ˆæ¯æ­·å²:
   {relevant_history}
   """)

# =============================================================================
# è¼”åŠ©å‡½æ•¸ï¼šåŸ·è¡Œå·¥å…· (ä¿®æ”¹ä»¥è™•ç† Pinterest ä¸‹è¼‰è·¯å¾‘)
# =============================================================================
async def execute_tools(agent_action: AIMessage, selected_tools: List[BaseTool]) -> List[ToolMessage]:
    """åŸ·è¡Œ AI Message ä¸­çš„å·¥å…·èª¿ç”¨ï¼Œè™•ç† capture_focused_view å’Œ pinterest download è¿”å›ï¼Œä¸¦ç¢ºä¿ ToolMessage content éç©ºå­—ä¸²ã€‚"""
    tool_messages = []
    if not agent_action.tool_calls:
        return tool_messages
    name_to_tool_map = {tool.name: tool for tool in selected_tools}
    print(f"    æº–å‚™åŸ·è¡Œ {len(agent_action.tool_calls)} å€‹å·¥å…·èª¿ç”¨...")
    for tool_call in agent_action.tool_calls:
        tool_name = tool_call.get("name")
        tool_args = tool_call.get("args", {})
        tool_call_id = tool_call.get("id")
        print(f"      >> èª¿ç”¨å·¥å…·: {tool_name} (ID: {tool_call_id})")

        tool_to_use = name_to_tool_map.get(tool_name)
        if not tool_to_use:
            error_msg = f"éŒ¯èª¤ï¼šæ‰¾ä¸åˆ°åç‚º '{tool_name}' çš„å·¥å…·ã€‚"
            print(f"      !! {error_msg}")
            tool_messages.append(ToolMessage(content=error_msg, tool_call_id=tool_call_id, name=tool_name))
            continue

        observation_str = f"[æœªæˆåŠŸåŸ·è¡Œå·¥å…· {tool_name}]"
        final_content = "UNEXPECTED_TOOL_EXECUTION_FAILURE"
        observation = None

        try:
            # --- åƒæ•¸è™•ç† (ä¿æŒä¸è®Š) ---
            if not isinstance(tool_args, dict):
                 try:
                     tool_args_dict = json.loads(str(tool_args)) if isinstance(tool_args, str) and str(tool_args).strip().startswith('{') else {"input": tool_args}
                 except json.JSONDecodeError:
                     tool_args_dict = {"input": tool_args}
            else:
                 tool_args_dict = tool_args

            # --- èª¿ç”¨å·¥å…· (ainvoke) ---
            print(f"        èª¿ç”¨ {tool_name}.ainvoke...")
            observation = await tool_to_use.ainvoke(tool_args_dict, config=None)
            print(f"        {tool_name}.ainvoke èª¿ç”¨å®Œæˆã€‚è§€å¯Ÿå€¼é¡å‹: {type(observation).__name__}")

            # --- è½‰æ› observation ç‚ºå­—ä¸² ---

            # --- è™•ç† capture_viewport è¿”å› (ä¿æŒä¸è®Š) ---
            if tool_name == "capture_focused_view" and isinstance(observation, str):
                if observation.startswith("[Error]"):
                    final_content = f"[Error: Viewport Capture Failed]: {observation}"
                    print(f"      !! å·¥å…· '{tool_name}' è¿”å›éŒ¯èª¤ä¿¡æ¯: {observation}")
                else:
                    final_content = f"[IMAGE_FILE_PATH]:{observation}"
                    print(f"      << å·¥å…· '{tool_name}' è¿”å›æ–‡ä»¶è·¯å¾‘å­—ç¬¦ä¸²: {observation}")

            # --- è™•ç† pinterest_search_and_download è¿”å› (MODIFIED to return JSON list of paths) ---
            elif tool_name == "pinterest_search_and_download" and isinstance(observation, list):
                 print(f"      << å·¥å…· '{tool_name}' è¿”å›åˆ—è¡¨ã€‚æ­£åœ¨è§£æä¸‹è¼‰è·¯å¾‘...")
                 try:
                     print(f"         DEBUG: Raw observation list received:\n{json.dumps(observation, indent=2, ensure_ascii=False)}")
                 except Exception as json_e:
                     print(f"         DEBUG: Could not JSON dump observation: {json_e}")
                     print(f"         DEBUG: Raw observation list (repr): {repr(observation)}")

                 download_paths = []
                 full_text_output = []
                 expected_prefix = "ä¿å­˜ä½ç½®: " # ä½¿ç”¨ç°¡é«”ä¸­æ–‡å‰ç¶´

                 for text_item in observation:
                     if isinstance(text_item, str):
                         full_text_output.append(text_item)
                         if text_item.startswith(expected_prefix):
                             path = text_item.split(expected_prefix, 1)[1].strip()
                             if path and os.path.exists(path): # <<< ADDED: Check if path exists >>>
                                 print(f"         æå–åˆ°æœ‰æ•ˆè·¯å¾‘: {path}")
                                 download_paths.append(path)
                             elif path:
                                 print(f"         è­¦å‘Š: å¾ '{text_item}' æå–çš„è·¯å¾‘ä¸å­˜åœ¨: {path}")
                             else:
                                 print(f"         è­¦å‘Š: å¾ '{text_item}' æå–çš„è·¯å¾‘ç‚ºç©ºã€‚")
                     else:
                         print(f"         è­¦å‘Š: è§€å¯Ÿåˆ—è¡¨ä¸­çš„é …ç›®ä¸æ˜¯é æœŸçš„å­—ä¸²: {type(text_item)} - {repr(text_item)}")
                         full_text_output.append(str(text_item))

                 print(f"         æ‰¾åˆ° {len(download_paths)} å€‹æœ‰æ•ˆä¸‹è¼‰è·¯å¾‘ã€‚")
                 if download_paths:
                     # <<< MODIFIED: Return JSON list of paths >>>
                     try:
                         final_content = json.dumps({"downloaded_paths": download_paths})
                         print(f"         è¿”å› JSON åˆ—è¡¨: {final_content}")
                     except Exception as json_e:
                         print(f"         !! JSON åºåˆ—åŒ–ä¸‹è¼‰è·¯å¾‘åˆ—è¡¨æ™‚å‡ºéŒ¯: {json_e}")
                         final_content = "[Error serializing download paths]"
                     # <<< END MODIFIED >>>
                 else:
                     failure_mentioned = any("å¤±è´¥" in t or "failed" in t.lower() for t in full_text_output)
                     if failure_mentioned:
                         final_content = "\n".join(full_text_output) if full_text_output else "Pinterest tool ran with download errors, no valid paths reported."
                     else:
                         final_content = "\n".join(full_text_output) if full_text_output else "Pinterest tool ran but no valid download paths found."
                     print(f"         æœªæ‰¾åˆ°æœ‰æ•ˆä¸‹è¼‰è·¯å¾‘ï¼Œè¿”å›æ–‡æœ¬è¼¸å‡º: {final_content[:100]}...")

            # --- è™•ç† bytes (ä¿æŒä¸è®Š) ---
            elif isinstance(observation, bytes):
                try:
                    observation_str = observation.decode('utf-8', errors='replace')
                    print(f"      << å·¥å…· '{tool_name}' è¿”å› bytesï¼Œå·²è§£ç¢¼ã€‚")
                except Exception as decode_err:
                    observation_str = f"[Error Decoding Bytes: {decode_err}]"
                    print(f"      !! å·¥å…· '{tool_name}' è¿”å› bytesï¼Œè§£ç¢¼å¤±æ•—: {decode_err}")
                final_content = observation_str if observation_str else "DECODED_EMPTY_STRING"

            # --- è™•ç† dict/list (æ’é™¤ capture_viewport å’Œ pinterest) ---
            elif isinstance(observation, (dict, list)):
                if isinstance(observation, list) and not observation:
                     error_msg = f"å·¥å…· '{tool_name}' çš„ ainvoke è¿”å›äº†ç©ºåˆ—è¡¨ `[]`ã€‚é€™å¯èƒ½è¡¨ç¤º langchain-mcp-adapters åœ¨è™•ç†å·¥å…·éŸ¿æ‡‰æ™‚å…§éƒ¨å‡ºéŒ¯ï¼Œæˆ–è€…å·¥å…·æœ¬èº«æœªæŒ‰é æœŸè¿”å› (æª¢æŸ¥å·¥å…·å¯¦ç¾)ã€‚"
                     print(f"      !! {error_msg}")
                     final_content = "ADAPTER_RETURNED_EMPTY_LIST"
                else:
                    try:
                        observation_str = json.dumps(observation, ensure_ascii=False, indent=2)
                        print(f"      << å·¥å…· '{tool_name}' è¿”å›æ™®é€š dict/listï¼Œå·²åºåˆ—åŒ–ç‚º JSON å­—ä¸²ã€‚")
                    except TypeError as json_err:
                        observation_str = f"[Error JSON Serializing Result: {json_err}] å›é€€åˆ° str(): {str(observation)}"
                        print(f"      !! å·¥å…· '{tool_name}' è¿”å› dict/listï¼ŒJSON åºåˆ—åŒ–å¤±æ•—: {json_err}ã€‚å›é€€åˆ° str()")
                    except Exception as ser_err:
                        observation_str = f"[Error Serializing Result: {ser_err}]"
                        print(f"      !! å·¥å…· '{tool_name}' è¿”å› dict/listï¼Œåºåˆ—åŒ–æ™‚ç™¼ç”ŸæœªçŸ¥éŒ¯èª¤: {ser_err}")
                    final_content = observation_str

            # --- è™•ç†å…¶ä»–é¡å‹ (ä¿æŒä¸è®Š) ---
            else:
                try:
                    temp_str = str(observation)
                    if temp_str == "[]":
                         print(f"      !! å·¥å…· '{tool_name}' è¿”å›å€¼ string åŒ–å¾Œç‚º '[]'ï¼Œå¯èƒ½è¡¨ç¤ºéŒ¯èª¤æˆ–ç©ºåˆ—è¡¨ã€‚åŸå§‹é¡å‹: {type(observation).__name__}")
                         observation_str = "TOOL_RETURNED_EMPTY_LIST_STR"
                    elif temp_str == "":
                        observation_str = "EMPTY_TOOL_RESULT"
                        print(f"      << å·¥å…· '{tool_name}' è¿”å›ç©ºå­—ä¸²ï¼Œå·²æ›¿æ›ç‚ºä½”ä½ç¬¦ã€‚")
                    elif observation is None:
                        observation_str = "NONE_TOOL_RESULT"
                        print(f"      << å·¥å…· '{tool_name}' è¿”å› Noneï¼Œå·²æ›¿æ›ç‚ºä½”ä½ç¬¦ã€‚")
                    else:
                        observation_str = temp_str
                        print(f"      << å·¥å…· '{tool_name}' è¿”å›å…¶ä»–é¡å‹ ({type(observation).__name__})ï¼Œå·²ä½¿ç”¨ str() è½‰æ›ã€‚")
                except Exception as str_conv_err:
                     observation_str = f"[Error Converting Result to String: {str_conv_err}]"
                     print(f"      !! å·¥å…· '{tool_name}' è¿”å›å…¶ä»–é¡å‹ï¼Œstr() è½‰æ›å¤±æ•—: {str_conv_err}")
                final_content = observation_str

            # æœ€çµ‚é˜²ç·š (ä¿æŒä¸è®Š)
            if not final_content:
                final_content = "FINAL_CONTENT_EMPTY"
                print(f"      !! è­¦å‘Šï¼šæœ€çµ‚ final_content ç‚ºç©ºï¼Œä½¿ç”¨æœ€çµ‚ä½”ä½ç¬¦ã€‚")

            tool_messages.append(ToolMessage(content=final_content, tool_call_id=tool_call_id, name=tool_name))

        except Exception as tool_exec_e:
            error_msg = f"éŒ¯èª¤ï¼šåŸ·è¡Œæˆ–è™•ç†å·¥å…· '{tool_name}' æ™‚å¤±æ•—: {tool_exec_e}"
            print(f"      !! {error_msg}")
            print(f"         èª¿ç”¨æ™‚åƒæ•¸: {tool_args_dict}")
            if observation is not None:
                print(f"         ainvoke è¿”å›çš„è§€å¯Ÿå€¼ (é¡å‹ {type(observation).__name__}): {repr(observation)[:500]}")
            traceback.print_exc()
            tool_messages.append(ToolMessage(content=str(error_msg), tool_call_id=tool_call_id, name=tool_name))

    return tool_messages


# =============================================================================
# æ ¸å¿ƒå‡½æ•¸ï¼šèª¿ç”¨ LLM åŸ·è¡Œè¨ˆåŠƒæ­¥é©Ÿ (æ·»åŠ è©³ç´°æ‰“å°)
# =============================================================================
async def call_llm_with_tools(
    messages: List[BaseMessage],
    selected_tools: List[BaseTool],
    execution_prompt: SystemMessage # <<< æ–°å¢åƒæ•¸
) -> AIMessage:
    """
    èª¿ç”¨ agent_llm (Gemini) æ ¹æ“šæ¶ˆæ¯æ­·å²ï¼ˆå«è¨ˆåŠƒï¼‰å’Œå¯ç”¨å·¥å…·ä¾†åŸ·è¡Œä¸‹ä¸€æ­¥ã€‚
    è¼¸å…¥æ¶ˆæ¯æ‡‰å·²åŒ…å«å¤šæ¨¡æ…‹å…§å®¹ã€‚
    æœƒè‡ªå‹•è™•ç†é…é¡éŒ¯èª¤ä¸¦åˆ‡æ›åˆ° VIP Keyã€‚
    """
    try:
        # --- å‹•æ…‹é¸æ“‡ LLM (æ ¹æ“š API Key Manager) ---
        global agent_llm, fast_llm, agent_llm_free, agent_llm_vip, fast_llm_free, fast_llm_vip
        
        if api_key_manager.should_use_vip():
            llm_to_use = agent_llm_vip if agent_llm_vip else agent_llm_free
            key_type = api_key_manager.get_current_key_type()
            print(f"  >> ä½¿ç”¨ {key_type} LLM ({llm_to_use.model})ï¼Œå‰©é¤˜ {api_key_manager.vip_calls_remaining} è¼ª")
        else:
            llm_to_use = agent_llm_free
            key_type = api_key_manager.get_current_key_type()
            print(f"  >> ä½¿ç”¨ {key_type} LLM ({llm_to_use.model}) åŸ·è¡Œä¸‹ä¸€æ­¥")
        
    except Exception as e:
        print(f"Error selecting LLM: {e}")
        llm_to_use = agent_llm_free

    # æœ€å¤šé‡è©¦ 4 æ¬¡ (è™•ç†é…é¡éŒ¯èª¤: Free -> VIP -> VIP Retry -> Fail)
    max_retries = 4
    for retry_count in range(max_retries):
        try:
            # --- ä½¿ç”¨è¼”åŠ©å‡½æ•¸ç²å– Gemini å…¼å®¹çš„å·¥å…·å®šç¾© ---
            if retry_count == 0:  # åªåœ¨ç¬¬ä¸€æ¬¡æ‰“å°
                print("     æ­£åœ¨æº–å‚™ Gemini å…¼å®¹çš„å·¥å…·å®šç¾©åˆ—è¡¨...")
            gemini_compatible_tools = _prepare_gemini_compatible_tools(selected_tools)
            if retry_count == 0:
                print(f"     ç²å–äº† {len(gemini_compatible_tools)} å€‹ Gemini å…¼å®¹çš„å·¥å…·å®šç¾©ã€‚")

            # --- ç¶å®šå·¥å…·åˆ° LLM ---
            if retry_count == 0:
                print("     æ­£åœ¨å°‡ MCP å·¥å…· (å«æ‰‹å‹•å®šç¾©) ç¶å®šåˆ° LLM...")
            llm_with_tools = llm_to_use.bind_tools(gemini_compatible_tools)
            if retry_count == 0:
                print("     MCP å·¥å…·ç¶å®šå®Œæˆã€‚")

            # --- é…ç½® Runnable ç§»é™¤å›èª¿ ---
            if retry_count == 0:
                print("     æ­£åœ¨é…ç½® LLM runnable ä»¥ç§»é™¤å›èª¿ (with_config)...")
            llm_configured_no_callbacks = llm_with_tools.with_config({"callbacks": None})
            if retry_count == 0:
                print("     LLM runnable é…ç½®å®Œæˆ (callbacks=None)ã€‚")

            # --- æº–å‚™èª¿ç”¨æ¶ˆæ¯ ---
            current_call_messages = [execution_prompt] + messages
            if retry_count == 0:
                print(f"     LLM è¼¸å…¥æ¶ˆæ¯æ•¸ (å«åŸ·è¡Œæç¤º): {len(current_call_messages)}")

            # --- æ·»åŠ è©³ç´°æ‰“å° (æª¢æŸ¥å¤šæ¨¡æ…‹æ¶ˆæ¯æ ¼å¼) ---
            print("-" * 40)
            print(f">>> DEBUG: Messages Sent to LLM.ainvoke (Attempt {retry_count + 1}/{max_retries}):")
            for i, msg in enumerate(current_call_messages):
                print(f"  Message {i} ({type(msg).__name__}):")
                try:
                    # ä½¿ç”¨æ›´å®‰å…¨çš„æ–¹å¼ç²å–å’Œæ‰“å°å…§å®¹
                    if isinstance(msg.content, str):
                        content_repr = repr(msg.content)
                    elif isinstance(msg.content, list):
                         # å°åˆ—è¡¨å…§å®¹é€²è¡Œéƒ¨åˆ†è¡¨ç¤ºï¼Œé¿å…éé•·
                         content_repr = "[" + ", ".join(repr(item)[:100] + ('...' if len(repr(item)) > 100 else '') for item in msg.content) + "]"
                    else:
                         content_repr = repr(msg.content)
                    print(f"    Content: {content_repr[:1000]}{'...' if len(content_repr) > 1000 else ''}")
                except Exception as repr_err:
                    print(f"    Content: [Error representing content: {repr_err}]")

                if isinstance(msg, AIMessage) and msg.tool_calls:
                    try:
                        tool_calls_repr = repr(msg.tool_calls)
                        print(f"    Tool Calls: {tool_calls_repr[:500]}{'...' if len(tool_calls_repr) > 500 else ''}")
                    except Exception as repr_err:
                        print(f"    Tool Calls: [Error representing tool_calls: {repr_err}]")
                elif isinstance(msg, ToolMessage) and hasattr(msg, 'tool_call_id'):
                     print(f"    Tool Call ID: {msg.tool_call_id}")
            print("-" * 40)
            # --- çµæŸè©³ç´°æ‰“å° ---

            # --- åŸ·è¡Œ LLM èª¿ç”¨ (ä½¿ç”¨é…ç½®å¾Œçš„ Runnable) ---
            if retry_count == 0:
                print(f"     æ­£åœ¨èª¿ç”¨é…ç½®å¾Œçš„ LLM.ainvoke (Model: {llm_to_use.model})...")
            else:
                print(f"     [Retry {retry_count}] æ­£åœ¨èª¿ç”¨ LLM.ainvoke (Model: {llm_to_use.model})...")
            
            response = await llm_configured_no_callbacks.ainvoke(current_call_messages)
            
            # --- æˆåŠŸèª¿ç”¨ï¼Œè™•ç† VIP è¨ˆæ•¸å™¨ ---
            if api_key_manager.should_use_vip():
                api_key_manager.decrement_vip_calls()
            
            if retry_count == 0:
                print(f"  << LLM èª¿ç”¨å®Œæˆã€‚")
            if isinstance(response, AIMessage) and response.tool_calls:
                 print(f"     LLM è«‹æ±‚èª¿ç”¨ {len(response.tool_calls)} å€‹å·¥å…·ã€‚")
            elif isinstance(response, AIMessage):
                 print(f"     LLM è¿”å›å…§å®¹: {response.content[:150]}...")
                 if "ä»»å‹™å·²å®Œæˆ" in response.content.lower():
                     print("     åµæ¸¬åˆ° 'ä»»å‹™å·²å®Œæˆ'ã€‚")
            else:
                 print(f"     LLM è¿”å›éé æœŸé¡å‹: {type(response).__name__}")

            return response

        except Exception as e:
            str_e = str(e)
            is_quota_error = ("429" in str_e and ("quota" in str_e.lower() or "rate" in str_e.lower())) or \
                            ("Quota exceeded" in str_e) or \
                            ("You exceeded your current quota" in str_e)
            
            if is_quota_error and retry_count < max_retries - 1:
                print(f"  âš ï¸  æ•ç²é…é¡éŒ¯èª¤ (429 Quota Exceeded): {e}")
                # å˜—è©¦åˆ‡æ›åˆ° VIP
                if api_key_manager.handle_quota_error():
                    # æª¢æŸ¥ agent_llm_vip æ˜¯å¦å¯ç”¨
                    if not agent_llm_vip:
                        # å˜—è©¦å‹•æ…‹åˆå§‹åŒ– VIP Agent
                        vip_key = os.getenv("GEMINI_API_KEY_VIP")
                        if vip_key:
                            print("  >> [Dynamic Init] å˜—è©¦å‹•æ…‹åˆå§‹åŒ– agent_llm_vip...")
                            try:
                                agent_llm_vip = ChatGoogleGenerativeAI(
                                    model="gemini-2.5-pro",
                                    temperature=0.5,
                                    google_api_key=vip_key
                                )
                                print("  >> [Dynamic Init] agent_llm_vip åˆå§‹åŒ–æˆåŠŸï¼")
                            except Exception as init_err:
                                print(f"  >> [Dynamic Init] agent_llm_vip åˆå§‹åŒ–å¤±æ•—: {init_err}")
                        else:
                            print("  >> [Dynamic Init] å¤±æ•—: ç’°å¢ƒè®Šæ•¸ GEMINI_API_KEY_VIP æœªè¨­ç½®")

                    # åˆ‡æ› LLM
                    if agent_llm_vip:
                        llm_to_use = agent_llm_vip
                        print(f"  >> âœ… æˆåŠŸåˆ‡æ›åˆ° VIP LLM ({llm_to_use.model})")
                    else:
                        llm_to_use = agent_llm_free
                        print(f"  >> âŒ åˆ‡æ›å¤±æ•—: ç„¡æ³•ç²å– VIP LLM å¯¦ä¾‹ï¼Œå°‡ç¹¼çºŒä½¿ç”¨ Free LLM é‡è©¦")

                    print(f"  >> ç¬¬ {retry_count + 1}/{max_retries} æ¬¡é‡è©¦å³å°‡é–‹å§‹...")
                    await asyncio.sleep(2)  # çŸ­æš«ç­‰å¾…
                    continue  # é‡è©¦
                else:
                    # æ²’æœ‰ VIP Keyï¼Œç„¡æ³•ç¹¼çºŒ
                    error_content = f"é…é¡å·²æ»¿ä¸”ç„¡ VIP Key å¯ç”¨ (handle_quota_error returned False): {e}"
                    print(f"!! {error_content}")
                    return AIMessage(content=error_content)
            
            # å…¶ä»–éŒ¯èª¤æˆ–å·²é”æœ€å¤§é‡è©¦æ¬¡æ•¸
            print(f"!! åŸ·è¡Œ LLM èª¿ç”¨ (call_llm_with_tools) æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            traceback.print_exc()
            
            error_content = f"åŸ·è¡Œ LLM æ±ºç­–æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}"
            if isinstance(e, ValueError) and "Unexpected message with type" in str_e:
                 error_content = f"å…§éƒ¨éŒ¯èª¤ï¼šèª¿ç”¨ LLM æ™‚æ¶ˆæ¯é †åºæˆ–é¡å‹ä¸åŒ¹é…ã€‚éŒ¯èª¤: {e}"
            elif "Function and/or coroutine must be provided" in str_e or "bind_tools" in str_e.lower():
                 error_content = f"å…§éƒ¨éŒ¯èª¤ï¼šç¶å®šæˆ–èª¿ç”¨å·¥å…·æ™‚å‡ºéŒ¯ã€‚æª¢æŸ¥å·¥å…·å®šç¾©æˆ–LLMå…¼å®¹æ€§ã€‚éŒ¯èª¤: {e}"
            elif "InvalidArgument: 400" in str_e:
                 reason = "æœªçŸ¥åŸå› "
                 if "missing field" in str_e:
                     reason = f"å·¥å…· Schema ç„¡æ•ˆ (å³ä½¿æ‰‹å‹•ä¿®æ­£å¾Œï¼Œä»å¯èƒ½å­˜åœ¨å•é¡Œæˆ–å½±éŸ¿å…¶ä»–å·¥å…·)"
                 elif "function declaration" in str_e:
                      reason = f"å·¥å…·å‡½æ•¸è²æ˜æ ¼å¼éŒ¯èª¤"
                 elif "contents" in str_e:
                     reason = f"æ¶ˆæ¯å…§å®¹æ ¼å¼éŒ¯èª¤ï¼Œå¯èƒ½å¤šæ¨¡æ…‹è¼¸å…¥æœªè¢«æ­£ç¢ºè™•ç†"
                 error_content = f"å…§éƒ¨éŒ¯èª¤ï¼šå‚³éçµ¦ Gemini çš„æ•¸æ“šç„¡æ•ˆ ({reason})ã€‚éŒ¯èª¤: {e}"

            return AIMessage(content=error_content)
    
    # å¦‚æœæ‰€æœ‰é‡è©¦éƒ½å¤±æ•—
    return AIMessage(content="LLM èª¿ç”¨å¤±æ•—ï¼šå·²é”æœ€å¤§é‡è©¦æ¬¡æ•¸")


# --- NEW HELPER FUNCTION for preparing Gemini-compatible tools ---
def _prepare_gemini_compatible_tools(mcp_tools: List[BaseTool]) -> List[Union[BaseTool, Dict]]:
    """
    ç‚º Gemini LLM æº–å‚™å·¥å…·åˆ—è¡¨ï¼Œæ‰‹å‹•ä¿®æ­£ç‰¹å®šå·¥å…·çš„ schemaã€‚
    """
    print("     [Helper] æº–å‚™ Gemini å…¼å®¹çš„å·¥å…·å®šç¾©åˆ—è¡¨...")
    tools_for_binding = []
    if not mcp_tools:
        print("     [Helper] è­¦å‘Š: å‚³å…¥çš„ mcp_tools åˆ—è¡¨ç‚ºç©ºã€‚")
        return []

    for tool in mcp_tools:
        if not tool or not hasattr(tool, 'name'):
            print(f"     [Helper] è­¦å‘Š: å·¥å…·åˆ—è¡¨ä¸­ç™¼ç¾ç„¡æ•ˆå·¥å…·å°è±¡: {tool}")
            continue

        if tool.name == "get_scene_objects_with_metadata":
            print(f"     [Helper] ç‚º '{tool.name}' å‰µå»ºæ‰‹å‹• Gemini FunctionDeclaration...")
            manual_declaration = {
                "name": tool.name,
                "description": tool.description,
                "parameters": {
                    "type": "OBJECT",
                    "properties": {
                        "filters": {
                            "type": "OBJECT",
                            "description": "ç¯©é¸æ¢ä»¶ï¼Œä¾‹å¦‚ {'layer': 'Default', 'name': 'Cube*'}",
                            "nullable": True,
                        },
                        "metadata_fields": {
                            "type": "ARRAY",
                            "description": "è¦è¿”å›çš„å…ƒæ•¸æ“šæ¬„ä½åˆ—è¡¨ï¼Œä¾‹å¦‚ ['name', 'layer', 'short_id']",
                            "nullable": True,
                            "items": { "type": "STRING" }
                        }
                    },
                }
            }
            tools_for_binding.append(manual_declaration)
        elif tool.name == "zoom_to_target" or tool.name == "capture_focused_view":
            print(f"     [Helper] ç‚ºå« bounding_box åƒæ•¸çš„å·¥å…· '{tool.name}' å‰µå»ºæ‰‹å‹• Gemini FunctionDeclaration...")
            properties = {
                "view": { "type": "STRING", "description": "è¦–åœ–åç¨±æˆ–ID", "nullable": True }
            }
            if tool.name == "zoom_to_target":
                properties.update({
                    "object_ids": { "type": "ARRAY", "description": "è¦ç¸®æ”¾åˆ°çš„å°è±¡IDåˆ—è¡¨", "nullable": True, "items": {"type": "STRING"} },
                    "all_views": { "type": "BOOLEAN", "description": "æ˜¯å¦æ‡‰ç”¨æ–¼æ‰€æœ‰è¦–åœ–", "nullable": True }
                })
            elif tool.name == "capture_focused_view":
                properties.update({
                    "projection_type": { "type": "STRING", "description": "æŠ•å½±é¡å‹: 'parallel', 'perspective', 'two_point'", "nullable": True },
                    "lens_angle": { "type": "NUMBER", "description": "é€è¦–æˆ–å…©é»æŠ•å½±çš„é¡é ­è§’åº¦", "nullable": True },
                    "camera_position": { "type": "ARRAY", "description": "ç›¸æ©Ÿä½ç½®çš„ [x, y, z] åæ¨™", "nullable": True, "items": {"type": "NUMBER"} },
                    "target_position": { "type": "ARRAY", "description": "ç›®æ¨™é»çš„ [x, y, z] åæ¨™", "nullable": True, "items": {"type": "NUMBER"} },
                    "layer": { "type": "STRING", "description": "ç”¨æ–¼ç¯©é¸é¡¯ç¤ºè¨»é‡‹çš„åœ–å±¤åç¨±", "nullable": True },
                    "show_annotations": { "type": "BOOLEAN", "description": "æ˜¯å¦é¡¯ç¤ºç‰©ä»¶è¨»é‡‹", "nullable": True },
                    "max_size": { "type": "INTEGER", "description": "æˆªåœ–çš„æœ€å¤§å°ºå¯¸", "nullable": True }
                })
            
            # Correct bounding_box for Gemini: items need a type for the inner array's elements
            properties["bounding_box"] = {
                "type": "ARRAY",
                "description": "é‚Šç•Œæ¡†çš„8å€‹è§’é»åæ¨™ [[x,y,z], [x,y,z], ...]",
                "nullable": True,
                "items": { # This 'items' describes the outer array (list of points)
                    "type": "ARRAY", # Each item is an array (a point)
                    "items": { # This 'items' describes the inner array (coordinates of a point)
                        "type": "NUMBER" # Each coordinate is a NUMBER
                    }
                }
            }
            manual_declaration = {
                "name": tool.name,
                "description": tool.description,
                "parameters": { "type": "OBJECT", "properties": properties }
            }
            tools_for_binding.append(manual_declaration)
        else:
            tools_for_binding.append(tool) # Add other tools as they are
            # print(f"     [Helper] ä¿ç•™æ¨™æº– MCP BaseTool å°è±¡: {tool.name}")
    
    if not tools_for_binding and mcp_tools: # If all tools were invalid or some other issue
        print("     [Helper] è­¦å‘Š: å·¥å…·æº–å‚™å¾Œåˆ—è¡¨ç‚ºç©ºï¼Œä½†åŸå§‹åˆ—è¡¨éç©ºã€‚å¯èƒ½æ‰€æœ‰å·¥å…·éƒ½ç„¡æ³•è™•ç†ã€‚")
    elif not tools_for_binding and not mcp_tools:
        pass # Expected if input was empty
    else:
        print(f"     [Helper] å®Œæˆ Gemini å…¼å®¹å·¥å…·æº–å‚™ï¼Œå…± {len(tools_for_binding)} å€‹ã€‚")
    return tools_for_binding
# --- END NEW HELPER FUNCTION ---

# =============================================================================
# åœ–ç¯€é» (Graph Nodes)
# =============================================================================

# --- Router Node (MODIFIED to handle pinterest) ---
async def route_mcp_target(state: MCPAgentState, config: RunnableConfig) -> Dict:
    """ä½¿ç”¨ utility_llm åˆ¤æ–·ç”¨æˆ¶åˆå§‹è«‹æ±‚æ–‡æœ¬æ‡‰è·¯ç”±åˆ°å“ªå€‹ MCP (revit, rhino, pinterest)ã€‚"""
    print("--- åŸ·è¡Œ MCP è·¯ç”±ç¯€é» ---")

    # --- NEW: Check if target_mcp is already set in the state ---
    pre_set_target_mcp = state.get("target_mcp")
    valid_mcp_targets = ["revit", "rhino", "pinterest", "osm"]
    if pre_set_target_mcp and pre_set_target_mcp in valid_mcp_targets:
        print(f"  æª¢æ¸¬åˆ°å·²é è¨­ target_mcp: '{pre_set_target_mcp}'ã€‚ç›´æ¥ä½¿ç”¨æ­¤ç›®æ¨™ï¼Œè·³é LLM è·¯ç”±ã€‚")
        return {"target_mcp": pre_set_target_mcp, "last_executed_node": "router_skipped_due_to_preset"}
    # --- END NEW ---

    initial_request_text = state.get('initial_request', '')
    if not initial_request_text:
        print("éŒ¯èª¤ï¼šç‹€æ…‹ä¸­æœªæ‰¾åˆ° 'initial_request' ä¸” target_mcp æœªé è¨­ã€‚é»˜èªç‚º rhinoã€‚")
        # {{ edit_1 }}
        return {"target_mcp": "rhino", "last_executed_node": "router_defaulted_rhino_no_request"}
        # {{ end_edit_1 }}

    print(f"  æ ¹æ“šåˆå§‹è«‹æ±‚æ–‡æœ¬è·¯ç”±: '{initial_request_text[:150]}...'")
    prompt = ROUTER_PROMPT.format(user_request_text=initial_request_text)
    try:
        response = await utility_llm.ainvoke([SystemMessage(content=prompt)], config=config)
        route_decision = response.content.strip().lower()
        print(f"  LLM è·¯ç”±æ±ºå®š: {route_decision}")
        if route_decision in valid_mcp_targets: # Use the list here
            # {{ edit_2 }}
            return {"target_mcp": route_decision, "last_executed_node": "router_llm_decision"}
            # {{ end_edit_2 }}
        else:
            print(f"  è­¦å‘Š: LLM è·¯ç”±å™¨çš„å›æ‡‰ç„¡æ³•è­˜åˆ¥ ('{route_decision}')ã€‚é è¨­ç‚º rhinoã€‚")
            # {{ edit_3 }}
            return {"target_mcp": "rhino", "last_executed_node": "router_defaulted_rhino_unknown_llm_response"}
            # {{ end_edit_3 }}
    except Exception as e:
        print(f"  è·¯ç”± LLM å‘¼å«å¤±æ•—: {e}")
        traceback.print_exc()
        # {{ edit_4 }}
        return {"target_mcp": "rhino", "last_executed_node": "router_defaulted_rhino_llm_exception"}
        # {{ end_edit_4 }}


# <<< æ–°å¢ï¼šè¨Šæ¯å‰ªæè¼”åŠ©å‡½å¼ >>>
MAX_RECENT_INTERACTIONS_DEFAULT = 18
MAX_RECENT_INTERACTIONS_FORCING = 23

def _prune_messages_for_llm(full_messages: List[BaseMessage], max_recent_interactions: int = MAX_RECENT_INTERACTIONS_DEFAULT) -> List[BaseMessage]:
    if not full_messages:
        return []

    initial_human_message = None
    plan_ai_message = None

    # æ‰¾åˆ°åˆå§‹çš„ HumanMessage (é€šå¸¸æ˜¯åˆ—è¡¨ä¸­çš„ç¬¬ä¸€å€‹)
    if full_messages and isinstance(full_messages[0], HumanMessage): # Added check for full_messages not empty
        initial_human_message = full_messages[0]

    # æ‰¾åˆ°æœ€æ–°çš„è¨ˆåŠƒ AIMessage
    PLAN_PREFIX = "[ç›®æ¨™éšæ®µè¨ˆåŠƒ]:\n"
    for msg in reversed(full_messages):
        if isinstance(msg, AIMessage) and isinstance(msg.content, str) and msg.content.strip().startswith(PLAN_PREFIX):
            plan_ai_message = msg
            break

    pruned_list = []
    added_message_ids = set() # ä½¿ç”¨ç‰©ä»¶ id ä¾†é¿å…é‡è¤‡æ·»åŠ å®Œå…¨ç›¸åŒçš„è¨Šæ¯å¯¦ä¾‹

    # 1. æ·»åŠ åˆå§‹ HumanMessage (å¦‚æœå­˜åœ¨)
    if initial_human_message:
        pruned_list.append(initial_human_message)
        added_message_ids.add(id(initial_human_message))

    # 2. æ·»åŠ è¨ˆåŠƒ AIMessage (å¦‚æœå­˜åœ¨ä¸”èˆ‡ initial_human_message ä¸åŒ)
    if plan_ai_message and id(plan_ai_message) not in added_message_ids:
        # ç¢ºä¿è¨ˆåŠƒè¨Šæ¯ä¸æ˜¯åˆ—è¡¨ä¸­çš„ç¬¬ä¸€å€‹ HumanMessage (é›–ç„¶ä¸å¤ªå¯èƒ½ï¼Œä½†ä»¥é˜²è¬ä¸€)
        if not (initial_human_message and id(plan_ai_message) == id(initial_human_message)):
            pruned_list.append(plan_ai_message)
            added_message_ids.add(id(plan_ai_message))

    # 3. ç¢ºå®šè¿‘æœŸäº’å‹•çš„å€™é¸è¨Šæ¯ (æ’é™¤å·²æ·»åŠ çš„ initial_human_message å’Œ plan_ai_message)
    recent_interaction_candidates = []
    for msg in full_messages:
        if id(msg) not in added_message_ids:
            recent_interaction_candidates.append(msg)
    
    # é¸å–æœ€å¾Œ N æ¢ä½œç‚ºå¯¦éš›çš„è¿‘æœŸäº’å‹•è¨Šæ¯
    actual_recent_interactions = recent_interaction_candidates[-max_recent_interactions:]

    # 4. å°‡è¿‘æœŸäº’å‹•è¨Šæ¯æ·»åŠ åˆ°å‰ªæå¾Œçš„åˆ—è¡¨
    #    å°‡ initial_human_message å’Œ plan_ai_message æ”¾åœ¨å‰é¢ï¼Œç„¶å¾Œæ˜¯ recent_interactions
    #    é€™è£¡çš„é‚è¼¯æ˜¯é‡æ–°æ§‹å»º pruned_listï¼Œè€Œä¸æ˜¯åœ¨ç¾æœ‰çš„ pruned_list å¾Œè¿½åŠ 
    final_pruned_list = []
    temp_added_ids = set()

    if initial_human_message:
        final_pruned_list.append(initial_human_message)
        temp_added_ids.add(id(initial_human_message))

    if plan_ai_message and id(plan_ai_message) not in temp_added_ids:
        final_pruned_list.append(plan_ai_message)
        temp_added_ids.add(id(plan_ai_message))
    
    for msg in actual_recent_interactions:
        if id(msg) not in temp_added_ids: # é¿å…å†æ¬¡æ·»åŠ  plan æˆ– initial human message å¦‚æœå®ƒå€‘æ°å¥½åœ¨å°¾éƒ¨
            final_pruned_list.append(msg)
            # temp_added_ids.add(id(msg)) # ä¸éœ€è¦ï¼Œå› ç‚ºæ˜¯å¾å°¾éƒ¨å–çš„

    # --- æ—¥èªŒè¨˜éŒ„å‰ªæå¾Œçš„è¨Šæ¯ (å¯é¸ï¼Œç”¨æ–¼èª¿è©¦) ---
    # print(f"    åŸå§‹è¨Šæ¯æ•¸é‡: {len(full_messages)}, å‰ªæå¾Œè¨Šæ¯æ•¸é‡: {len(final_pruned_list)}")
    # pruned_message_summary = []
    # for i, m_obj in enumerate(final_pruned_list):
    #     m_content_str = ""
    #     if isinstance(m_obj.content, str):
    #         m_content_str = m_obj.content[:30].replace("\n", " ") + "..."
    #     elif isinstance(m_obj.content, list) and m_obj.content:
    #         first_item_content = m_obj.content[0]
    #         if isinstance(first_item_content, dict) and first_item_content.get("type") == "text":
    #             m_content_str = first_item_content.get("text", "")[:30] + "..."
    #         else:
    #             m_content_str = str(first_item_content)[:30] + "..."
    #     elif m_obj.content is None:
    #         m_content_str = "[None Content]"
    #     else:
    #         m_content_str = f"[{type(m_obj.content).__name__} Content]"
    #     pruned_message_summary.append(f"      {i}: {type(m_obj).__name__} - '{m_content_str}'")
    # print("    å‰ªæå¾Œè¨Šæ¯é è¦½:\n" + "\n".join(pruned_message_summary))
    # --- çµæŸæ—¥èªŒè¨˜éŒ„ ---

    return final_pruned_list
# <<< çµæŸï¼šè¨Šæ¯å‰ªæè¼”åŠ©å‡½å¼ >>>

# =============================================================================
# Agent Nodes (ä¿®æ”¹ï¼šè™•ç† Pinterest ToolMessageï¼Œè¿”å›æœ€çµ‚çµæœ)
# =============================================================================
async def agent_node_logic(state: MCPAgentState, config: RunnableConfig, mcp_name: str) -> Dict:
    """é€šç”¨ Agent ç¯€é»é‚è¼¯ï¼šè™•ç†ç‰¹å®šå·¥å…·æ¶ˆæ¯ï¼Œè¦åŠƒï¼Œæˆ–åŸ·è¡Œä¸‹ä¸€æ­¥ã€‚"""
    print(f"--- åŸ·è¡Œ {mcp_name.upper()} Agent ç¯€é» ---")
    
    current_messages = list(state['messages'])
    last_message = current_messages[-1] if current_messages else None
    current_consecutive_responses = state.get("consecutive_llm_text_responses", 0)
    # Ensure rhino_screenshot_counter is present in the state, default to 0 if not
    current_rhino_screenshot_counter = state.get("rhino_screenshot_counter", 0)

    # --- è™•ç† capture_viewport, OSM, Pinterest çš„ ToolMessage è¿”å› ---
    IMAGE_PATH_PREFIX = "[IMAGE_FILE_PATH]:"
    OSM_IMAGE_PATH_PREFIX = "[OSM_IMAGE_PATH]:" # Assuming OSM tool returns this prefix
    CSV_PATH_PREFIX = "[CSV_FILE_PATH]:"

    if isinstance(last_message, ToolMessage):
        # Handle Local CSV Creation Tool
        if last_message.name == "create_planned_data_summary_csv":
            if last_message.content.startswith(CSV_PATH_PREFIX):
                csv_path = last_message.content[len(CSV_PATH_PREFIX):]
                print(f"  æª¢æ¸¬åˆ°è¨ˆåŠƒæ•¸æ“šCSVå ±å‘Šå·²ç”Ÿæˆæ–¼: {csv_path}")
                # This tool is called after planning is done. The next step is to start executing the modeling.
                # Returning a message here allows the agent to acknowledge and proceed.
                return {
                    "messages": [AIMessage(content=f"è¨ˆåŠƒç¸½çµå ±å‘Šå·²åœ¨è¦åŠƒéšæ®µå®Œæˆï¼Œä¸¦ä¿å­˜æ–¼ {csv_path}ã€‚ç¾åœ¨é–‹å§‹åŸ·è¡Œæ¨¡å‹å»ºæ§‹ã€‚")],
                    "saved_csv_path": csv_path,
                    "task_complete": False, # Modeling is not yet done
                    "consecutive_llm_text_responses": 0,
                    "last_executed_node": f"{mcp_name}_agent"
                }

        # Handle Rhino/Revit Screenshot Path
        if last_message.name == "capture_focused_view" and isinstance(last_message.content, str):
            if last_message.content.startswith(IMAGE_PATH_PREFIX):
                print("  æª¢æ¸¬åˆ° capture_viewport å·¥å…·è¿”å›çš„æ–‡ä»¶è·¯å¾‘ã€‚") 
                uuid_image_path = last_message.content[len(IMAGE_PATH_PREFIX):]
                print(f"    åŸå§‹æ–‡ä»¶è·¯å¾‘ (UUID based): {uuid_image_path}")
                
                new_image_path_for_state = uuid_image_path # Default to original if rename fails
                data_uri_for_state = None
                # {{ edit_2 }}
                # --- MODIFIED: Renaming logic for Rhino screenshots ---
                if mcp_name == "rhino":
                    current_rhino_screenshot_counter += 1 # Increment counter from state
                    
                    # Sanitize initial_request for use in filename (take first 20 chars, replace spaces, keep alphanum and underscore)
                    req_str_part = state.get('initial_request', 'RhinoTask')
                    sanitized_req_prefix = "".join(filter(lambda x: x.isalnum() or x == '_', req_str_part.replace(" ", "_")[:20]))
                    
                    original_extension = os.path.splitext(uuid_image_path)[1]
                    new_filename = f"{sanitized_req_prefix}_Shot-{current_rhino_screenshot_counter}{original_extension}"
                    
                    try:
                        if os.path.exists(uuid_image_path):
                            new_renamed_path = os.path.join(os.path.dirname(uuid_image_path), new_filename)
                            os.rename(uuid_image_path, new_renamed_path)
                            new_image_path_for_state = new_renamed_path # Use renamed path
                            print(f"    æ–‡ä»¶å·²é‡å‘½åç‚º: {new_renamed_path}")
                        else:
                            print(f"  !! éŒ¯èª¤ï¼šcapture_viewport è¿”å›çš„åŸå§‹æ–‡ä»¶è·¯å¾‘ä¸å­˜åœ¨: {uuid_image_path}ã€‚ç„¡æ³•é‡å‘½åã€‚")
                            # new_image_path_for_state remains uuid_image_path, which is problematic if it doesn't exist.
                            # Consider how to handle this error - perhaps return an error message.
                            # For now, it will proceed and likely fail to generate URI / be found later.
                    except Exception as rename_err:
                        print(f"  !! é‡å‘½åæ–‡ä»¶ '{uuid_image_path}' è‡³ '{new_filename}' æ™‚å‡ºéŒ¯: {rename_err}")
                        # new_image_path_for_state remains uuid_image_path
                # --- END MODIFICATION ---
                # {{ end_edit_2 }}

                try:
                    if not os.path.exists(new_image_path_for_state):
                        print(f"  !! éŒ¯èª¤ï¼šè™•ç†å¾Œçš„åœ–åƒæ–‡ä»¶è·¯å¾‘ä¸å­˜åœ¨: {new_image_path_for_state}")
                        # {{ edit_3 }}
                        return { 
                              "messages": [AIMessage(content=f"æˆªåœ–æ–‡ä»¶æœªæ‰¾åˆ°: {new_image_path_for_state}ã€‚")],
                              "saved_image_path": None, "saved_image_data_uri": None,
                              "task_complete": False, 
                              "consecutive_llm_text_responses": 0,
                              "rhino_screenshot_counter": current_rhino_screenshot_counter # Return updated counter
                              # {{ end_edit_3 }}
                          }
                    with open(new_image_path_for_state, "rb") as f: image_bytes = f.read()
                    base64_data = base64.b64encode(image_bytes).decode('utf-8')
                    mime_type = "image/png" 
                    ext = os.path.splitext(new_image_path_for_state)[1].lower()
                    if ext in [".jpg", ".jpeg"]: mime_type = "image/jpeg"
                    data_uri_for_state = f"data:{mime_type};base64,{base64_data}"
                    # {{ edit_4 }}
                    return {
                         "messages": [AIMessage(content=f"å·²æˆåŠŸæˆªå–ç•«é¢ä¸¦ä¿å­˜è‡³ {new_image_path_for_state}ã€‚")],
                         "saved_image_path": new_image_path_for_state, 
                         "saved_image_data_uri": data_uri_for_state,
                         "task_complete": False, 
                         "consecutive_llm_text_responses": 0,
                         "rhino_screenshot_counter": current_rhino_screenshot_counter # Return updated counter
                         # {{ end_edit_4 }}
                    }
                except Exception as img_proc_err:
                    print(f"  !! è™•ç†æˆªåœ–æ–‡ä»¶ '{new_image_path_for_state}' æˆ–ç·¨ç¢¼æ™‚å‡ºéŒ¯: {img_proc_err}")
                    # {{ edit_5 }}
                    return { 
                         "messages": [AIMessage(content=f"è™•ç†æˆªåœ–æ–‡ä»¶ '{new_image_path_for_state}' æ™‚å¤±æ•—: {img_proc_err}ã€‚")],
                         "task_complete": False, 
                         "consecutive_llm_text_responses": 0,
                         "rhino_screenshot_counter": current_rhino_screenshot_counter # Return updated counter
                         # {{ end_edit_5 }}
                     }
            elif last_message.content.startswith("[Error: Viewport Capture Failed]:"): 
                error_msg = last_message.content 
                print(f"  æª¢æ¸¬åˆ° capture_viewport å·¥å…·è¿”å›éŒ¯èª¤: {error_msg}")
                # {{ edit_6 }}
                return {"messages": [AIMessage(content=f"ä»»å‹™å› æˆªåœ–éŒ¯èª¤è€Œä¸­æ­¢: {error_msg}")], "task_complete": True, "consecutive_llm_text_responses": 0, "rhino_screenshot_counter": current_rhino_screenshot_counter} 
                # {{ end_edit_6 }}

        # Handle OSM Screenshot Path
        elif last_message.name == "geocode_and_screenshot" and isinstance(last_message.content, str) and last_message.content.startswith(OSM_IMAGE_PATH_PREFIX): 
            print("  æª¢æ¸¬åˆ° geocode_and_screenshot å·¥å…·è¿”å›çš„æ–‡ä»¶è·¯å¾‘ã€‚") 
            image_path = last_message.content[len(OSM_IMAGE_PATH_PREFIX):]
            print(f"    OSM æ–‡ä»¶è·¯å¾‘: {image_path}")
            try:
                # ... (OSM Image processing logic: check exists, read, encode, create data URI) ...
                if not os.path.exists(image_path):
                    print(f"  !! éŒ¯èª¤ï¼šæ”¶åˆ°çš„ OSM åœ–åƒæ–‡ä»¶è·¯å¾‘ä¸å­˜åœ¨: {image_path}") # Corrected Indentation
                    return {"messages": [AIMessage(content=f"åœ°åœ–è™•ç†å®Œç•¢ï¼Œä½†æˆªåœ–æ–‡ä»¶æœªæ‰¾åˆ°: {image_path}")], "task_complete": True, "consecutive_llm_text_responses": 0} # OSM task is likely done
                with open(image_path, "rb") as f: image_bytes = f.read() # Corrected Indentation
                base64_data = base64.b64encode(image_bytes).decode('utf-8')
                # ... (mime type detection) ...
                mime_type = "image/png" # Default or detect # Corrected Indentation
                data_uri = f"data:{mime_type};base64,{base64_data}"
                return {
                    "messages": [AIMessage(content=f"åœ°åœ–æˆªåœ–å·²å®Œæˆã€‚\næˆªåœ–å·²ä¿å­˜è‡³ {image_path}ã€‚")],
                    "saved_image_path": image_path, "saved_image_data_uri": data_uri,
                    "task_complete": True, # OSM task usually ends here
                    "consecutive_llm_text_responses": 0
                }
            except Exception as img_proc_err:
                print(f"  !! è™•ç† OSM æˆªåœ–æ–‡ä»¶ '{image_path}' æˆ–ç·¨ç¢¼æ™‚å‡ºéŒ¯: {img_proc_err}")
                return {"messages": [AIMessage(content=f"åœ°åœ–æˆªåœ–å·²å®Œæˆï¼Œä½†è™•ç†æ–‡ä»¶ '{image_path}' æ™‚å¤±æ•—: {img_proc_err}")], "task_complete": True, "consecutive_llm_text_responses": 0} # Corrected Indentation

        # Handle Pinterest Download Paths
        elif last_message.name == "pinterest_search_and_download": # Corrected Indentation
            print("  æª¢æ¸¬åˆ° pinterest_search_and_download å·¥å…·è¿”å›ã€‚") # Corrected Indentation
            content = last_message.content
            saved_paths_list = None
            try:
                data = json.loads(content)
                if isinstance(data, dict) and "downloaded_paths" in data and isinstance(data["downloaded_paths"], list):
                    saved_paths_list = data["downloaded_paths"]
                    print(f"    æˆåŠŸè§£æåˆ° {len(saved_paths_list)} å€‹ä¸‹è¼‰è·¯å¾‘ã€‚")
                else:
                     print(f"    ToolMessage content is JSON but missing 'downloaded_paths' list: {content[:200]}...")
            except json.JSONDecodeError:
                print(f"    ToolMessage content is not JSON (likely text output or error): {content[:200]}...")
            except Exception as e:
                print(f"    è§£æ Pinterest ToolMessage content æ™‚å‡ºéŒ¯: {e}")

            if saved_paths_list:
                 last_path = saved_paths_list[-1] if saved_paths_list else None
                 data_uri = None
                 if last_path:
                     try:
                        # ... (Image processing for last Pinterest image) ...
                         with open(last_path, "rb") as f: image_bytes = f.read()
                         base64_data = base64.b64encode(image_bytes).decode('utf-8')
                         # ... (mime type detection) ...
                         mime_type = "image/png" # Default or detect
                         data_uri = f"data:{mime_type};base64,{base64_data}"
                     except Exception as img_proc_err:
                         print(f"    !! è™•ç†æœ€å¾Œä¸€å€‹ Pinterest æ–‡ä»¶ '{last_path}' æˆ–ç·¨ç¢¼æ™‚å‡ºéŒ¯: {img_proc_err}")

                 return {
                     "messages": [AIMessage(content=f"Pinterest åœ–ç‰‡æœç´¢å’Œä¸‹è¼‰å®Œæˆï¼Œå…±æ‰¾åˆ° {len(saved_paths_list)} å€‹æœ‰æ•ˆæ–‡ä»¶ã€‚")],
                     "saved_image_path": last_path, # Keep last for reference
                     "saved_image_data_uri": data_uri, # Keep last for reference
                     "saved_image_paths": saved_paths_list, # Store the full list
                     "task_complete": True, # Assume Pinterest is final step
                     "consecutive_llm_text_responses": 0
                 }
            else:
                 print("    Pinterest å·¥å…·æœªè¿”å›æœ‰æ•ˆè·¯å¾‘åˆ—è¡¨ï¼Œä»»å‹™å¯èƒ½æœªæˆåŠŸæˆ–æœªæ‰¾åˆ°åœ–ç‰‡ã€‚")
                 # Return text message, reset counter, task likely complete based on Pinterest prompt
                 return {"messages": [AIMessage(content=f"Pinterest ä»»å‹™è™•ç†å®Œæˆï¼Œä½†æœªæ‰¾åˆ°æˆ–è™•ç†ä¸‹è¼‰è·¯å¾‘ã€‚å·¥å…·è¼¸å‡º: {content[:200]}...")], "task_complete": True, "consecutive_llm_text_responses": 0} # Corrected Indentation
            # Add more elif blocks here if other tools return specific results needing processing

    # --- å¦‚æœä¸æ˜¯è™•ç†ç‰¹å®šå·¥å…·è¿”å›ï¼Œå‰‡åŸ·è¡Œæ­£å¸¸è¦åŠƒ/åŸ·è¡Œé‚è¼¯ ---
    try:
        # ... (Planning/Execution logic starts here) ...
        initial_image_path = state.get('initial_image_path')
        has_input_image = initial_image_path and os.path.exists(initial_image_path)
        if has_input_image: print(f"  æª¢æ¸¬åˆ°åˆå§‹åœ–ç‰‡è¼¸å…¥: {initial_image_path}")
        else: print("  æœªæª¢æ¸¬åˆ°æœ‰æ•ˆåˆå§‹åœ–ç‰‡è¼¸å…¥ã€‚")

        if not current_messages or not isinstance(current_messages[0], HumanMessage):
             print("!! éŒ¯èª¤ï¼šç‹€æ…‹ 'messages' ç‚ºç©ºæˆ–ç¬¬ä¸€å€‹æ¶ˆæ¯ä¸æ˜¯ HumanMessageã€‚")
             return {"messages": [AIMessage(content="å…§éƒ¨éŒ¯èª¤ï¼šç¼ºå°‘æœ‰æ•ˆçš„åˆå§‹ç”¨æˆ¶è«‹æ±‚æ¶ˆæ¯ã€‚")]}
        initial_user_message_obj = current_messages[0]
        initial_user_text = ""
        if isinstance(initial_user_message_obj.content, str): initial_user_text = initial_user_message_obj.content
        elif isinstance(initial_user_message_obj.content, list):
            for item in initial_user_message_obj.content:
                if isinstance(item, dict) and item.get("type") == "text":
                    initial_user_text = item.get("text", ""); break
        if not initial_user_text:
            print("!! éŒ¯èª¤ï¼šç„¡æ³•å¾åˆå§‹ HumanMessage æå–æ–‡æœ¬å…§å®¹ã€‚")
            return {"messages": [AIMessage(content="å…§éƒ¨éŒ¯èª¤ï¼šç„¡æ³•è§£æåˆå§‹ç”¨æˆ¶è«‹æ±‚æ–‡æœ¬ã€‚")]}
        print(f"  ä½¿ç”¨åˆå§‹æ–‡æœ¬ '{initial_user_text[:100]}...' ä½œç‚ºåŸºç¤ã€‚")

        # PLAN_PREFIX = "[ç›®æ¨™éšæ®µè¨ˆåŠƒ]:\n" # <<< ç§»é™¤æ­¤è™•çš„å±€éƒ¨å®šç¾© >>>
        plan_exists = any(
            isinstance(msg, AIMessage) and isinstance(msg.content, str) and msg.content.strip().startswith(PLAN_PREFIX)
            for msg in current_messages
        )

        # ========================
        # === PLANNING PHASE ===
        # ========================
        if not plan_exists:
            print(f"  æª¢æ¸¬åˆ°ç„¡è¨ˆåŠƒï¼Œé€²å…¥è¦åŠƒéšæ®µ...")
            # --- ç²å–å·¥å…·ç”¨æ–¼è¦åŠƒæç¤º ---
            mcp_tools = await get_mcp_tools(mcp_name)
            print(f"  ç²å–äº† {len(mcp_tools)} å€‹ {mcp_name} MCP å·¥å…· (ç”¨æ–¼è¦åŠƒæç¤º)ã€‚")
            if not mcp_tools: print(f"  è­¦å‘Šï¼šæœªæ‰¾åˆ° {mcp_name} å·¥å…·ï¼")

            # --- æ–°å¢: å°‡æœ¬åœ°å·¥å…·åŠ å…¥åˆ—è¡¨ ---
            all_available_tools = mcp_tools + LOCAL_TOOLS
            print(f"  æä¾›çµ¦è¦åŠƒå¸«çš„å·¥å…·ç¸½æ•¸: {len(all_available_tools)} (MCP: {len(mcp_tools)}, Local: {len(LOCAL_TOOLS)})")

            # --- é¸æ“‡è¦åŠƒæç¤º ---
            active_planning_prompt_content = ""
            if mcp_name in ["rhino", "revit"]:
                active_planning_prompt_content = """ä½ æ˜¯ä¸€ä½å„ªç§€çš„ä»»å‹™è¦åŠƒåŠ©ç†ï¼Œå°ˆé–€ç‚º CAD/BIM ä»»å‹™åˆ¶å®šè¨ˆåŠƒã€‚
            åŸºæ–¼ä½¿ç”¨è€…æä¾›çš„æ–‡å­—è«‹æ±‚ã€å¯é¸çš„åœ–åƒä»¥åŠä¸‹æ–¹åˆ—å‡ºçš„å¯ç”¨å·¥å…·ï¼Œç”Ÿæˆä¸€å€‹æ¸…æ™°çš„ã€**åˆ†éšæ®µç›®æ¨™**çš„è¨ˆåŠƒã€‚

            **é‡è¦è¦æ±‚ï¼š**
            1.  **ç´°ç·»çš„åˆ†æ­¥è¦åŠƒ (æ¥µåº¦é‡è¦):** 
                * å°‡ä»»å‹™æ‹†è§£ç‚º**éå¸¸ç´°ç·»çš„å°æ­¥é©Ÿ**ï¼Œæ¯å€‹æ­¥é©Ÿæ‡‰è©²æ˜¯ä¸€å€‹å¯ä»¥ç¨ç«‹å®Œæˆçš„åŸå­æ“ä½œ
                * **é¿å…åœ¨å–®ä¸€æ­¥é©Ÿä¸­åŒ…å«éå¤šæ“ä½œ**ã€‚ä¾‹å¦‚ï¼Œ"å‰µå»ºæ‰€æœ‰æ‹±å½¢è‚‹æ¢"æ‡‰æ‹†åˆ†ç‚ºï¼š"å‰µå»ºç¬¬ä¸€å€‹æ‹±å½¢è‚‹æ¢è¼ªå»“" â†’ "æ“ å‡ºç¬¬ä¸€å€‹è‚‹æ¢" â†’ "é™£åˆ—è¤‡è£½è‚‹æ¢"
                * **ä»£ç¢¼è¤‡é›œåº¦è€ƒé‡:** æ¯å€‹æ­¥é©Ÿæ‡‰è©²å°æ‡‰ä¸è¶…é 50-80 è¡Œçš„ä»£ç¢¼é‡
                * å¦‚æœæŸå€‹æ“ä½œæ¶‰åŠå¤šå€‹å­ç‰©ä»¶æˆ–é‡è¤‡å‹•ä½œï¼Œæ‡‰è©²è¦åŠƒç‚ºå¤šå€‹ç¨ç«‹æ­¥é©Ÿ
            2.  **é‡åŒ–èˆ‡å…·é«”åŒ–:** å°æ–¼å¹¾ä½•æ“ä½œ (Rhino/Revit)ï¼Œæ¯å€‹éšæ®µç›®æ¨™**å¿…é ˆ**åŒ…å«ç›¡å¯èƒ½å¤šçš„**å…·é«”æ•¸å€¼ã€å°ºå¯¸ã€åº§æ¨™ã€è§’åº¦ã€æ•¸é‡ã€è·é›¢ã€æ–¹å‘ã€æˆ–æ¸…æ™°çš„ç©ºé–“é—œä¿‚æè¿°**ã€‚
            3.  **é‚è¼¯é †åº:** ç¢ºä¿éšæ®µç›®æ¨™æŒ‰é‚è¼¯é †åºæ’åˆ—ï¼Œå¾ŒçºŒæ­¥é©Ÿä¾è³´æ–¼å…ˆå‰æ­¥é©Ÿçš„çµæœã€‚
            4.  **åŸºåœ°èˆ‡åº§æ¨™ç³»çµ±æ„è­˜ (Rhino - æ¥µåº¦é‡è¦):**
                *   **ç¢ºç«‹åŸºæº–æ–¹ä½:** åœ¨é€²è¡Œä»»ä½•èˆ‡åŸºåœ°ä½ˆå±€ç›¸é—œçš„è¦åŠƒæ™‚ï¼Œ**ç¬¬ä¸€æ­¥å¿…é ˆæ˜¯ç¢ºç«‹ä¸€å€‹æ¸…æ™°çš„åº§æ¨™ç³»çµ±å’Œæ–¹å‘åŸºæº–**ã€‚æ˜ç¢ºå®šç¾©ã€ŒåŒ—ã€æ–¹èˆ‡å…¶ä»–ã€Œæ±ã€è¥¿ã€å—ã€å°æ‡‰çš„å‘é‡ï¼ˆä¾‹å¦‚ï¼Œä¸–ç•Œåº§æ¨™çš„Yè»¸æ­£æ–¹å‘ `(0, 1, 0)`ï¼‰ï¼Œä¸¦åœ¨å¾ŒçºŒæ‰€æœ‰æ­¥é©Ÿä¸­åš´æ ¼éµå®ˆæ­¤åŸºæº–ã€‚
                *   **é‚Šç•Œæ„è­˜:** å¦‚æœä»»å‹™æä¾›äº†åŸºåœ°é‚Šç•Œï¼Œ**å¿…é ˆ**å°‡è™•ç†åŸºåœ°é‚Šç•Œä½œç‚ºå„ªå…ˆæ­¥é©Ÿã€‚
                    *   a. è¦åŠƒå‰µå»ºæˆ–è­˜åˆ¥ä»£è¡¨åŸºåœ°é‚Šç•Œçš„æ›²ç·šã€‚
                    *   b. åœ¨è¦åŠƒæ”¾ç½®ä»»ä½•å»ºç¯‰é‡é«”ã€é“è·¯æˆ–æ™¯è§€å…ƒç´ ä¹‹å‰ï¼Œ**å¿…é ˆ**å…ˆé©—è­‰å…¶é è¨ˆä½ç½®**å®Œå…¨ä½æ–¼**å·²å®šç¾©çš„åŸºåœ°é‚Šç•Œå…§éƒ¨ã€‚å¯ä»¥è¦åŠƒç²å–åŸºåœ°é‚Šç•Œçš„ bounding box ä½œç‚ºå¿«é€Ÿæª¢æŸ¥ã€‚
            5.  **ç©ºé–“ä½ˆå±€è¦åŠƒ (Rhino):**
                    *   ç•¶ä»»å‹™æ¶‰åŠç©ºé–“é…ç½®æˆ–å¤šå€‹é‡é«”çš„ä½ˆå±€æ™‚ï¼Œè¨ˆåŠƒæ‡‰æ˜ç¢ºæè¿°é€™äº›é‡é«”ä¹‹é–“çš„**æ‹“æ’²é—œä¿‚** (å¦‚ç›¸é„°ã€å…±äº«é¢ã€åŒ…å«) å’Œ**ç›¸å°ä½ç½®** (å¦‚Aåœ¨Bçš„ä¸Šæ–¹ï¼ŒCåœ¨Dçš„è¥¿å´ä¸¦åç§»Xå–®ä½)ã€‚
                    *   **ç©ºé–“å–®å…ƒåŒ–åŸå‰‡ï¼šåŸå‰‡ä¸Šï¼Œæ¯ä¸€å€‹ç¨ç«‹çš„åŠŸèƒ½ç©ºé–“ï¼ˆä¾‹å¦‚å®¢å»³ã€å–®ç¨çš„è‡¥å®¤ã€å»šæˆ¿ã€è¡›ç”Ÿé–“ç­‰ï¼‰éƒ½æ‡‰è©²è¦åŠƒç‚ºä¸€å€‹ç¨ç«‹çš„å¹¾ä½•é‡é«”ã€‚é¿å…ä½¿ç”¨å–®ä¸€é‡é«”ä»£è¡¨å¤šå€‹ä¸åŒçš„åŠŸèƒ½ç©ºé–“ã€‚ç‚ºæ¯å€‹è¦åŠƒç”Ÿæˆçš„ç¨ç«‹ç©ºé–“é‡é«”æˆ–é‡è¦å‹•ç·šå…ƒç´ æŒ‡å®šä¸€å€‹æœ‰æ„ç¾©çš„è‡¨æ™‚åç¨±æˆ–æ¨™è­˜ç¬¦ï¼Œä¸¦åœ¨å¾ŒçºŒçš„å»ºæ¨¡æ­¥é©Ÿä¸­é€šé Rhino çš„ `add_object_metadata()` åŠŸèƒ½å°‡æ­¤åç¨±è³¦äºˆå°æ‡‰çš„ Rhino ç‰©ä»¶ã€‚**
                    *   **åœ–å±¤è¦åŠƒ - åˆå§‹è¨­å®šï¼š** åœ¨é–‹å§‹ä»»ä½•å»ºæ¨¡æˆ–å‰µå»ºæ–°çš„æ–¹æ¡ˆ/åŸºç¤åœ–å±¤ (å¦‚ "æ–¹æ¡ˆA", "Floor_1") ä¹‹å‰ï¼Œ**å¿…é ˆ**è¦åŠƒä¸€å€‹æ­¥é©Ÿï¼šé¦–å…ˆç²å–ç•¶å‰å ´æ™¯ä¸­çš„æ‰€æœ‰åœ–å±¤åˆ—è¡¨ï¼Œç„¶å¾Œå°‡æ‰€æœ‰å·²å­˜åœ¨çš„**é ‚å±¤åœ–å±¤**åŠå…¶å­åœ–å±¤è¨­ç½®ç‚ºä¸å¯è¦‹ã€‚é€™æ¨£å¯ä»¥ç¢ºä¿åœ¨ä¸€å€‹ä¹¾æ·¨çš„ç’°å¢ƒä¸­é–‹å§‹æ–°çš„è¨­è¨ˆå·¥ä½œã€‚ä¹‹å¾Œå†å‰µå»ºä¸¦è¨­ç½®ç•¶å‰å·¥ä½œæ‰€éœ€çš„åœ–å±¤ã€‚
                    *   **åœ–å±¤è¦åŠƒ - å‹•ç·šè¡¨é”èˆ‡åˆ†å±¤ (Rhino):**
                        *   å°æ–¼**æ°´å¹³å‹•ç·š**ï¼ˆä¾‹å¦‚èµ°å»Šã€é€šé“ï¼‰ï¼Œå¦‚æœéœ€è¦è¦–è¦ºåŒ–ï¼Œå»ºè­°è¦åŠƒä½¿ç”¨éå¸¸è–„çš„æ¿ç‹€é‡é«”ä¾†ç¤ºæ„å…¶è·¯å¾‘å’Œå¯¬åº¦ã€‚é€™äº›æ°´å¹³å‹•ç·šå…ƒç´ **å¿…é ˆ**è¦åŠƒåˆ°å…¶æ‰€æœå‹™çš„æ¨“å±¤åœ–å±¤ä¸‹çš„**å­åœ–å±¤**ä¸­ï¼Œä¾‹å¦‚ï¼š`Floor_1::Corridors_F1` æˆ– `Floor_Ground::Horizontal_Circulation`ã€‚
                        *   å°æ–¼**å‚ç›´å‹•ç·š**ï¼ˆä¾‹å¦‚æ¨“æ¢¯ã€å¡é“ã€é›»æ¢¯äº•ï¼‰ï¼Œå‰‡æ‡‰è¦åŠƒä½¿ç”¨åˆé©çš„3Dé‡é«”ä¾†è¡¨é”å…¶ä½”æ“šçš„ç©ºé–“å’Œå½¢æ…‹ã€‚é€™äº›å‚ç›´å‹•ç·šå…ƒç´ é€šå¸¸è¦åŠƒåˆ°ä¸€å€‹ç¨ç«‹çš„é ‚å±¤åœ–å±¤ä¸‹ï¼Œä¾‹å¦‚ `Circulation::Vertical_Core` æˆ– `Stairs_Elevators`ã€‚
                        *   æ‰€æœ‰å‹•ç·šå…ƒç´ ä¹Ÿå¿…é ˆæ ¹æ“šå…¶æœå‹™çš„æ¨“å±¤æˆ–é€£æ¥é—œä¿‚ï¼Œæ­£ç¢ºåœ°è¦åŠƒåˆ°ç›¸æ‡‰çš„åœ–å±¤ä¸‹ã€‚
                    *   åœ¨é€²è¡Œè¤‡é›œçš„ç©ºé–“ä½ˆå±€è¦åŠƒæ™‚ï¼Œå¯ä»¥å…ˆ(ä»¥æ–‡å­—æè¿°çš„å½¢å¼)æ§‹æ€ä¸€å€‹2Då¹³é¢ä¸Šçš„é—œä¿‚è‰åœ–ï¼Œæ¨™è¨»å‡ºå„å€‹ç¨ç«‹ç©ºé–“é‡é«”å’Œå‹•ç·šçš„å¤§è‡´ä½ç½®ã€å°ºå¯¸å’Œé„°æ¥é—œä¿‚ï¼Œç„¶å¾Œå†å°‡æ­¤2Dé—œä¿‚è½‰åŒ–ç‚º3Då»ºæ¨¡æ­¥é©Ÿçš„è¦åŠƒã€‚
                *   è¦åŠƒæ™‚éœ€ä»”ç´°è€ƒæ…®ä¸¦ç¢ºä¿æœ€çµ‚ç”Ÿæˆçš„**é‡é«”æ•¸é‡ã€å„å€‹ç©ºé–“é‡é«”çš„å…·é«”ä½ç½®å’Œå°ºå¯¸**ç¬¦åˆè¨­è¨ˆæ„åœ–å’Œç©ºé–“é‚è¼¯ã€‚ **å°æ–¼æ¯å€‹å‰µå»ºçš„ç©ºé–“ï¼Œå¿…é ˆä½¿ç”¨ `rs.AddTextDot("ç©ºé–“åç¨±", (x,y,z))` åœ¨å…¶é‡é«”ä¸­å¿ƒé™„è¿‘æ¨™ç¤ºç©ºé–“åç¨±ã€‚çµ•å°ç¦æ­¢ä½¿ç”¨ `rs.AddText()` æˆ– `rs.SetUserText()`ã€‚**
            6.  **å¤šæ–¹æ¡ˆèˆ‡å¤šæ¨“å±¤è™•ç† (Rhino):**
                *   å¦‚æœç”¨æˆ¶è«‹æ±‚ä¸­æ˜ç¢ºè¦æ±‚"å¤šæ–¹æ¡ˆ"æˆ–"ä¸åŒé¸é …"ï¼Œ**å¿…é ˆ**å°‡æ¯å€‹æ–¹æ¡ˆè¦–ç‚ºä¸€å€‹**ç¨ç«‹çš„ã€å®Œæ•´çš„ä»»å‹™åºåˆ—**ä¾†è¦åŠƒã€‚
                *   ç‚ºæ¯å€‹æ–¹æ¡ˆæŒ‡å®šä¸€å€‹æ¸…æ™°çš„åç¨±æˆ–æ¨™è­˜ç¬¦ (ä¾‹å¦‚ "æ–¹æ¡ˆA_ç¾ä»£é¢¨æ ¼", "æ–¹æ¡ˆB_å‚³çµ±é¢¨æ ¼")ï¼Œä¸¦åœ¨æ•´å€‹æ–¹æ¡ˆçš„è¦åŠƒå’ŒåŸ·è¡Œéšæ®µä¸­ä½¿ç”¨æ­¤æ¨™è­˜ã€‚
                *   è¨ˆåŠƒæ‡‰æ¸…æ™°åœ°æ¨™ç¤ºæ¯å€‹æ–¹æ¡ˆçš„é–‹å§‹å’ŒçµæŸã€‚
                *   **å°æ–¼åŒ…å«å¤šå€‹æ¨“å±¤çš„è¨­è¨ˆæ–¹æ¡ˆï¼Œåœ¨å®Œæˆæ¯ä¸€æ¨“å±¤çš„ä¸»è¦å»ºæ¨¡å…§å®¹å¾Œï¼Œæ‡‰è¦åŠƒä¸€æ¬¡è©³ç´°çš„æˆªåœ–æ­¥é©Ÿã€‚å¤šæ–¹æ¡ˆè¦åŠƒæ™‚æ¯ä¸€æ–¹æ¡ˆå®Œæˆå¾Œä¹ŸåŒæ¨£ã€‚ (åƒè€ƒä¸‹æ–¹æˆªåœ–è¦åŠƒè©³ç´°æµç¨‹)ã€‚**
                *   å°æ–¼å¤šæ¨“å±¤å¯ä»¥è¦åŠƒåŒæ™‚å±•ç¤ºæ‰€æœ‰æ¨“å±¤çš„æˆªåœ–ç¸½è¦½ï¼Œä½†å°æ–¼å¤šæ–¹æ¡ˆä¸ç”¨ã€‚
            7.  **é€ å‹èˆ‡å½¢æ…‹è¦åŠƒ (Rhino):**
                *   ç•¶ä»»å‹™ç›®æ¨™æ¶‰åŠ'é€ å‹æ–¹æ¡ˆ'ã€'å½¢æ…‹ç”Ÿæˆ'æˆ–å°ç¾æœ‰é‡é«”é€²è¡Œ'å¤–è§€è¨­è¨ˆ'æ™‚ï¼Œè¦åŠƒéšæ®µæ‡‰ç©æ¥µè€ƒæ…®å¦‚ä½•åˆ©ç”¨å¸ƒæ—é‹ç®— (å¦‚åŠ æ³•ã€æ¸›æ³•ã€äº¤é›†) å’Œå¹¾ä½•è®Šæ› (å¦‚æ‰­è½‰ã€å½æ›²ã€é™£åˆ—ã€ç¸®æ”¾ã€æ—‹è½‰) ç­‰é«˜ç´šå»ºæ¨¡æŠ€å·§ä¾†é”æˆç¨ç‰¹ä¸”å…·æœ‰ç©ºé–“æ„Ÿçš„ã€Œè™›ã€å¯¦ã€å¹¾ä½•å½¢æ…‹ã€‚
                *   **å¦‚è¦å‰µé€ æ›´å…·ç‰¹æ®Šæ€§ã€æµå‹•æ€§æˆ–æœ‰æ©Ÿæ„Ÿçš„é€ å‹ï¼Œæ‡‰è€ƒæ…®ä¸¦è¦åŠƒä½¿ç”¨å¤šç¨®æ›²é¢ç”Ÿæˆèˆ‡ç·¨è¼¯æŠ€å·§ã€‚è¦åŠƒæ™‚æ‡‰è€ƒæ…®å·¥å…·çš„è¼¸å…¥è¦æ±‚ï¼š**
                    *   **æ›²é¢æ‡‰ç”¨æŠ€å·§ï¼š** å„ªå…ˆè¦åŠƒå¾æ›²ç·šæˆ–æ›²é¢å‰µå»º**å°é–‰å¯¦é«”**æˆ–æœ‰åšåº¦çš„æ›²é¢ï¼Œä¸è¦åªæ˜¯é–‹æ”¾æ›²é¢ã€‚æ‡‰ç”¨ä¸Šç›¡é‡ä¸è¦æ··é›œä¿æŒé€ å‹ç´”ç²¹æ€§ã€‚**åœ¨è¦åŠƒä¸­å¿…é ˆæ˜ç¢ºè¦æ±‚å°å‰µå»ºçš„æ›²é¢é€²è¡Œå°é–‰æ€§æª¢æŸ¥å’Œä¿®æ­£ã€‚**
                    *   **æ›²é¢å‰µå»ºé¡åˆ¥ï¼š**
                        *   **æƒæ  (Sweep):**
                            *   `rs.AddSweep1(rail_curve_id, shape_curve_ids)`: å°‡å‰–é¢æ›²ç·šåˆ—è¡¨ `shape_curve_ids` æ²¿å–®ä¸€è»Œé“ `rail_curve_id` æƒæ æˆæ›²é¢ã€‚æ³¨æ„å‰–é¢æ›²ç·šçš„æ–¹å‘å’Œé †åºã€‚
                            *   `rs.AddSweep2(rail_curve_ids, shape_curve_ids)`: å°‡å‰–é¢æ›²ç·šåˆ—è¡¨ `shape_curve_ids` æ²¿å…©å€‹è»Œé“åˆ—è¡¨ `rail_curve_ids` æƒæ æˆæ›²é¢ã€‚æ³¨æ„å‰–é¢æ›²ç·šçš„æ–¹å‘ã€é †åºåŠèˆ‡è»Œé“çš„æ¥è§¸ã€‚
                        *   **æ”¾æ¨£ (Loft):**
                            *   `rs.AddLoftSrf(curve_ids, start_pt=None, end_pt=None, type=0, style=0, simplify=0, closed=False)`: åœ¨æœ‰åºçš„æ›²ç·šåˆ—è¡¨ `curve_ids` ä¹‹é–“å‰µå»ºæ”¾æ¨£æ›²é¢ã€‚æ³¨æ„æ›²ç·šæ–¹å‘å’Œæ¥ç¸«é»ã€‚å¯æŒ‡å®šé¡å‹ã€æ¨£å¼ç­‰ã€‚
                        *   **ç¶²æ ¼æ›²é¢ (Network Surface):**
                            *   `rs.AddNetworkSrf(curve_ids)`: å¾ä¸€çµ„ç›¸äº¤çš„æ›²ç·šç¶²çµ¡ `curve_ids` å‰µå»ºæ›²é¢ã€‚æ‰€æœ‰ U æ–¹å‘æ›²ç·šå¿…é ˆèˆ‡æ‰€æœ‰ V æ–¹å‘æ›²ç·šç›¸äº¤ã€‚
                        *   **å¹³é¢æ›²é¢ (Planar Surface):**
                            *   `rs.AddPlanarSrf(curve_ids)`: å¾ä¸€å€‹æˆ–å¤šå€‹å°é–‰çš„*å¹³é¢*æ›²ç·šåˆ—è¡¨ `curve_ids` å‰µå»ºå¹³é¢æ›²é¢ã€‚æ›²ç·šå¿…é ˆå…±é¢ä¸”å°é–‰ã€‚
                    *   **å¯¦é«”å‰µå»ºé¡åˆ¥ï¼š**
                        *   **æ“ å‡º (Extrusion):**
                            *   `rs.ExtrudeCurve(curve_id, path_curve_id)`: å°‡è¼ªå»“ç·š `curve_id` æ²¿è·¯å¾‘æ›²ç·š `path_curve_id` æ“ å‡ºæˆæ›²é¢ã€‚
                            *   `rs.ExtrudeCurveStraight(curve_id, start_point, end_point)` æˆ– `rs.ExtrudeCurveStraight(curve_id, direction_vector)`: å°‡æ›²ç·š `curve_id` æ²¿ç›´ç·šæ“ å‡ºæŒ‡å®šè·é›¢å’Œæ–¹å‘ã€‚
                            *   `rs.ExtrudeCurveTapered(curve_id, distance, direction, base_point, angle)`: å°‡æ›²ç·š `curve_id` æ²¿ `direction` æ–¹å‘æ“ å‡º `distance` è·é›¢ï¼ŒåŒæ™‚ä»¥ `base_point` ç‚ºåŸºæº–ã€æŒ‰ `angle` è§’åº¦é€²è¡ŒéŒåŒ–ã€‚
                            *   `rs.ExtrudeSurface(surface_id, path_curve_id, cap=True/False)`: å°‡æ›²é¢ `surface_id` æ²¿è·¯å¾‘æ›²ç·š `path_curve_id` æ“ å‡ºæˆå¯¦é«”æˆ–é–‹æ”¾å½¢ç‹€ï¼Œå¯é¸æ˜¯å¦å°å£ (`cap`)ã€‚
                    *   **å°é–‰æ€§æª¢æŸ¥è¦åŠƒ (æ¥µåº¦é‡è¦):**
                        *   è¦åŠƒä¸­å¿…é ˆåŒ…å«ç¨ç«‹çš„æ­¥é©Ÿä¾†æª¢æŸ¥ä¸¦ä¿®æ­£æ›²é¢çš„å°é–‰æ€§
                        *   ä½¿ç”¨ `rs.IsClosed()` æª¢æŸ¥ç‰©ä»¶æ˜¯å¦å°é–‰ï¼Œä½¿ç”¨ `rs.CapPlanarHoles()` å°é–‰å¹³é¢é–‹å£
                        *   å°æ–¼æ“ å‡ºæ“ä½œï¼Œè¦åŠƒæ™‚æ‡‰æ˜ç¢ºæŒ‡å®šä½¿ç”¨ `cap=True` ä¾†è‡ªå‹•å°é–‰ç«¯é¢
                        *   å„ªå…ˆè¦åŠƒä½¿ç”¨èƒ½ç›´æ¥ç”Ÿæˆå°é–‰å¯¦é«”çš„å»ºæ¨¡æ–¹æ³•
                *   åœ¨è¨ˆåŠƒä¸­æ˜ç¢ºæŒ‡å‡ºé è¨ˆåœ¨å“ªäº›æ­¥é©Ÿä½¿ç”¨é€™äº›æŠ€å·§ï¼Œä»¥åŠé æœŸé”æˆçš„å½¢æ…‹æ•ˆæœå’Œæ‰€éœ€çš„è¼¸å…¥ç‰©ä»¶ã€‚é€ å‹ä¸Šæ‡‰å…·æœ‰ç‰¹æ®Šçš„ç¾å­¸åƒ¹å€¼ä¸¦ç¬¦åˆè¨­è¨ˆæ¦‚å¿µã€‚
            8.  **åœ–åƒåƒè€ƒè¦åŠƒ (è‹¥æœ‰æä¾›åœ–åƒ):**
                *   åœ¨ç”Ÿæˆå…·é«”çš„å»ºæ¨¡è¨ˆåŠƒä¹‹å‰ï¼Œ**å¿…é ˆ**å…ˆé€²è¡Œè©³ç´°çš„"åœ–åƒåˆ†æèˆ‡è§£è®€"éšæ®µã€‚
                *   è¦åŠƒæ™‚æ‡‰åŸºæ–¼ï¼šè§€å¯Ÿåˆ°çš„ä¸»è¦å»ºç¯‰é«”å¡Šçµ„æˆå’Œå®ƒå€‘ä¹‹é–“çš„**ç©ºé–“å¸ƒå±€é—œä¿‚**ï¼ˆä¾‹å¦‚ï¼Œç©¿æ’ã€ä¸¦åˆ—ã€å †ç–Šï¼‰ï¼›ä¼°è¨ˆä¸»è¦éƒ¨åˆ†ä¹‹é–“çš„ç²¾ç¢ºé•·ã€å¯¬ã€é«˜æ¯”ä¾‹é—œä¿‚ï¼›ä¸»æ¬¡è¦é‡é«”çš„ä½ç½®é—œä¿‚ï¼›ä¸»è¦çš„ç«‹é¢ç‰¹å¾µï¼ˆé‡é»æ˜¯æ•´é«”å½¢æ…‹ï¼‰ï¼›æŸ±å­åŠå…¶ä»–ç‰¹æ®Šå½¢å¼ã€‚
                *   **å¿…é ˆ**å°‡ä¸Šè¿°åœ–åƒåˆ†æå¾—å‡ºçš„è§€å¯Ÿçµæœï¼Œè½‰åŒ–ç‚ºå¾ŒçºŒ Rhino å»ºæ¨¡æ­¥é©Ÿä¸­çš„å…·é«”åƒæ•¸å’Œæ“ä½œæŒ‡å°ã€‚**éœ€ç‰¹åˆ¥æ³¨æ„çµ•å°åº§æ¨™ä¸Šçš„ä½ç½®é—œä¿‚ï¼›æ–¹é«”çš„é«˜åº¦åŠè§’åº¦é—œä¿‚ï¼›é•·çŸ­é‚Šçš„æ–¹å‘é—œä¿‚ï¼Œä»¥æ§‹æˆç¬¦åˆåœ–ç‰‡ç›®æ¨™çš„å»ºç¯‰å¡Šé«”ã€‚**
                *   **å¦‚æœä»»å‹™æ˜¯åƒè€ƒåœ–ç‰‡é€²è¡Œç©ºé–“ä½ˆå±€(æˆ–é‡é«”é…ç½®)è¦åŠƒï¼Œè¦åœ¨ä¸»è¦å»ºç¯‰å¡Šé«”çš„é—œä¿‚ä¸‹ç™¼å±•è©³ç´°é‡é«”åŠç©ºé–“é…ç½®ã€‚ä¸éœ€è¦å»ºç«‹ç²¾ç¢ºç«‹é¢ç­‰ç´°éƒ¨ç‰¹å¾µã€‚**
            9.  **æˆªåœ–è¦åŠƒè©³ç´°æµç¨‹ (Rhino/Revit):**
                *   **æˆªåœ–ç­–ç•¥ï¼š** è¦åŠƒæ‡‰åˆ†ç‚ºå…©å€‹ä¸»è¦æˆªåœ–éšæ®µï¼Œä»¥ç¢ºä¿æˆæœçš„å®Œæ•´å±•ç¤ºï¼š
                    1.  **æ•´é«”è¦–åœ–éšæ®µï¼š** åœ¨æ‰€æœ‰ä¸»è¦å»ºæ¨¡æ­¥é©Ÿå®Œæˆå¾Œï¼Œé¦–å…ˆè¦åŠƒç”Ÿæˆä¸€åˆ°å…©å€‹èƒ½å¤ å±•ç¤ºæ•´é«”è¨­è¨ˆçš„**é€è¦– (`perspective`) æˆ–å…©é»é€è¦– (`two_point`)** è¦–åœ–ã€‚åœ¨åŸ·è¡Œæ­¤éšæ®µçš„æˆªåœ–æ™‚ï¼Œ**å¿…é ˆç¢ºä¿æ‰€æœ‰èˆ‡è¨­è¨ˆæ–¹æ¡ˆç›¸é—œçš„åœ–å±¤ï¼ˆä¾‹å¦‚æ‰€æœ‰æ¨“å±¤ã€å¤–éƒ¨é€ å‹ã€åŸºåœ°ç­‰ï¼‰éƒ½æ˜¯å¯è¦‹çš„**ï¼Œä»¥å‘ˆç¾å®Œæ•´çš„æ¨¡å‹ã€‚
                    2.  **åˆ†å±¤å¹³é¢åœ–éšæ®µï¼š** å¦‚æœæ˜¯é‡é«”æˆ–å¹³é¢è¦åŠƒä»»å‹™ï¼Œåœ¨æ•´é«”è¦–åœ–æˆªåœ–å®Œæˆå¾Œï¼Œå†é‡å°**æ¯ä¸€å€‹æ¨“å±¤**è¦åŠƒç”Ÿæˆå–®ç¨çš„ã€**ä¿¯è¦–çš„å¹³è¡ŒæŠ•å½± (`parallel`)** è¦–åœ–ã€‚åœ¨åŸ·è¡Œæ­¤éšæ®µçš„æˆªåœ–æ™‚ï¼Œ**å¿…é ˆåªé¡¯ç¤ºç•¶å‰æ­£åœ¨æˆªåœ–çš„æ¨“å±¤åœ–å±¤**ï¼Œä¸¦éš±è—æ‰€æœ‰å…¶ä»–ä¸ç›¸é—œçš„æ¨“å±¤åœ–å±¤ï¼Œä»¥ç¢ºä¿å¹³é¢åœ–çš„æ¸…æ™°æ€§ã€‚
                *   **æ¯å¼µæˆªåœ–çš„è©³ç´°æ­¥é©Ÿï¼š**
                    a.  **è¨­å®šè¦–åœ–èˆ‡æŠ•å½±ï¼š** æ˜ç¢ºæŒ‡å®šæŠ•å½±æ¨¡å¼ (`perspective`, `two_point`, `parallel`) ä¸¦è¨­å®šé©ç•¶çš„é¡é ­è§’åº¦ã€‚
                    b.  **ç®¡ç†åœ–å±¤å¯è¦‹æ€§ (é—œéµ)ï¼š** è¦åŠƒç²å–ç•¶å‰å ´æ™¯ä¸­æ‰€æœ‰åœ–å±¤çš„åˆ—è¡¨å¾Œï¼Œæ ¹æ“šä¸Šè¿°çš„ã€Œæ•´é«”è¦–åœ–ã€æˆ–ã€Œåˆ†å±¤å¹³é¢åœ–ã€ç­–ç•¥ï¼Œç²¾ç¢ºåœ°è¦åŠƒé¡¯ç¤ºæˆ–éš±è—å“ªäº›åœ–å±¤ã€‚
                    c.  **è¨­å®šç›¸æ©Ÿ (å¯é¸ä½†å»ºè­°)ï¼š** å°æ–¼é€è¦–åœ–ï¼Œè¦åŠƒè¨­å®šç›¸æ©Ÿä½ç½®(`camera_position`)åƒæ•¸ç‚ºé«˜åº¦èˆ‡é¡é ­è§’åº¦(`z, lens_angle`) å’Œç›®æ¨™é» (`target_position`)ï¼Œä»¥ç²å¾—æœ€ä½³è¦–è§’ã€‚é³¥ç°è¦–è§’å¯ä»¥æ›´é«˜ã€‚**ä¸è«–ä½•æ™‚ï¼Œå¿…é ˆç¢ºä¿ç›¸æ©Ÿæ—‹è½‰è¨­å®šç‚º0ï¼Œåˆ‡å‹¿è®“å…¶è®Šç‚º-90åº¦ã€‚**
                    d.  **åŸ·è¡Œæˆªåœ–ï¼š** è¦åŠƒèª¿ç”¨ `capture_focused_view` å·¥å…·ã€‚ å»ºè­°è¨­å®šç›¸æ©Ÿå¾Œé‚„è¦ä½¿ç”¨zoomåŠŸèƒ½é–å®šç›®æ¨™ã€‚ 
            10.  **ç›®æ¨™ç‹€æ…‹:** è¨ˆåŠƒæ‡‰å´é‡æ–¼**æ¯å€‹éšæ®µè¦é”æˆçš„ç›®æ¨™ç‹€æ…‹**ï¼Œèªªæ˜è©²éšæ®µå®Œæˆå¾Œå ´æ™¯æ‡‰æœ‰çš„è®ŠåŒ–ã€‚
                *   **æœ€å¾Œä¸€å€‹è¨ˆåŠƒæ‡‰åŒ…å«"å…¨éƒ¨ä»»å‹™å·²å®Œæˆ"æ™‚çš„ç›¸é—œè¡Œå‹•ï¼Œå¼•å°å¯¦éš›åŸ·è¡Œæ™‚çš„è™•ç†ã€‚**
            11.  **è¦åŠƒæ•¸æ“šæ‘˜è¦å ±å‘Š (ç©ºé–“è¦åŠƒä»»å‹™çš„å¿…è¦é¦–æ­¥):**
                *   **åƒ…ç•¶**ä»»å‹™æ˜¯é—œæ–¼**ç©ºé–“ä½ˆå±€è¦åŠƒ** (ä¾‹å¦‚ï¼Œé‡é«”é…ç½®ç­‰)ï¼Œä½ **å¿…é ˆ**å°‡ç”Ÿæˆæ‘˜è¦å ±å‘Šä½œç‚ºè¨ˆåŠƒçš„**ç¬¬ä¸€å€‹æ­¥é©Ÿ**ã€‚
                *   **æ­¤æ­¥é©ŸåŸºæ–¼ä½ å³å°‡åˆ¶å®šçš„å¾ŒçºŒå»ºæ¨¡æ­¥é©Ÿï¼Œå…ˆè¡Œç¸½çµå’Œå ±å‘Šè¦åŠƒçš„é‡åŒ–æ•¸æ“šã€‚å¦‚æœæ˜¯è¦æ±‚åˆ†æå·²æœ‰çš„æ–¹æ¡ˆï¼Œå‰‡æ‡‰è©²è¦å…ˆåˆ†æå†é€²è¡Œæ•¸æ“šæ‘˜è¦æ•´ç†ã€‚**
                *   **è¦åŠƒçš„ç¬¬ä¸€æ­¥æ‡‰å¦‚ä¸‹ï¼š**
                    1.  **é å…ˆåŒ¯ç¸½:** åœ¨è…¦ä¸­æ§‹æ€å¥½æ‰€æœ‰å»ºæ¨¡æ­¥é©Ÿå¾Œï¼Œå¯©æŸ¥ä½ è¨ˆåŠƒè¦å‰µå»ºçš„æ‰€æœ‰ç©ºé–“ï¼ˆå¦‚å®¢å»³ã€è‡¥å®¤ç­‰ï¼‰çš„åç¨±ã€**æ‰€å±¬æ¨“å±¤**å’Œå…·é«”å°ºå¯¸/é¢ç©ã€‚
                    2.  **è¨ˆç®—åŒ¯ç¸½æ•¸æ“š:** åŸºæ–¼é€™äº›è¦åŠƒæ•¸å€¼ï¼Œè¨ˆç®—å‡ºç¸½é¢ç©ã€æ¯å€‹ç©ºé–“çš„é¢ç©ä½”æ¯”ï¼Œä»¥åŠå»ºè”½ç‡(BCR)å’Œå®¹ç©ç‡(FAR)ï¼ˆå¦‚æœé©ç”¨ï¼‰ã€‚
                    3.  **è¦åŠƒé¦–å€‹å·¥å…·èª¿ç”¨:** å°‡åŒ¯ç¸½å¥½çš„æ•¸æ“šï¼ˆ`data_rows` - å…¶ä¸­æ¯å€‹ç©ºé–“å­—å…¸éœ€åŒ…å« `name`, `area`, `percentage` **å’Œ `floor`**ï¼Œ`total_area`, `bcr`, `far`ï¼‰ä½œç‚ºåƒæ•¸ï¼Œå°‡å° `create_planned_data_summary_csv` å·¥å…·çš„èª¿ç”¨è¦åŠƒç‚ºæ•´å€‹è¨ˆåŠƒçš„**ç¬¬ 1 æ­¥**ã€‚
                    4.  **å¾ŒçºŒæ­¥é©Ÿ:** åœ¨æ­¤å ±å‘Šæ­¥é©Ÿä¹‹å¾Œï¼Œå†ä¾æ¬¡åˆ—å‡ºæ‰€æœ‰å¯¦éš›çš„ Rhino æ¨¡å‹å»ºæ§‹æ­¥é©Ÿã€‚

            **rhinoæé†’:ç›®å‰å–®ä½æ˜¯å…¬åˆ†ã€‚**é€™å€‹è¨ˆåŠƒæ‡‰å´é‡æ–¼**æ¯å€‹éšæ®µè¦é”æˆçš„ç›®æ¨™ç‹€æ…‹ä¸¦åŒ…å«ç´°ç¯€**ï¼Œè€Œä¸æ˜¯å…·é«”çš„å·¥å…·ä½¿ç”¨ç´°ç¯€ã€‚å°‡ä»»å‹™åˆ†è§£æˆç¬¦åˆé‚è¼¯é †åºåŠç´°ç¯€çš„å¤šå€‹éšæ®µç›®æ¨™ã€‚ç›´æ¥è¼¸å‡ºé€™å€‹éšæ®µæ€§ç›®æ¨™è¨ˆåŠƒï¼Œä¸è¦é¢å¤–çš„é–‹å ´ç™½æˆ–è§£é‡‹ã€‚
            å¯ç”¨å·¥å…·å¦‚ä¸‹ ({mcp_name}):
            {tool_descriptions}"""
            elif mcp_name == "pinterest":
                # Define Pinterest planning prompt content here or use a global variable
                active_planning_prompt_content = f"""ç”¨æˆ¶è«‹æ±‚ä½¿ç”¨ Pinterest é€²è¡Œåœ–ç‰‡æœç´¢ã€‚
                å¯ç”¨å·¥å…· ({mcp_name}):
                - pinterest_search_and_download: {{"description": "Searches Pinterest for images based on a keyword and downloads them. Args: keyword (str), limit (int, optional)."}}
                è«‹åˆ¶å®šä¸€å€‹å–®ä¸€æ­¥é©Ÿè¨ˆåŠƒä¾†ä½¿ç”¨ pinterest_search_and_download å·¥å…·ï¼Œç›®æ¨™æ˜¯æ ¹æ“šç”¨æˆ¶è«‹æ±‚æœç´¢ä¸¦ä¸‹è¼‰åœ–ç‰‡ã€‚
                è¨ˆåŠƒçš„æœ€çµ‚æ­¥é©Ÿæ‡‰æ˜ç¢ºæŒ‡å‡ºèª¿ç”¨ `pinterest_search_and_download`ã€‚"""
            elif mcp_name == "osm":
                 # Define OSM planning prompt content here or use a global variable
                 active_planning_prompt_content = f"""ç”¨æˆ¶è«‹æ±‚ä½¿ç”¨ OpenStreetMap ç”Ÿæˆåœ°åœ–æˆªåœ–ã€‚
                 å¯ç”¨å·¥å…· ({mcp_name}):
                 - geocode_and_screenshot: {{"description": "Geocodes an address or uses coordinates to take a screenshot from OpenStreetMap. Args: address (str: address or 'lat,lon')."}}
                 è«‹åˆ¶å®šä¸€å€‹å–®ä¸€æ­¥é©Ÿè¨ˆåŠƒä¾†ä½¿ç”¨ geocode_and_screenshot å·¥å…·ï¼Œç›®æ¨™æ˜¯æ ¹æ“šç”¨æˆ¶è«‹æ±‚ç”Ÿæˆåœ°åœ–æˆªåœ–ã€‚
                 è¨ˆåŠƒçš„æœ€çµ‚æ­¥é©Ÿæ‡‰æ˜ç¢ºæŒ‡å‡ºèª¿ç”¨ `geocode_and_screenshot`ã€‚"""
            else: # Fallback
                tool_descriptions_for_fallback_str = "\n".join([f"- {tool.name}: {tool.description}" for tool in mcp_tools])
                active_planning_prompt_content = f"è«‹ç‚ºä½¿ç”¨ {mcp_name} çš„ä»»å‹™åˆ¶å®šè¨ˆåŠƒã€‚å¯ç”¨å·¥å…·ï¼š\n{tool_descriptions_for_fallback_str}"

            # --- æ ¼å¼åŒ–è¦åŠƒæç¤º (Only for Rhino/Revit as others have descriptions embedded or generated above) ---
            planning_system_content_final = active_planning_prompt_content
            if mcp_name in ["rhino", "revit"]:
                tool_descriptions_for_prompt = "\n".join([f"- {tool.name}: {tool.description}" for tool in all_available_tools])
                planning_system_content_final = active_planning_prompt_content.format(
                    mcp_name=mcp_name,
                    tool_descriptions=tool_descriptions_for_prompt
                )
            # Note: No formatting needed for Pinterest/OSM/Fallback as their prompts are already complete strings

            planning_system_message = SystemMessage(content=planning_system_content_final)
            print(f"    ç‚º {mcp_name} æ§‹é€ äº†è¦åŠƒ SystemMessage")

            # --- æ§‹é€ è¦åŠƒ HumanMessage ---
            planning_human_content = [{"type": "text", "text": initial_user_text}]
            if has_input_image:
                try:
                    with open(initial_image_path, "rb") as img_file: img_bytes = img_file.read()
                    img_base64 = base64.b64encode(img_bytes).decode('utf-8')
                    # Determine mime type properly if possible, default to png
                    mime_type="image/png"
                    file_ext = os.path.splitext(initial_image_path)[1].lower()
                    if file_ext in ['.jpg', '.jpeg']: mime_type = 'image/jpeg'
                    elif file_ext == '.gif': mime_type = 'image/gif'
                    elif file_ext == '.webp': mime_type = 'image/webp'

                    planning_human_content.append({
                        "type": "image_url",
                        "image_url": {"url": f"data:{mime_type};base64,{img_base64}"}
                    })
                    print("    å·²å°‡åˆå§‹åœ–ç‰‡æ·»åŠ åˆ°è¦åŠƒ HumanMessage ä¸­ã€‚")
                except Exception as img_read_err:
                    print(f"    !! ç„¡æ³•è®€å–æˆ–ç·¨ç¢¼åˆå§‹åœ–ç‰‡: {img_read_err}")
                    # Fallback to text only if image fails
                    planning_human_content = [{"type": "text", "text": initial_user_text}]

            # Ensure content is always a list for multi-modal models
            if not isinstance(planning_human_content, list):
                 planning_human_content = [{"type": "text", "text": str(planning_human_content)}] # Should not happen with above logic, but safe fallback

            planning_human_message_user_input = HumanMessage(content=planning_human_content)

            # --- èª¿ç”¨ LLM é€²è¡Œè¦åŠƒ ---
            print(f"     æ­£åœ¨èª¿ç”¨ LLM ({agent_llm.model}) é€²è¡Œè¦åŠƒ...")
            plan_message = None
            try:
                # Use the main agent LLM for planning
                planning_llm_no_callbacks = agent_llm.with_config({"callbacks": None})
                planning_response = await planning_llm_no_callbacks.ainvoke(
                    [planning_system_message, planning_human_message_user_input]
                )

                if isinstance(planning_response, AIMessage) and planning_response.content:
                    # Prepend the prefix to identify it as a plan
                    plan_content = PLAN_PREFIX + planning_response.content.strip()
                    plan_message = AIMessage(content=plan_content)
                    print(f"  ç”Ÿæˆéšæ®µç›®æ¨™è¨ˆåŠƒ:\n------\n{plan_content[:500]}...\n------")
                else:
                    # Handle cases where planning LLM failed or returned unexpected format
                    error_msg = "LLM æœªèƒ½ç”Ÿæˆæœ‰æ•ˆè¨ˆåŠƒã€‚"
                    if isinstance(planning_response, AIMessage) and not planning_response.content:
                         error_msg += " (å›æ‡‰å…§å®¹ç‚ºç©º)"
                    elif not isinstance(planning_response, AIMessage):
                         error_msg += f" (è¿”å›é¡å‹ç‚º {type(planning_response).__name__})"
                    print(f"  !! {error_msg}")
                    plan_message = AIMessage(content=f"ç„¡æ³•ç‚ºæ‚¨çš„è«‹æ±‚åˆ¶å®šè¨ˆåŠƒã€‚({error_msg})") # Provide some error info

            except Exception as planning_err:
                 error_msg = f"èª¿ç”¨è¦åŠƒ LLM æ™‚ç™¼ç”ŸéŒ¯èª¤: {planning_err}"
                 print(f"  !! {error_msg}")
                 traceback.print_exc()
                 plan_message = AIMessage(content=error_msg) # Return the error message
            finally:
                rpm_delay = state.get("rpm_delay", 6.5)
                print(f"     è¦åŠƒ LLM èª¿ç”¨çµæŸï¼Œç­‰å¾… {rpm_delay} ç§’...")
                await asyncio.sleep(rpm_delay)
                print("     ç­‰å¾…çµæŸã€‚")

            # --- *** è¦åŠƒå®Œæˆå¾Œç›´æ¥è¿”å›ï¼Œè§¸ç™¼ should_continue *** ---
            # Return the plan message (or error message if planning failed)
            # Reset counter as this node completed its current task (planning)
            return {"messages": [plan_message] if plan_message else [], "consecutive_llm_text_responses": 0, "last_executed_node": f"{mcp_name}_agent"}

        # ==========================
        # === EXECUTION PHASE ===
        # ==========================
        else:
            print(f"  æª¢æ¸¬åˆ°å·²æœ‰è¨ˆåŠƒï¼Œé€²å…¥åŸ·è¡Œéšæ®µ...")
            # --- ç²å– MCP å·¥å…· ---
            mcp_tools = await get_mcp_tools(mcp_name)
            print(f"  ç²å–äº† {len(mcp_tools)} å€‹ {mcp_name} MCP å·¥å…· (ç”¨æ–¼åŸ·è¡Œ)ã€‚")
            if not mcp_tools: print(f"  è­¦å‘Šï¼šåŸ·è¡Œéšæ®µæœªæ‰¾åˆ° {mcp_name} å·¥å…·ï¼")

            # --- çµ„åˆæ‰€æœ‰å¯ç”¨å·¥å…· ---
            all_tools_for_execution = mcp_tools + LOCAL_TOOLS

            # --- é¸æ“‡åŸ·è¡Œæç¤º ---
            active_execution_prompt_template = None # Use template now
            if mcp_name in ["rhino", "revit"]:
                # Use the globally defined RHINO_AGENT_EXECUTION_PROMPT
                active_execution_prompt_template = RHINO_AGENT_EXECUTION_PROMPT
            elif mcp_name == "pinterest":
                 # Use the globally defined PINTEREST_AGENT_EXECUTION_PROMPT
                 active_execution_prompt_template = PINTEREST_AGENT_EXECUTION_PROMPT # No formatting needed
            elif mcp_name == "osm":
                 # Use the globally defined OSM_AGENT_EXECUTION_PROMPT
                 active_execution_prompt_template = OSM_AGENT_EXECUTION_PROMPT # No formatting needed
            else: # Fallback
                print(f"  è­¦å‘Šï¼šåŸ·è¡Œéšæ®µæ‰¾ä¸åˆ°ç‚º {mcp_name} å®šç¾©çš„ç‰¹å®šåŸ·è¡Œæç¤ºï¼Œå°‡ä½¿ç”¨ Rhino/Revit å¾Œå‚™æç¤ºã€‚")
                active_execution_prompt_template = RHINO_AGENT_EXECUTION_PROMPT

            if not active_execution_prompt_template:
                 # Safety check
                 print(f"  !! åš´é‡éŒ¯èª¤ï¼šæœªèƒ½ç‚º {mcp_name} ç¢ºå®šæœ‰æ•ˆçš„åŸ·è¡Œæç¤ºï¼")
                 return {"messages": [AIMessage(content=f"å…§éƒ¨éŒ¯èª¤ï¼šç„¡æ³•ç‚º {mcp_name} åŠ è¼‰åŸ·è¡ŒæŒ‡ä»¤ã€‚")], "consecutive_llm_text_responses": 0, "last_executed_node": f"{mcp_name}_agent_error"}

            # --- NEW: Format execution prompt with tools for relevant agents ---
            active_execution_prompt = None
            if "{tool_descriptions}" in active_execution_prompt_template.content:
                tool_descriptions_for_exec = "\n".join([f"- {tool.name}: {tool.description}" for tool in all_tools_for_execution])
                active_execution_prompt = SystemMessage(
                    content=active_execution_prompt_template.content.format(tool_descriptions=tool_descriptions_for_exec)
                )
            else:
                # For prompts that don't need tool formatting (like Pinterest/OSM)
                active_execution_prompt = active_execution_prompt_template
            # --- END NEW ---

            # --- åˆ¤æ–·æ˜¯å¦ç‚ºè¨ˆåŠƒç”Ÿæˆå¾Œé¦–æ¬¡åŸ·è¡Œ ---
            is_first_execution_after_plan = False
            # å¦‚æœ plan_exists (æˆ‘å€‘åœ¨åŸ·è¡Œåˆ†æ”¯) ä¸”æœ€å¾Œä¸€æ¢æ¶ˆæ¯æ˜¯æœ‰æ•ˆçš„è¨ˆåŠƒæ¶ˆæ¯,
            # é€™æ„å‘³è‘—æˆ‘å€‘å‰›å¾è¦åŠƒéšæ®µéæ¸¡åˆ°åŸ·è¡Œéšæ®µçš„ç¬¬ä¸€æ­¥ã€‚
            if plan_exists and isinstance(last_message, AIMessage) and \
               isinstance(last_message.content, str) and \
               last_message.content.strip().startswith(PLAN_PREFIX):
                
                # å†æ¬¡ç¢ºèªé€™ä¸æ˜¯ä¸€å€‹åŒ…å« PLAN_PREFIX çš„éŒ¯èª¤æ¶ˆæ¯
                is_actual_plan_msg = "ç„¡æ³•ç‚ºæ‚¨çš„è«‹æ±‚åˆ¶å®šè¨ˆåŠƒ" not in last_message.content and \
                                     "èª¿ç”¨è¦åŠƒ LLM æ™‚ç™¼ç”ŸéŒ¯èª¤" not in last_message.content
                if is_actual_plan_msg:
                    is_first_execution_after_plan = True
                    print("    æª¢æ¸¬åˆ°é€™æ˜¯è¨ˆåŠƒç”Ÿæˆå¾Œçš„ç¬¬ä¸€å€‹åŸ·è¡Œèª¿ç”¨ (æœ€å¾Œä¸€æ¢æ¶ˆæ¯æ˜¯æœ‰æ•ˆçš„è¨ˆåŠƒ)ã€‚")

            # --- æº–å‚™åŸ·è¡Œéšæ®µçš„æ¶ˆæ¯ ---
            messages_for_execution = current_messages
            # Ensure the first HumanMessage includes the image if provided and not already multi-modal
            if has_input_image and isinstance(messages_for_execution[0], HumanMessage) and not isinstance(messages_for_execution[0].content, list):
                # ... (ä¿®æ­£ HumanMessage ä»¥åŒ…å«åœ–ç‰‡çš„é‚è¼¯ä¸è®Š) ...
                 print("   ä¿®æ­£åŸ·è¡Œéšæ®µçš„åˆå§‹ HumanMessage ä»¥åŒ…å«åœ–ç‰‡...")
                 try:
                     # Re-read image and create multi-modal content
                     with open(initial_image_path, "rb") as img_file: img_bytes = img_file.read()
                     img_base64 = base64.b64encode(img_bytes).decode('utf-8')
                     mime_type="image/png" # Re-detect or use default
                     file_ext = os.path.splitext(initial_image_path)[1].lower()
                     if file_ext in ['.jpg', '.jpeg']: mime_type = 'image/jpeg'
                     elif file_ext == '.gif': mime_type = 'image/gif'
                     elif file_ext == '.webp': mime_type = 'image/webp'

                     initial_human_content = [
                         {"type": "text", "text": initial_user_text}, # Use the extracted text
                         {"type": "image_url", "image_url": {"url": f"data:{mime_type};base64,{img_base64}"}}
                     ]
                     messages_for_execution[0] = HumanMessage(content=initial_human_content)
                 except Exception as img_read_err:
                     print(f"   !! ç„¡æ³•è®€å–æˆ–ç·¨ç¢¼åˆå§‹åœ–ç‰‡ç”¨æ–¼åŸ·è¡Œéšæ®µ: {img_read_err}")
                     # Proceed with text-only if image fails during execution prep


            # --- èª¿ç”¨ LLM åŸ·è¡Œä¸‹ä¸€æ­¥ ---
            execution_response = None
            try:
                # --- PRUNE MESSAGES ---
                pruned_messages_for_llm = messages_for_execution # é è¨­ä¸å‰ªæ

                if mcp_name == "rhino":
                    max_interactions_for_rhino_pruning = MAX_RECENT_INTERACTIONS_DEFAULT
                    if is_first_execution_after_plan:
                        max_interactions_for_rhino_pruning = 2
                        print(f"    ç‚º Rhino é¦–æ¬¡åŸ·è¡Œèª¿ç”¨ï¼Œè¨­å®š max_interactions_for_pruning={max_interactions_for_rhino_pruning} (ä¿ç•™åˆå§‹è«‹æ±‚ã€è¨ˆåŠƒå’Œå°‘é‡è¿‘æœŸäº’å‹•)ã€‚")
                    else:
                        print(f"    ç‚º Rhino éé¦–æ¬¡åŸ·è¡Œèª¿ç”¨ï¼Œä½¿ç”¨é è¨­æ­·å²è¨˜éŒ„äº¤äº’æ•¸é‡: {max_interactions_for_rhino_pruning}")
                    
                    print(f"  Rhino: æº–å‚™åŸ·è¡Œ LLM èª¿ç”¨ï¼ŒåŸå§‹å¾…è™•ç†æ¶ˆæ¯æ•¸: {len(messages_for_execution)}")
                    pruned_messages_for_llm = _prune_messages_for_llm(messages_for_execution, max_interactions_for_rhino_pruning)
                else: # å°æ–¼ revit, pinterest, osm ç­‰å…¶ä»– MCP
                    print(f"  {mcp_name.upper()}: ä¸åŸ·è¡Œè¨Šæ¯å‰ªæã€‚åŸå§‹å¾…è™•ç†æ¶ˆæ¯æ•¸: {len(messages_for_execution)}")
                    # pruned_messages_for_llm å·²è¨­ç‚º messages_for_execution (ä¸å‰ªæ)

                print(f"  å‰ªæå¾Œ/è™•ç†å¾Œå‚³éçµ¦ LLM çš„æ¶ˆæ¯æ•¸: {len(pruned_messages_for_llm)}")
                
                execution_response = await call_llm_with_tools(pruned_messages_for_llm, all_tools_for_execution, active_execution_prompt)

            finally:
                rpm_delay = state.get("rpm_delay", 6.5)
                print(f"     åŸ·è¡Œ LLM èª¿ç”¨çµæŸï¼Œç­‰å¾… {rpm_delay} ç§’...")
                await asyncio.sleep(rpm_delay)
                print("     ç­‰å¾…çµæŸã€‚")

            # --- æ›´æ–°é€£çºŒç©ºéŸ¿æ‡‰è¨ˆæ•¸å™¨ ---
            new_consecutive_responses = 0 # Reset by default
            if isinstance(execution_response, AIMessage):
                has_tool_calls = hasattr(execution_response, 'tool_calls') and execution_response.tool_calls
                has_content = execution_response.content is not None and execution_response.content.strip() != ""
                if has_tool_calls:
                    new_consecutive_responses = 0 # Corrected Indentation
                    print(f"  LLM è¿”å› {len(execution_response.tool_calls)} å€‹å·¥å…·èª¿ç”¨ï¼Œé‡ç½®é€£çºŒæ–‡æœ¬éŸ¿æ‡‰è¨ˆæ•¸å™¨ç‚º 0ã€‚")
                elif has_content:
                    # Includes error messages, completion messages, etc.
                    new_consecutive_responses = 0 # Corrected Indentation
                    print(f"  LLM è¿”å›å¸¶æœ‰å…§å®¹çš„æ–‡æœ¬æ¶ˆæ¯ ('{execution_response.content[:50]}...')ï¼Œé‡ç½®é€£çºŒæ–‡æœ¬éŸ¿æ‡‰è¨ˆæ•¸å™¨ç‚º 0ã€‚")
                else: # No tool calls, no content (empty string or None)
                    new_consecutive_responses = current_consecutive_responses + 1 # Corrected Indentation
                    print(f"  LLM è¿”å›ç©ºå…§å®¹ä¸”ç„¡å·¥å…·èª¿ç”¨ï¼Œéå¢é€£çºŒæ–‡æœ¬éŸ¿æ‡‰è¨ˆæ•¸å™¨ç‚º {new_consecutive_responses}ã€‚")
            else: # Not an AIMessage (e.g., internal error in call_llm_with_tools returned something else)
                new_consecutive_responses = 0
                print(f"  æœ€çµ‚è¿”å›é AIMessage é¡å‹ ({type(execution_response).__name__})ï¼Œé‡ç½®é€£çºŒæ–‡æœ¬éŸ¿æ‡‰è¨ˆæ•¸å™¨ç‚º 0ã€‚") # Corrected Indentation

            # --- æª¢æŸ¥è¨ˆæ•¸å™¨é–¾å€¼ ---
            task_complete_due_to_counter = False
            messages_to_return = [] # Initialize list for messages to add to state this turn
            if new_consecutive_responses >= 3:
                print(f"  å·²é€£çºŒæ”¶åˆ° {new_consecutive_responses} æ¬¡ç„¡æ•ˆéŸ¿æ‡‰ï¼Œå°‡æ¨™è¨˜ä»»å‹™å®Œæˆã€‚") # Corrected Indentation
                task_complete_due_to_counter = True
                error_msg = f"[ç³»çµ±éŒ¯èª¤ï¼šé€£çºŒ {new_consecutive_responses} æ¬¡æœªèƒ½ç”Ÿæˆæœ‰æ•ˆå·¥å…·èª¿ç”¨æˆ–å®Œæˆæ¶ˆæ¯ï¼Œä»»å‹™å¼·åˆ¶çµ‚æ­¢ã€‚]" # Corrected Indentation
                # Append the problematic response if it exists and isn't the error message itself
                if execution_response and (not isinstance(execution_response, AIMessage) or execution_response.content != error_msg): # Corrected Indentation
                    messages_to_return.append(execution_response) # Corrected Indentation
                messages_to_return.append(AIMessage(content=error_msg)) # Add the termination message
            elif execution_response: # If counter not exceeded, add the valid response from LLM # Corrected Indentation
                messages_to_return.append(execution_response) # Corrected Indentation

            # --- è¿”å›åŸ·è¡Œçµæœ ---
            return_dict = {
                "messages": messages_to_return,
                "consecutive_llm_text_responses": new_consecutive_responses,
                "last_executed_node": f"{mcp_name}_agent", # æ›´æ–°åŸ·è¡Œçš„ç¯€é»å
                "rhino_screenshot_counter": current_rhino_screenshot_counter # Pass back updated counter
            }
            if task_complete_due_to_counter:
                return_dict["task_complete"] = True # Mark task complete if counter triggered

            return return_dict

    except Exception as e:
        print(f"!! åŸ·è¡Œ {mcp_name.upper()} Agent ç¯€é»æ™‚ç™¼ç”Ÿå¤–éƒ¨éŒ¯èª¤: {e}")
        traceback.print_exc()
        # Return error message and reset counter
        # {{ edit_2 }}
        return {"messages": [AIMessage(content=f"åŸ·è¡Œ {mcp_name} Agent æ™‚ç™¼ç”Ÿå¤–éƒ¨éŒ¯èª¤: {e}")], "consecutive_llm_text_responses": 0, "last_executed_node": f"{mcp_name}_agent_error", "rhino_screenshot_counter": current_rhino_screenshot_counter}
        # {{ end_edit_2 }}

# --- å…·é«”çš„ Agent Nodes (æ·»åŠ  OSM) ---
async def call_revit_agent(state: MCPAgentState, config: RunnableConfig) -> Dict:
    return await agent_node_logic(state, config, "revit")

async def call_rhino_agent(state: MCPAgentState, config: RunnableConfig) -> Dict:
    return await agent_node_logic(state, config, "rhino")

# --- æ–°å¢ Pinterest Agent Node ---
async def call_pinterest_agent(state: MCPAgentState, config: RunnableConfig) -> Dict:
    return await agent_node_logic(state, config, "pinterest")

# --- æ–°å¢ OSM Agent Node ---
async def call_osm_agent(state: MCPAgentState, config: RunnableConfig) -> Dict:
    return await agent_node_logic(state, config, "osm")

# --- Tool Executor Node (ä¿æŒä¸è®Š) ---
async def agent_tool_executor(state: MCPAgentState, config: RunnableConfig) -> Dict:
    """åŸ·è¡Œ Agent è«‹æ±‚çš„å·¥å…·èª¿ç”¨ - å°ˆé–€ç”¨æ–¼ Rhino MCPã€‚"""
    print("--- åŸ·è¡Œ Agent å·¥å…·ç¯€é» (Rhino) ---")
    messages = state['messages']
    last_message = messages[-1] if messages else None

    if not isinstance(last_message, AIMessage) or not last_message.tool_calls:
        print("  æœ€å¾Œæ¶ˆæ¯æ²’æœ‰å·¥å…·èª¿ç”¨ï¼Œè·³éã€‚")
        return {"last_executed_node": "agent_tool_executor_skipped"}

    # ç›´æ¥ä½¿ç”¨ "rhino"ï¼Œä¸éœ€è¦å¾ç‹€æ…‹ä¸­è®€å–
    mcp_name = "rhino"
    print(f"  ç›®æ¨™ MCP: {mcp_name}")
    
    try:
        mcp_tools = await get_mcp_tools(mcp_name)
        all_tools_for_execution = mcp_tools + LOCAL_TOOLS
        print(f"  ä½¿ç”¨ {len(all_tools_for_execution)} å€‹ç¸½å·¥å…· ({mcp_name} MCP: {len(mcp_tools)}, Local: {len(LOCAL_TOOLS)})ã€‚")
        tool_messages = await execute_tools(last_message, all_tools_for_execution)
        print(f"  å·¥å…·åŸ·è¡Œå®Œæˆï¼Œè¿”å› {len(tool_messages)} å€‹ ToolMessageã€‚")
        return {"messages": tool_messages, "last_executed_node": "agent_tool_executor"}
    except Exception as e:
        print(f"!! åŸ·è¡Œ Agent å·¥å…·ç¯€é»æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        traceback.print_exc()
        error_msg = f"åŸ·è¡Œå·¥å…·æ™‚å‡ºéŒ¯: {e}"
        error_tool_messages = [ ToolMessage(content=error_msg, tool_call_id=tc.get("id"), name=tc.get("name", "unknown_tool")) for tc in last_message.tool_calls ]
        return {"messages": error_tool_messages, "last_executed_node": "agent_tool_executor_error"}

# --- Fallback Agent Node ---
async def call_fallback_agent(state: MCPAgentState, config: RunnableConfig) -> Dict:
    """èª¿ç”¨è£œæ•‘ LLM å˜—è©¦æ¢å¾©æµç¨‹ - å°ˆé–€ç”¨æ–¼ Rhino MCPã€‚"""
    print("--- åŸ·è¡Œ Fallback Agent ç¯€é» (Rhino) ---")
    current_messages = state['messages']
    
    # ç›´æ¥ä½¿ç”¨ "rhino"ï¼Œä¸éœ€è¦å¾ç‹€æ…‹ä¸­è®€å–
    mcp_name = "rhino"

    # æå–ç›¸é—œæ­·å²è¨˜éŒ„ç”¨æ–¼æç¤º
    plan_message = next((msg for msg in reversed(current_messages) if isinstance(msg, AIMessage) and isinstance(msg.content, str) and msg.content.strip().startswith(PLAN_PREFIX)), None)
    plan_content_for_prompt = ""
    if plan_message and isinstance(plan_message.content, str):
        # MODIFIED: Use the full plan content for the prompt
        plan_content_for_prompt = plan_message.content.strip()
        print(f"  æå–åˆ°å®Œæ•´è¨ˆåŠƒå…§å®¹ (ç”¨æ–¼ Fallback Prompt): {plan_content_for_prompt[:500]}...")

    # åªå–æœ€è¿‘å¹¾æ¢æ¶ˆæ¯ + è¨ˆåŠƒ (è¨ˆåŠƒå·²å–®ç¨è™•ç†ï¼Œé€™è£¡åªå–éè¨ˆåŠƒçš„è¿‘æœŸæ¶ˆæ¯)
    # MODIFIED: _prune_messages_for_llm now only gets recent *non-plan* messages if plan is found
    # Or, we can build the history string more explicitly. Let's build it explicitly for clarity.
    
    history_items = []
    # Add the initial human message if available (usually the first)
    if current_messages and isinstance(current_messages[0], HumanMessage):
        first_human_msg = current_messages[0]
        # Summarize the initial human message if it's the one with the image content list
        if isinstance(first_human_msg.content, list):
            text_part = ""
            for item in first_human_msg.content:
                 if isinstance(item, dict) and item.get("type") == "text":
                      text_part = item.get("text", "")
                      break
            history_items.append(f"åˆå§‹ç”¨æˆ¶è«‹æ±‚ (HumanMessage): {text_part[:300]}...") # Summarize initial request text
        else:
             history_items.append(f"åˆå§‹ç”¨æˆ¶è«‹æ±‚ (HumanMessage): {str(first_human_msg.content)[:300]}...") # Summarize initial request string

    # Add the plan message's full content (already extracted above)
    if plan_content_for_prompt:
         history_items.append(f"\n---\nå®Œæ•´ç›®æ¨™éšæ®µè¨ˆåŠƒ (AIMessage):\n{plan_content_for_prompt}\n---")


    # Add recent messages (excluding the initial human message and the plan message if they are at the end)
    # Let's grab the last N messages, but skip the first if it's the initial human, and skip the last if it's the plan message itself.
    messages_for_recent_history = current_messages[1:] # Skip the first message assuming it's the initial Human
    if messages_for_recent_history and plan_message and id(messages_for_recent_history[-1]) == id(plan_message):
         messages_for_recent_history = messages_for_recent_history[:-1] # Skip the plan message if it's the last

    # Get the last few relevant messages (e.g., last 5-7 interactions)
    max_recent = 7 # Limit recent history to avoid overwhelming the LLM
    recent_messages_to_summarize = messages_for_recent_history[-max_recent:]


    for msg in recent_messages_to_summarize:
        msg_summary = f"{type(msg).__name__}: "
        if isinstance(msg.content, str):
            msg_summary += f"{msg.content[:500]}..." if len(msg.content) > 500 else msg.content
        elif isinstance(msg.content, list):
            # Summarize list content (e.g., tool message with file path)
            summary_parts = []
            for item in msg.content:
                if isinstance(item, dict) and item.get("type") == "text":
                    summary_parts.append(item.get("text", "")[:100] + "...")
                elif isinstance(item, str): # Handle ToolMessage content which might be JSON string or simple string
                    summary_parts.append(item[:100] + "...")
                else:
                    summary_parts.append(f"[{type(item).__name__} content]")
            msg_summary += " | ".join(summary_parts)
        elif hasattr(msg, 'tool_calls') and msg.tool_calls: # Check for tool_calls attribute
            # Summarize tool calls
            tool_call_summaries = []
            for tc in msg.tool_calls:
                 tool_call_summaries.append(f"ToolCall(name={tc.get('name', 'N/A')}, args={str(tc.get('args', {}))[:100]}...)")
            msg_summary += f"ToolCalls: {'; '.join(tool_call_summaries)}"

        history_items.append(msg_summary)

    # Join the history items into a single string for the prompt
    relevant_history_str = "\n".join(history_items)


    prompt_content = FALLBACK_PROMPT.content.format(relevant_history=relevant_history_str)
    fallback_system_message = SystemMessage(content=prompt_content)
    print(f"  Fallback Agent Prompt (Partial Preview):\n{prompt_content[:1000]}...") # Print a longer preview

    original_fallback_response = None
    fallback_response_to_return = None
    mcp_tools_raw = [] # Define outside try for access in parsing block

    try:
        # ç²å–å·¥å…·ä»¥ä¾›ç¶å®šï¼ˆè£œæ•‘ LLM ä¹Ÿéœ€è¦çŸ¥é“å¯ç”¨å·¥å…·ï¼‰
        mcp_tools_raw = await get_mcp_tools(mcp_name) # Assign to mcp_tools_raw
        if not mcp_tools_raw:
             print(f"  !! Fallback Agent è­¦å‘Šï¼šæœªæ‰¾åˆ° {mcp_name} å·¥å…·ï¼")
        
        # --- ä½¿ç”¨è¼”åŠ©å‡½æ•¸æº–å‚™ Gemini å…¼å®¹çš„å·¥å…· ---
        gemini_compatible_fallback_tools = _prepare_gemini_compatible_tools(mcp_tools_raw)

        # ä½¿ç”¨ agent_llm (Gemini)
        fallback_llm = agent_llm 
        llm_with_tools = fallback_llm.bind_tools(gemini_compatible_fallback_tools) # Bind corrected tools
        llm_configured = llm_with_tools.with_config({"callbacks": None})

        messages_for_llm_invoke = [fallback_system_message]
        # Add a neutral HumanMessage to ensure the 'contents' field is not empty
        # when the SystemMessage is potentially moved to 'system_instruction' by LangChain.
        # This message also serves as a conversational turn for the LLM to respond to.
        # Using "." is a common minimal prompt to trigger a response based on system instructions.
        messages_for_llm_invoke.append(HumanMessage(content="."))

        # original_fallback_response = await llm_configured.ainvoke([fallback_system_message]) # OLD
        original_fallback_response = await llm_configured.ainvoke(messages_for_llm_invoke) # NEW
        print(f"  Fallback Agent åŸå§‹éŸ¿æ‡‰: {original_fallback_response}")
        
        fallback_response_to_return = original_fallback_response # Default


        # --- Reinstated: Process fallback_response to extract tool_calls from content if necessary ---
        if isinstance(original_fallback_response, AIMessage) and \
           isinstance(original_fallback_response.content, str) and \
           not original_fallback_response.tool_calls: 
            
            content_str = original_fallback_response.content.strip()
            is_potential_json_tool_call = False
            if (content_str.startswith('{') and content_str.endswith('}')):
                 is_potential_json_tool_call = True
            elif content_str.startswith('```json'):
                 match = re.match(r'^```json\s*(\{.*?\})\s*```$', content_str, re.DOTALL | re.IGNORECASE)
                 if match:
                     content_str = match.group(1).strip()
                     is_potential_json_tool_call = True
                 else:
                     if "tool_calls" in content_str and ("recipient_name" in content_str or "name" in content_str) : # Added "name"
                          cleaned_md_json_str = re.sub(r'^```(?:json)?\s*|\s*```$', '', original_fallback_response.content.strip(), flags=re.IGNORECASE)
                          if cleaned_md_json_str.strip().startswith('{'):
                              content_str = cleaned_md_json_str.strip()
                              is_potential_json_tool_call = True
            
            if is_potential_json_tool_call:
                try:
                    parsed_json = json.loads(content_str)
                    if isinstance(parsed_json, dict) and "tool_calls" in parsed_json and isinstance(parsed_json["tool_calls"], list):
                        processed_tool_calls = []
                        for tc_orig in parsed_json["tool_calls"]:
                            if isinstance(tc_orig, dict):
                                tc = tc_orig.copy() 
                                tool_name_to_set = None
                                tool_args_to_set = tc.get("parameters", tc.get("args", {}))
                                raw_name = tc.get("recipient_name", tc.get("name"))

                                if raw_name:
                                    func_name_part = raw_name
                                    if raw_name.startswith("functions."):
                                        func_name_part = raw_name.split("functions.", 1)[1]
                                    
                                    found_tool_match = False
                                    # Use mcp_tools_raw which contains the original BaseTool objects
                                    for t_obj in mcp_tools_raw: 
                                        if t_obj.name == func_name_part: 
                                            tool_name_to_set = t_obj.name
                                            found_tool_match = True
                                            break
                                        if t_obj.name.endswith(f"_{func_name_part}"): 
                                            tool_name_to_set = t_obj.name
                                            found_tool_match = True
                                            break
                                    if not found_tool_match:
                                         print(f"  Fallback Agent: Could not reliably map name '{raw_name}' to a known tool. Using '{func_name_part}'.")
                                         tool_name_to_set = func_name_part
                                else:
                                    print(f"  Fallback Agent: Tool call missing 'recipient_name' or 'name': {tc_orig}")
                                    continue 
                                
                                new_tc_entry = {
                                    "name": tool_name_to_set,
                                    "args": tool_args_to_set,
                                    "id": tc.get("id", str(uuid.uuid4()))
                                }
                                processed_tool_calls.append(new_tc_entry)
                            
                        if processed_tool_calls:
                             placeholder_content = "[Fallback agent initiated tool call via content parsing.]"
                             fallback_response_to_return = AIMessage(
                                 content=placeholder_content, 
                                 tool_calls=processed_tool_calls,
                                 id=original_fallback_response.id if original_fallback_response else str(uuid.uuid4()), 
                                 additional_kwargs=original_fallback_response.additional_kwargs if original_fallback_response else {},
                                 response_metadata=original_fallback_response.response_metadata if original_fallback_response else {},
                                 # tool_call_chunks should be fine as None/default if not streaming
                             )
                             print(f"  Fallback Agent: Reconstructed AIMessage with tool_calls attribute: {fallback_response_to_return.tool_calls} and content: '{placeholder_content}'")
                        else:
                            print("  Fallback Agent: Parsed JSON from content, but 'tool_calls' list was empty or malformed after processing.")
                    # else:
                        # print(f"  Fallback Agent: Content was JSON, but not in expected tool_calls format. Parsed: {json.dumps(parsed_json, indent=2)}")


                except json.JSONDecodeError:
                    print(f"  Fallback Agent: Content looked like JSON for tool call but failed to parse: {content_str[:200]}...")
                except Exception as e_proc:
                    print(f"  Fallback Agent: Error processing content for tool_calls: {e_proc} on content {content_str[:200]}")
        # --- END Reinstated Parsing ---


    except Exception as e:
        print(f"!! Fallback Agent èª¿ç”¨ LLM æˆ–è§£ææ™‚ç™¼ç”ŸéŒ¯èª¤: {e}") # Modified error message
        traceback.print_exc()
        # Ensure fallback_response_to_return is an AIMessage
        if not isinstance(fallback_response_to_return, AIMessage):
            fallback_response_to_return = AIMessage(content=f"[FALLBACK_LLM_ERROR_OR_PARSING] {e}")
        else: # If it was already an AIMessage (e.g. from LLM and parsing failed later), append error
            fallback_response_to_return.content += f" [Error during post-processing: {e}]"

    finally:
        # çŸ­æš«ç­‰å¾…ï¼Œé¿å…é€Ÿç‡é™åˆ¶
        rpm_delay = state.get("rpm_delay", 6.5)
        await asyncio.sleep(rpm_delay / 2) # Shorter delay for fallback
        print("     Fallback Agent ç­‰å¾…çµæŸã€‚")

    return {"messages": [fallback_response_to_return] if fallback_response_to_return else [], "last_executed_node": "fallback_agent"}

# =============================================================================
# Conditional Edge Logic (ä¿®æ”¹ should_continue è™•ç† task_complete)
# =============================================================================
def should_continue(state: MCPAgentState) -> str:
    """ç¢ºå®šæ˜¯å¦ç¹¼çºŒè™•ç†è«‹æ±‚ã€èª¿ç”¨å·¥å…·ã€èª¿ç”¨è£œæ•‘æˆ–çµæŸ - å°ˆé–€ç”¨æ–¼ Rhino MCPã€‚"""
    print("--- åˆ¤æ–·æ˜¯å¦ç¹¼çºŒ ---")
    messages = state['messages']
    last_message = messages[-1] if messages else None
    last_node = state.get("last_executed_node")
    
    # ç›´æ¥ä½¿ç”¨ "rhino"ï¼Œä¸éœ€è¦å¾ç‹€æ…‹ä¸­è®€å–
    mcp_name = "rhino"

    # --- å„ªå…ˆæª¢æŸ¥ task_complete æ¨™èªŒ (é€šå¸¸ç”± agent_node_logic ä¸­çš„å·¥å…·çµæœæˆ–é€£çºŒéŒ¯èª¤è§¸ç™¼) ---
    if state.get("task_complete"):
        print(f"  æª¢æ¸¬åˆ° task_complete æ¨™èªŒ (å¯èƒ½ä¾†è‡ªå·¥å…·æˆ–é€£çºŒéŒ¯èª¤) -> end")
        return END

    if not last_message:
        print("  æ¶ˆæ¯åˆ—è¡¨ç‚ºç©º -> end")
        return END

    # --- æª¢æŸ¥ AI æ˜¯å¦è«‹æ±‚å·¥å…·èª¿ç”¨ (ä¾†è‡ªä»»ä½• Agentï¼ŒåŒ…æ‹¬ Fallback) ---
    if isinstance(last_message, AIMessage) and hasattr(last_message, 'tool_calls') and last_message.tool_calls:
        print(f"  AIè«‹æ±‚å·¥å…· ({len(last_message.tool_calls)}å€‹å¾ {last_node}) -> agent_tool_executor")
        return "agent_tool_executor" 

    # --- è™•ç†è¨ˆåŠƒç”Ÿæˆ (é€šå¸¸ç”± primary agent åœ¨æ²’æœ‰è¨ˆåŠƒæ™‚è§¸ç™¼) ---
    if isinstance(last_message, AIMessage) and isinstance(last_message.content, str) and last_message.content.strip().startswith(PLAN_PREFIX):
        is_actual_plan = "ç„¡æ³•ç‚ºæ‚¨çš„è«‹æ±‚åˆ¶å®šè¨ˆåŠƒ" not in last_message.content and "èª¿ç”¨è¦åŠƒ LLM æ™‚ç™¼ç”ŸéŒ¯èª¤" not in last_message.content
        if is_actual_plan:
            if last_node and (last_node.endswith("_agent") or last_node.endswith("_planner")):
                 print(f"  æœ€å¾Œæ¶ˆæ¯æ˜¯æ–°ç”Ÿæˆçš„è¨ˆåŠƒ (ä¾†è‡ª {last_node}) -> è¿”å› {mcp_name}_agent åŸ·è¡Œç¬¬ä¸€æ­¥")
                 return f"{mcp_name}_agent"
            else: 
                 print(f"  !! éŒ¯èª¤: è¨ˆåŠƒæ„å¤–ä¾†è‡ªé Agent ç¯€é» ({last_node}) -> end (ç•°å¸¸)")
                 return END
        else: 
             print(f"  æœ€å¾Œæ¶ˆæ¯æ˜¯è¨ˆåŠƒç”ŸæˆéŒ¯èª¤ ('{last_message.content[:50]}...') -> end") 
             return END

    # --- æª¢æŸ¥æ˜¯å¦ç‚ºå·¥å…·åŸ·è¡Œçµæœ (ToolMessage) ---
    if isinstance(last_message, ToolMessage):
        print(f"  æœ€å¾Œæ¶ˆæ¯æ˜¯ ToolMessage (ä¾†è‡ªå·¥å…· '{last_message.name}') -> è¿”å› {mcp_name}_agent è™•ç†çµæœ")
        return f"{mcp_name}_agent"

    # --- è™•ç† AIMessage (éè¨ˆåŠƒï¼Œä¸”æ²’æœ‰ tool_calls) ---
    if isinstance(last_message, AIMessage):
        # ç¢ºä¿ content_str æ˜¯å¯¦éš›çš„å­—ä¸²ï¼Œå¦‚æœ content ç‚º Noneï¼Œå‰‡é è¨­ç‚ºç©ºå­—ä¸²ä»¥ä¾¿å®‰å…¨è™•ç†
        raw_content = last_message.content
        content_str = str(raw_content).lower() if raw_content is not None else ""

        # --- è™•ç† Fallback Agent çš„è¼¸å‡º (æ²’æœ‰ tool_calls attribute) ---
        if last_node == "fallback_agent":
            fallback_end_keywords = [
                "[fallback_cannot_recover]", "[fallback_error]", "[fallback_llm_error]",
                "[fallback_llm_error_or_parsing]", "[fallback_confirmed_completion]",
            ]
            if any(keyword in content_str for keyword in fallback_end_keywords):
                if "[fallback_confirmed_completion]" in content_str:
                    print(f"  æª¢æ¸¬åˆ° Fallback Agent ç¢ºèªä»»å‹™æˆåŠŸå®Œæˆ ('{content_str[:50]}...') -> end")
                else:
                    print(f"  æª¢æ¸¬åˆ° Fallback Agent æ˜ç¢ºçš„å¤±æ•—/ç„¡æ³•æ¢å¾©æ¶ˆæ¯ ('{content_str[:50]}...') -> end")
                return END
            else:
                print(f"  !! éŒ¯èª¤: Fallback Agent ({last_node}) è¼¸å‡ºéå·¥å…·/éæ˜ç¢ºçµæŸä¿¡è™Ÿçš„ AIMessage ('{content_str[:50]}...') -> end (ç•°å¸¸)")
                return END

        # --- è™•ç†ä¾†è‡ª ä¸»è¦ Agent / Planner çš„ AIMessage ---
        if last_node and (last_node.endswith("_agent") or last_node.endswith("_planner")):
            # 1. æª¢æŸ¥ä¸»è¦ Agent/Planner çš„å®Œæˆé—œéµå­—
            primary_agent_completion_keywords = [ "å…¨éƒ¨ä»»å‹™å·²å®Œæˆ", "åœ–ç‰‡æœç´¢å’Œä¸‹è¼‰å®Œæˆ", "åœ°åœ–æˆªåœ–å·²å®Œæˆ", ]
            if any(keyword in content_str for keyword in primary_agent_completion_keywords):
                print(f"  æª¢æ¸¬åˆ°ä¸»è¦ Agent/Planner ({last_node}) çš„å®Œæˆæ¶ˆæ¯ ('{content_str[:50]}...'). è·¯ç”±åˆ° fallback_agent é€²è¡Œé©—è­‰ã€‚")
                return "fallback_agent"

            # 2. æª¢æŸ¥ä¸»è¦ Agent/Planner çš„å…§å®¹æ˜¯å¦ç‚ºç©º
            #    (æ²’æœ‰ tool_calls çš„æƒ…æ³å·²åœ¨æœ€å‰é¢è™•ç†)
            if not content_str.strip(): # å¦‚æœå…§å®¹ç‚ºç©ºæˆ–åƒ…åŒ…å«ç©ºç™½å­—ç¬¦
                print(f"  ä¾†è‡ªä¸»è¦ Agent/Planner ({last_node}) çš„ AIMessage å…§å®¹ç‚ºç©ºæˆ–åƒ…ç©ºç™½ã€‚è·¯ç”±åˆ° fallback_agentã€‚")
                return "fallback_agent"
            
            # 3. å¦‚æœå…§å®¹éç©ºä¸”ä¸æ˜¯å®Œæˆé—œéµå­—ï¼Œå‰‡æ˜¯ä¸»è¦ Agent/Planner çš„ä¸­é–“æ­¥é©Ÿæ–‡æœ¬ã€‚
            #    è·¯ç”±å›ä¸»è¦ Agent ç¹¼çºŒå…¶è‡ªèº«é‚è¼¯ã€‚
            print(f"  ä¾†è‡ªä¸»è¦ Agent/Planner ({last_node}) çš„ä¸­é–“æ–‡æœ¬ AIMessage ('{content_str[:50]}...'). è·¯ç”±å› {mcp_name}_agentã€‚")
            return f"{mcp_name}_agent"

        # --- è™•ç†ä¾†è‡ª agent_tool_executor çš„ AIMessage ---
        # (é€™é€šå¸¸æ˜¯åœ¨ agent_node_logic è™•ç† ToolMessage å¾Œç”Ÿæˆçš„æ–‡æœ¬æ¶ˆæ¯ï¼Œ
        #  ä¾‹å¦‚ "screenshot saved at X", "Pinterest download complete", "OSM map ready")
        if last_node == "agent_tool_executor":
            # é€™é¡æ¶ˆæ¯æ˜¯è³‡è¨Šæ€§çš„ã€‚ä¸»è¦ Agent éœ€è¦çœ‹åˆ°å®ƒå€‘æ‰èƒ½ç¹¼çºŒåŸ·è¡Œè¨ˆåŠƒã€‚
            # å¦‚æœé€™è£¡çš„æ¶ˆæ¯ç‚ºç©ºï¼Œä¹Ÿæ‡‰è©²è·¯ç”±åˆ° fallbackã€‚
            if not content_str.strip(): # å¦‚æœå…§å®¹ç‚ºç©ºæˆ–åƒ…åŒ…å«ç©ºç™½å­—ç¬¦
                print(f"  ä¾†è‡ª agent_tool_executor çš„ AIMessage å…§å®¹ç‚ºç©ºæˆ–åƒ…ç©ºç™½ã€‚è·¯ç”±åˆ° fallback_agentã€‚")
                return "fallback_agent"

            print(f"  ä¾†è‡ª agent_tool_executor çš„ AIMessage (å·¥å…·çµæœè™•ç†å¾Œçš„ä¿¡æ¯) ('{content_str[:50]}...'). è·¯ç”±å› {mcp_name}_agentã€‚")
            return f"{mcp_name}_agent"

        # --- å…¶ä»– AIMessage çš„æ•ç² ---
        # (ä¾‹å¦‚ï¼Œä¾†è‡ªæœªçŸ¥ç¯€é»ï¼Œæˆ–ä»¥ä¸Šé‚è¼¯æœªèƒ½è¦†è“‹çš„æƒ…æ³)
        print(f"  ä¾†è‡ªç¯€é» '{last_node}' çš„ç„¡æ³•åˆ†é¡çš„ AIMessage (ç„¡å·¥å…·ã€éè¨ˆåŠƒ) ('{content_str[:50]}...'). è·¯ç”±åˆ° fallback_agentã€‚")
        return "fallback_agent"

    # --- å…¶ä»–æ„å¤–æƒ…æ³ ---
    elif isinstance(last_message, HumanMessage):
        print("  åœ¨æµç¨‹ä¸­æ„å¤–å‡ºç¾ HumanMessage (éåˆå§‹è«‹æ±‚) -> end (ç•°å¸¸)")
        return END
    else:
        print(f"  æœªçŸ¥çš„æœ€å¾Œæ¶ˆæ¯é¡å‹ ({type(last_message).__name__}) æˆ–ç„¡æ³•è™•ç†çš„ç‹€æ…‹ -> end")
        return END

# =============================================================================
# å»ºç«‹å’Œç·¨è­¯ LangGraph (æ·»åŠ  OSM ç¯€é»å’Œé‚Š)
# =============================================================================
workflow = StateGraph(MCPAgentState)
# workflow.add_node("router", route_mcp_target)  # æš«æ™‚é—œé–‰ router
# workflow.add_node("revit_agent", call_revit_agent)  # æš«æ™‚é—œé–‰ revit
workflow.add_node("rhino_agent", call_rhino_agent)
# workflow.add_node("pinterest_agent", call_pinterest_agent)  # æš«æ™‚é—œé–‰ pinterest
# workflow.add_node("osm_agent", call_osm_agent)  # æš«æ™‚é—œé–‰ osm
workflow.add_node("agent_tool_executor", agent_tool_executor)
# --- æ–°å¢ Fallback Node ---
workflow.add_node("fallback_agent", call_fallback_agent)

# workflow.set_entry_point("router")  # æš«æ™‚é—œé–‰ router å…¥å£
workflow.set_entry_point("rhino_agent")  # ç›´æ¥é€²å…¥ rhino_agent

# --- Router Edges (æš«æ™‚é—œé–‰) ---
# workflow.add_conditional_edges(
#     "router",
#     lambda x: x.get("target_mcp"),
#     {
#         "revit": "revit_agent",
#         "rhino": "rhino_agent",
#         "pinterest": "pinterest_agent",
#         "osm": "osm_agent"
#         # No default to END here, router should always pick one.
#         # If router fails, it defaults to "revit" internally or could be made to go to END.
#     }
# )

# --- Primary Agent Edges ---
# ç”±æ–¼ should_continue çš„é‚è¼¯å·²ä¿®æ”¹ï¼Œä¸»è¦ agent ä¸å†ç›´æ¥é€£æ¥åˆ° ENDã€‚
# å®ƒå€‘æœƒè«‹æ±‚å·¥å…· (agent_tool_executor)ï¼Œè™•ç†å·¥å…·çµæœå¾Œè¿”å›è‡ªèº«ï¼Œæˆ–è€…å¦‚æœå®ƒå€‘å¡ä½/è²ç¨±å®Œæˆï¼Œ
# should_continue æœƒå°‡å®ƒå€‘è·¯ç”±åˆ° fallback_agentã€‚

# --- æš«æ™‚é—œé–‰ revit_agent edges ---
# workflow.add_conditional_edges(
#     "revit_agent",
#     should_continue,
#     {
#         "agent_tool_executor": "agent_tool_executor",
#         "revit_agent": "revit_agent", # For loop after tool execution if more steps
#         "fallback_agent": "fallback_agent", # If stuck or claims completion
#         END: END # Only if should_continue returns END for critical errors (e.g. no plan, no message)
#     }
# )

workflow.add_conditional_edges(
    "rhino_agent",
    should_continue,
    {
        "agent_tool_executor": "agent_tool_executor",
        "rhino_agent": "rhino_agent",
        "fallback_agent": "fallback_agent",
        END: END
    }
)

# --- æš«æ™‚é—œé–‰ pinterest_agent edges ---
# workflow.add_conditional_edges(
#     "pinterest_agent",
#     should_continue,
#     {
#         "agent_tool_executor": "agent_tool_executor",
#         "pinterest_agent": "pinterest_agent",
#         "fallback_agent": "fallback_agent",
#         END: END
#     }
# )

# --- æš«æ™‚é—œé–‰ osm_agent edges ---
# workflow.add_conditional_edges(
#     "osm_agent",
#     should_continue,
#     {
#         "agent_tool_executor": "agent_tool_executor",
#         "osm_agent": "osm_agent",
#         "fallback_agent": "fallback_agent",
#         END: END
#     }
# )

# --- Fallback Agent Edges ---
workflow.add_conditional_edges(
    "fallback_agent",
    should_continue, # Reuse the same logic
    {
        "agent_tool_executor": "agent_tool_executor", # Fallback succeeded in generating tool call
        # "revit_agent": "revit_agent",  # æš«æ™‚é—œé–‰
        "rhino_agent": "rhino_agent",
        # "pinterest_agent": "pinterest_agent",  # æš«æ™‚é—œé–‰
        # "osm_agent": "osm_agent",  # æš«æ™‚é—œé–‰
        # For now, this setup relies on FALLBACK_PROMPT guiding it to either tool_call or [FALLBACK_CANNOT_RECOVER]
        "fallback_agent": "fallback_agent", # Allows fallback to re-evaluate if it produces text instead of tools/end
        END: END # If should_continue detects explicit fallback failure or other critical errors
    }
)


# --- Tool Executor Edges ---
# After tools are executed, should_continue will route to the correct primary agent
# (revit_agent, rhino_agent, etc.) based on the target_mcp in the state,
# or to fallback_agent if the primary agent then gets stuck.
workflow.add_conditional_edges(
   "agent_tool_executor",
   should_continue, # should_continue correctly routes ToolMessages back to the target_mcp_agent
   {
       # "revit_agent": "revit_agent",  # æš«æ™‚é—œé–‰
       "rhino_agent": "rhino_agent",
       # "pinterest_agent": "pinterest_agent",  # æš«æ™‚é—œé–‰
       # "osm_agent": "osm_agent",  # æš«æ™‚é—œé–‰
       "fallback_agent": "fallback_agent", # This path is less likely if ToolMessage logic in should_continue is robust
                                        # as ToolMessages should go to primary agents.
                                        # However, if a primary agent immediately yields to fallback after a tool, this covers it.
       END: END # If should_continue determines an end condition after tool execution (e.g. task_complete set by tool)
   }
)

graph = workflow.compile().with_config({"recursion_limit": 1000})
# --- ä¿®æ”¹ Graph Name ---
graph.name = "Rhino_Only_Agent_V23_Temp" # æš«æ™‚åªä½¿ç”¨ Rhino
print(f"LangGraph ç·¨è­¯å®Œæˆ: {graph.name}")






